Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS03              Model:              PatchTST            

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS03.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             358                 Dec In:             358                 
  C Out:              358                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS03_PatchTST_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15617
val 5135
test 5135
	iters: 100, epoch: 1 | loss: 0.2940289
	speed: 0.0652s/iter; left time: 312.3242s
	iters: 200, epoch: 1 | loss: 0.2085179
	speed: 0.0582s/iter; left time: 273.2481s
	iters: 300, epoch: 1 | loss: 0.1807979
	speed: 0.0583s/iter; left time: 267.5142s
	iters: 400, epoch: 1 | loss: 0.2055871
	speed: 0.0580s/iter; left time: 260.5079s
Epoch: 1 cost time: 29.223721742630005
Epoch: 1, Steps: 489 | Train Loss: 0.2533051 Vali Loss: 0.1760142 Test Loss: 0.1741022
Validation loss decreased (inf --> 0.176014).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2209225
	speed: 0.4865s/iter; left time: 2092.8699s
	iters: 200, epoch: 2 | loss: 0.2167606
	speed: 0.0669s/iter; left time: 281.0049s
	iters: 300, epoch: 2 | loss: 0.2563481
	speed: 0.0671s/iter; left time: 275.4019s
	iters: 400, epoch: 2 | loss: 0.1989519
	speed: 0.0658s/iter; left time: 263.4281s
Epoch: 2 cost time: 32.932133197784424
Epoch: 2, Steps: 489 | Train Loss: 0.2160437 Vali Loss: 0.1698862 Test Loss: 0.1689715
Validation loss decreased (0.176014 --> 0.169886).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2606546
	speed: 0.5400s/iter; left time: 2059.0551s
	iters: 200, epoch: 3 | loss: 0.2043665
	speed: 0.0706s/iter; left time: 262.2886s
	iters: 300, epoch: 3 | loss: 0.1861866
	speed: 0.0732s/iter; left time: 264.3066s
	iters: 400, epoch: 3 | loss: 0.2287759
	speed: 0.0712s/iter; left time: 249.9546s
Epoch: 3 cost time: 35.047624349594116
Epoch: 3, Steps: 489 | Train Loss: 0.2050479 Vali Loss: 0.1026235 Test Loss: 0.1018614
Validation loss decreased (0.169886 --> 0.102624).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2381307
	speed: 0.5048s/iter; left time: 1677.8664s
	iters: 200, epoch: 4 | loss: 0.1816657
	speed: 0.0619s/iter; left time: 199.6435s
	iters: 300, epoch: 4 | loss: 0.2054906
	speed: 0.0616s/iter; left time: 192.2880s
	iters: 400, epoch: 4 | loss: 0.1813220
	speed: 0.0612s/iter; left time: 185.0252s
Epoch: 4 cost time: 30.39216685295105
Epoch: 4, Steps: 489 | Train Loss: 0.1986158 Vali Loss: 0.0957627 Test Loss: 0.0967213
Validation loss decreased (0.102624 --> 0.095763).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1766473
	speed: 0.4288s/iter; left time: 1215.7265s
	iters: 200, epoch: 5 | loss: 0.1940462
	speed: 0.0577s/iter; left time: 157.7167s
	iters: 300, epoch: 5 | loss: 0.2291913
	speed: 0.0577s/iter; left time: 152.0491s
	iters: 400, epoch: 5 | loss: 0.2022150
	speed: 0.0579s/iter; left time: 146.8185s
Epoch: 5 cost time: 28.68951654434204
Epoch: 5, Steps: 489 | Train Loss: 0.1959077 Vali Loss: 0.0962894 Test Loss: 0.0969963
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1877650
	speed: 0.4242s/iter; left time: 995.2323s
	iters: 200, epoch: 6 | loss: 0.1920078
	speed: 0.0577s/iter; left time: 129.5661s
	iters: 300, epoch: 6 | loss: 0.1766460
	speed: 0.0633s/iter; left time: 135.7565s
	iters: 400, epoch: 6 | loss: 0.1729871
	speed: 0.0666s/iter; left time: 136.1730s
Epoch: 6 cost time: 30.724868535995483
Epoch: 6, Steps: 489 | Train Loss: 0.1944150 Vali Loss: 0.0939006 Test Loss: 0.0945071
Validation loss decreased (0.095763 --> 0.093901).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1831432
	speed: 0.5082s/iter; left time: 943.7869s
	iters: 200, epoch: 7 | loss: 0.1813937
	speed: 0.0670s/iter; left time: 117.6948s
	iters: 300, epoch: 7 | loss: 0.1961816
	speed: 0.0669s/iter; left time: 110.7761s
	iters: 400, epoch: 7 | loss: 0.2059110
	speed: 0.0694s/iter; left time: 108.1327s
Epoch: 7 cost time: 32.969908475875854
Epoch: 7, Steps: 489 | Train Loss: 0.1936065 Vali Loss: 0.0955319 Test Loss: 0.0965171
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2317641
	speed: 0.5076s/iter; left time: 694.4652s
	iters: 200, epoch: 8 | loss: 0.1639617
	speed: 0.0659s/iter; left time: 83.5101s
	iters: 300, epoch: 8 | loss: 0.1740812
	speed: 0.0627s/iter; left time: 73.2177s
	iters: 400, epoch: 8 | loss: 0.2234408
	speed: 0.0580s/iter; left time: 61.9796s
Epoch: 8 cost time: 30.731624126434326
Epoch: 8, Steps: 489 | Train Loss: 0.1930781 Vali Loss: 0.0938720 Test Loss: 0.0947563
Validation loss decreased (0.093901 --> 0.093872).  Saving model ...
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1665258
	speed: 0.4234s/iter; left time: 372.1542s
	iters: 200, epoch: 9 | loss: 0.2105747
	speed: 0.0585s/iter; left time: 45.5889s
	iters: 300, epoch: 9 | loss: 0.1583155
	speed: 0.0587s/iter; left time: 39.8679s
	iters: 400, epoch: 9 | loss: 0.1985337
	speed: 0.0578s/iter; left time: 33.4803s
Epoch: 9 cost time: 28.80696749687195
Epoch: 9, Steps: 489 | Train Loss: 0.1927702 Vali Loss: 0.0911530 Test Loss: 0.0918741
Validation loss decreased (0.093872 --> 0.091153).  Saving model ...
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1894649
	speed: 0.4238s/iter; left time: 165.2756s
	iters: 200, epoch: 10 | loss: 0.1866332
	speed: 0.0574s/iter; left time: 16.6501s
	iters: 300, epoch: 10 | loss: 0.1694674
	speed: 0.0581s/iter; left time: 11.0398s
	iters: 400, epoch: 10 | loss: 0.1892592
	speed: 0.0578s/iter; left time: 5.2024s
Epoch: 10 cost time: 28.635388135910034
Epoch: 10, Steps: 489 | Train Loss: 0.1924841 Vali Loss: 0.0913970 Test Loss: 0.0923757
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS03_PatchTST_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5135
test shape: (5135, 12, 358) (5135, 12, 358)
test shape: (5135, 12, 358) (5135, 12, 358)
mse:0.0919240415096283, mae:0.20805644989013672
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS04              Model:              PatchTST            

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS04.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             307                 Dec In:             307                 
  C Out:              307                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS04_PatchTST_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10088
val 3291
test 3292
	iters: 100, epoch: 1 | loss: 0.3479300
	speed: 0.0671s/iter; left time: 205.4239s
	iters: 200, epoch: 1 | loss: 0.2559107
	speed: 0.0603s/iter; left time: 178.4358s
	iters: 300, epoch: 1 | loss: 0.3217637
	speed: 0.0614s/iter; left time: 175.7570s
Epoch: 1 cost time: 19.80283546447754
Epoch: 1, Steps: 316 | Train Loss: 0.2553191 Vali Loss: 0.2773679 Test Loss: 0.2660793
Validation loss decreased (inf --> 0.277368).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2199619
	speed: 0.3143s/iter; left time: 862.8247s
	iters: 200, epoch: 2 | loss: 0.1996187
	speed: 0.0630s/iter; left time: 166.6396s
	iters: 300, epoch: 2 | loss: 0.2498219
	speed: 0.0635s/iter; left time: 161.7291s
Epoch: 2 cost time: 19.971821784973145
Epoch: 2, Steps: 316 | Train Loss: 0.2186365 Vali Loss: 0.1345965 Test Loss: 0.1282668
Validation loss decreased (0.277368 --> 0.134596).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2009686
	speed: 0.3142s/iter; left time: 763.1261s
	iters: 200, epoch: 3 | loss: 0.2439352
	speed: 0.0606s/iter; left time: 141.1368s
	iters: 300, epoch: 3 | loss: 0.1673178
	speed: 0.0608s/iter; left time: 135.4408s
Epoch: 3 cost time: 19.408901929855347
Epoch: 3, Steps: 316 | Train Loss: 0.2109741 Vali Loss: 0.1175474 Test Loss: 0.1119357
Validation loss decreased (0.134596 --> 0.117547).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2084118
	speed: 0.2621s/iter; left time: 553.9080s
	iters: 200, epoch: 4 | loss: 0.2041501
	speed: 0.0571s/iter; left time: 114.9094s
	iters: 300, epoch: 4 | loss: 0.2021882
	speed: 0.0574s/iter; left time: 109.7603s
Epoch: 4 cost time: 18.48710584640503
Epoch: 4, Steps: 316 | Train Loss: 0.2060802 Vali Loss: 0.1403769 Test Loss: 0.1351885
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2149005
	speed: 0.2869s/iter; left time: 515.5299s
	iters: 200, epoch: 5 | loss: 0.2075661
	speed: 0.0578s/iter; left time: 98.0451s
	iters: 300, epoch: 5 | loss: 0.1813707
	speed: 0.0570s/iter; left time: 91.0519s
Epoch: 5 cost time: 18.535449028015137
Epoch: 5, Steps: 316 | Train Loss: 0.2046853 Vali Loss: 0.1152059 Test Loss: 0.1102504
Validation loss decreased (0.117547 --> 0.115206).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1842024
	speed: 0.2838s/iter; left time: 420.3045s
	iters: 200, epoch: 6 | loss: 0.2291653
	speed: 0.0571s/iter; left time: 78.8802s
	iters: 300, epoch: 6 | loss: 0.1914808
	speed: 0.0569s/iter; left time: 72.9325s
Epoch: 6 cost time: 18.24455738067627
Epoch: 6, Steps: 316 | Train Loss: 0.2039034 Vali Loss: 0.1179307 Test Loss: 0.1127209
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2136895
	speed: 0.2855s/iter; left time: 332.6497s
	iters: 200, epoch: 7 | loss: 0.1895647
	speed: 0.0568s/iter; left time: 60.5294s
	iters: 300, epoch: 7 | loss: 0.1860422
	speed: 0.0562s/iter; left time: 54.2750s
Epoch: 7 cost time: 18.35953640937805
Epoch: 7, Steps: 316 | Train Loss: 0.2034386 Vali Loss: 0.1158417 Test Loss: 0.1106489
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1820397
	speed: 0.3150s/iter; left time: 267.4603s
	iters: 200, epoch: 8 | loss: 0.1757944
	speed: 0.0613s/iter; left time: 45.9128s
	iters: 300, epoch: 8 | loss: 0.2354628
	speed: 0.0626s/iter; left time: 40.6202s
Epoch: 8 cost time: 19.915261030197144
Epoch: 8, Steps: 316 | Train Loss: 0.2035068 Vali Loss: 0.1195919 Test Loss: 0.1141465
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.2164294
	speed: 0.3145s/iter; left time: 167.6528s
	iters: 200, epoch: 9 | loss: 0.1659112
	speed: 0.0608s/iter; left time: 26.3303s
	iters: 300, epoch: 9 | loss: 0.2156027
	speed: 0.0639s/iter; left time: 21.2717s
Epoch: 9 cost time: 20.02231478691101
Epoch: 9, Steps: 316 | Train Loss: 0.2029810 Vali Loss: 0.1198969 Test Loss: 0.1142218
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.2033646
	speed: 0.3134s/iter; left time: 68.0052s
	iters: 200, epoch: 10 | loss: 0.2376784
	speed: 0.0618s/iter; left time: 7.2336s
	iters: 300, epoch: 10 | loss: 0.2117303
	speed: 0.0629s/iter; left time: 1.0701s
Epoch: 10 cost time: 19.919127702713013
Epoch: 10, Steps: 316 | Train Loss: 0.2026834 Vali Loss: 0.1190623 Test Loss: 0.1135820
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS04_PatchTST_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3292
test shape: (3292, 12, 307) (3292, 12, 307)
test shape: (3292, 12, 307) (3292, 12, 307)
mse:0.11031007766723633, mae:0.22592583298683167
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS07              Model:              PatchTST            

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS07.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             883                 Dec In:             883                 
  C Out:              883                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS07_PatchTST_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16827
val 5538
test 5538
	iters: 100, epoch: 1 | loss: 0.2678867
	speed: 0.1136s/iter; left time: 586.2711s
	iters: 200, epoch: 1 | loss: 0.2452140
	speed: 0.1089s/iter; left time: 551.1290s
	iters: 300, epoch: 1 | loss: 0.2460430
	speed: 0.1081s/iter; left time: 536.5303s
	iters: 400, epoch: 1 | loss: 0.2283444
	speed: 0.1078s/iter; left time: 523.9742s
	iters: 500, epoch: 1 | loss: 0.1906729
	speed: 0.1084s/iter; left time: 516.0029s
Epoch: 1 cost time: 57.54853057861328
Epoch: 1, Steps: 526 | Train Loss: 0.2345420 Vali Loss: 0.1035613 Test Loss: 0.1053836
Validation loss decreased (inf --> 0.103561).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2140064
	speed: 0.5758s/iter; left time: 2668.8344s
	iters: 200, epoch: 2 | loss: 0.2393443
	speed: 0.1091s/iter; left time: 494.7604s
	iters: 300, epoch: 2 | loss: 0.2013235
	speed: 0.1141s/iter; left time: 505.8292s
	iters: 400, epoch: 2 | loss: 0.2575920
	speed: 0.1140s/iter; left time: 494.0313s
	iters: 500, epoch: 2 | loss: 0.1709675
	speed: 0.1140s/iter; left time: 482.6240s
Epoch: 2 cost time: 59.366074085235596
Epoch: 2, Steps: 526 | Train Loss: 0.2051801 Vali Loss: 0.1007539 Test Loss: 0.1032223
Validation loss decreased (0.103561 --> 0.100754).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1797185
	speed: 0.6852s/iter; left time: 2815.4013s
	iters: 200, epoch: 3 | loss: 0.1894321
	speed: 0.1142s/iter; left time: 457.9764s
	iters: 300, epoch: 3 | loss: 0.2083697
	speed: 0.1135s/iter; left time: 443.8217s
	iters: 400, epoch: 3 | loss: 0.2061494
	speed: 0.1086s/iter; left time: 413.8364s
	iters: 500, epoch: 3 | loss: 0.1754959
	speed: 0.1085s/iter; left time: 402.4494s
Epoch: 3 cost time: 59.2380530834198
Epoch: 3, Steps: 526 | Train Loss: 0.1958159 Vali Loss: 0.0912692 Test Loss: 0.0933455
Validation loss decreased (0.100754 --> 0.091269).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1754361
	speed: 0.5801s/iter; left time: 2078.4840s
	iters: 200, epoch: 4 | loss: 0.1887976
	speed: 0.1080s/iter; left time: 376.3379s
	iters: 300, epoch: 4 | loss: 0.2060842
	speed: 0.1082s/iter; left time: 365.9185s
	iters: 400, epoch: 4 | loss: 0.1692733
	speed: 0.1080s/iter; left time: 354.5921s
	iters: 500, epoch: 4 | loss: 0.1855839
	speed: 0.1088s/iter; left time: 346.2282s
Epoch: 4 cost time: 57.35473155975342
Epoch: 4, Steps: 526 | Train Loss: 0.1924010 Vali Loss: 0.0897186 Test Loss: 0.0918668
Validation loss decreased (0.091269 --> 0.089719).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1693030
	speed: 0.6573s/iter; left time: 2009.3731s
	iters: 200, epoch: 5 | loss: 0.1974058
	speed: 0.1153s/iter; left time: 340.9696s
	iters: 300, epoch: 5 | loss: 0.2221877
	speed: 0.1164s/iter; left time: 332.5973s
	iters: 400, epoch: 5 | loss: 0.1924653
	speed: 0.1164s/iter; left time: 321.0126s
	iters: 500, epoch: 5 | loss: 0.1598040
	speed: 0.1162s/iter; left time: 308.8531s
Epoch: 5 cost time: 61.71164512634277
Epoch: 5, Steps: 526 | Train Loss: 0.1907268 Vali Loss: 0.0881850 Test Loss: 0.0901572
Validation loss decreased (0.089719 --> 0.088185).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1864676
	speed: 0.7376s/iter; left time: 1866.9261s
	iters: 200, epoch: 6 | loss: 0.2215970
	speed: 0.1093s/iter; left time: 265.7462s
	iters: 300, epoch: 6 | loss: 0.1984552
	speed: 0.1088s/iter; left time: 253.5811s
	iters: 400, epoch: 6 | loss: 0.1937717
	speed: 0.1083s/iter; left time: 241.5256s
	iters: 500, epoch: 6 | loss: 0.2323685
	speed: 0.1079s/iter; left time: 229.9575s
Epoch: 6 cost time: 57.640724897384644
Epoch: 6, Steps: 526 | Train Loss: 0.1896879 Vali Loss: 0.0842828 Test Loss: 0.0858987
Validation loss decreased (0.088185 --> 0.084283).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1759064
	speed: 0.5733s/iter; left time: 1149.3992s
	iters: 200, epoch: 7 | loss: 0.1994263
	speed: 0.1078s/iter; left time: 205.2767s
	iters: 300, epoch: 7 | loss: 0.1742617
	speed: 0.1084s/iter; left time: 195.6580s
	iters: 400, epoch: 7 | loss: 0.1832719
	speed: 0.1084s/iter; left time: 184.9066s
	iters: 500, epoch: 7 | loss: 0.1956050
	speed: 0.1084s/iter; left time: 173.9362s
Epoch: 7 cost time: 57.97397541999817
Epoch: 7, Steps: 526 | Train Loss: 0.1891334 Vali Loss: 0.0873276 Test Loss: 0.0889997
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1970381
	speed: 0.5836s/iter; left time: 863.0976s
	iters: 200, epoch: 8 | loss: 0.1765321
	speed: 0.1129s/iter; left time: 155.6250s
	iters: 300, epoch: 8 | loss: 0.1872877
	speed: 0.1145s/iter; left time: 146.4618s
	iters: 400, epoch: 8 | loss: 0.1985703
	speed: 0.1140s/iter; left time: 134.4227s
	iters: 500, epoch: 8 | loss: 0.2104347
	speed: 0.1132s/iter; left time: 122.1512s
Epoch: 8 cost time: 59.697232723236084
Epoch: 8, Steps: 526 | Train Loss: 0.1887381 Vali Loss: 0.0875810 Test Loss: 0.0892835
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1809744
	speed: 0.6817s/iter; left time: 649.6528s
	iters: 200, epoch: 9 | loss: 0.2064697
	speed: 0.1134s/iter; left time: 96.6903s
	iters: 300, epoch: 9 | loss: 0.2231625
	speed: 0.1081s/iter; left time: 81.3654s
	iters: 400, epoch: 9 | loss: 0.1988540
	speed: 0.1084s/iter; left time: 70.7758s
	iters: 500, epoch: 9 | loss: 0.1884133
	speed: 0.1092s/iter; left time: 60.3814s
Epoch: 9 cost time: 58.53936958312988
Epoch: 9, Steps: 526 | Train Loss: 0.1885464 Vali Loss: 0.0867870 Test Loss: 0.0885785
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.2035676
	speed: 0.5790s/iter; left time: 247.2429s
	iters: 200, epoch: 10 | loss: 0.1772999
	speed: 0.1086s/iter; left time: 35.5238s
	iters: 300, epoch: 10 | loss: 0.2131130
	speed: 0.1079s/iter; left time: 24.4870s
	iters: 400, epoch: 10 | loss: 0.1955270
	speed: 0.1084s/iter; left time: 13.7666s
	iters: 500, epoch: 10 | loss: 0.2160742
	speed: 0.1080s/iter; left time: 2.9149s
Epoch: 10 cost time: 57.26452159881592
Epoch: 10, Steps: 526 | Train Loss: 0.1885812 Vali Loss: 0.0857707 Test Loss: 0.0876848
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS07_PatchTST_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5538
test shape: (5538, 12, 883) (5538, 12, 883)
test shape: (5538, 12, 883) (5538, 12, 883)
mse:0.08568326383829117, mae:0.20289485156536102
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS08              Model:              PatchTST            

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS08.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             170                 Dec In:             170                 
  C Out:              170                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS08_PatchTST_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10606
val 3464
test 3465
	iters: 100, epoch: 1 | loss: 0.2775234
	speed: 0.0637s/iter; left time: 205.2131s
	iters: 200, epoch: 1 | loss: 0.2430159
	speed: 0.0596s/iter; left time: 186.1156s
	iters: 300, epoch: 1 | loss: 0.2238337
	speed: 0.0600s/iter; left time: 181.1410s
Epoch: 1 cost time: 20.227967500686646
Epoch: 1, Steps: 332 | Train Loss: 0.2407248 Vali Loss: 0.1748509 Test Loss: 0.1686125
Validation loss decreased (inf --> 0.174851).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2066929
	speed: 0.3433s/iter; left time: 991.7654s
	iters: 200, epoch: 2 | loss: 0.1800060
	speed: 0.0606s/iter; left time: 169.0448s
	iters: 300, epoch: 2 | loss: 0.1975762
	speed: 0.0602s/iter; left time: 161.9919s
Epoch: 2 cost time: 20.117148876190186
Epoch: 2, Steps: 332 | Train Loss: 0.2112400 Vali Loss: 0.1235345 Test Loss: 0.1117224
Validation loss decreased (0.174851 --> 0.123534).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2252566
	speed: 0.2899s/iter; left time: 741.2927s
	iters: 200, epoch: 3 | loss: 0.1790915
	speed: 0.0485s/iter; left time: 119.2151s
	iters: 300, epoch: 3 | loss: 0.2106951
	speed: 0.0492s/iter; left time: 115.9829s
Epoch: 3 cost time: 16.533745288848877
Epoch: 3, Steps: 332 | Train Loss: 0.2039765 Vali Loss: 0.1261476 Test Loss: 0.1148319
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2057167
	speed: 0.2738s/iter; left time: 609.2745s
	iters: 200, epoch: 4 | loss: 0.2095817
	speed: 0.0494s/iter; left time: 104.8689s
	iters: 300, epoch: 4 | loss: 0.2271959
	speed: 0.0479s/iter; left time: 96.9698s
Epoch: 4 cost time: 16.314716815948486
Epoch: 4, Steps: 332 | Train Loss: 0.1998623 Vali Loss: 0.1181432 Test Loss: 0.1075455
Validation loss decreased (0.123534 --> 0.118143).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1858050
	speed: 0.2457s/iter; left time: 465.0242s
	iters: 200, epoch: 5 | loss: 0.1490435
	speed: 0.0457s/iter; left time: 81.9112s
	iters: 300, epoch: 5 | loss: 0.2028594
	speed: 0.0440s/iter; left time: 74.4779s
Epoch: 5 cost time: 15.117089748382568
Epoch: 5, Steps: 332 | Train Loss: 0.1978818 Vali Loss: 0.1178350 Test Loss: 0.1072089
Validation loss decreased (0.118143 --> 0.117835).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2261637
	speed: 0.2480s/iter; left time: 387.0713s
	iters: 200, epoch: 6 | loss: 0.2118671
	speed: 0.0451s/iter; left time: 65.8386s
	iters: 300, epoch: 6 | loss: 0.1942026
	speed: 0.0454s/iter; left time: 61.7404s
Epoch: 6 cost time: 15.121464967727661
Epoch: 6, Steps: 332 | Train Loss: 0.1968228 Vali Loss: 0.1143327 Test Loss: 0.1037158
Validation loss decreased (0.117835 --> 0.114333).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1739990
	speed: 0.2475s/iter; left time: 304.1686s
	iters: 200, epoch: 7 | loss: 0.1952303
	speed: 0.0541s/iter; left time: 61.0921s
	iters: 300, epoch: 7 | loss: 0.2291465
	speed: 0.0554s/iter; left time: 56.9615s
Epoch: 7 cost time: 17.487725734710693
Epoch: 7, Steps: 332 | Train Loss: 0.1964679 Vali Loss: 0.1139296 Test Loss: 0.1037495
Validation loss decreased (0.114333 --> 0.113930).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1870166
	speed: 0.3095s/iter; left time: 277.5878s
	iters: 200, epoch: 8 | loss: 0.2125304
	speed: 0.0549s/iter; left time: 43.7339s
	iters: 300, epoch: 8 | loss: 0.2035249
	speed: 0.0528s/iter; left time: 36.7884s
Epoch: 8 cost time: 18.193775415420532
Epoch: 8, Steps: 332 | Train Loss: 0.1958903 Vali Loss: 0.1151690 Test Loss: 0.1053511
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1842900
	speed: 0.3076s/iter; left time: 173.7898s
	iters: 200, epoch: 9 | loss: 0.2073862
	speed: 0.0541s/iter; left time: 25.1337s
	iters: 300, epoch: 9 | loss: 0.2062648
	speed: 0.0563s/iter; left time: 20.5321s
Epoch: 9 cost time: 18.344846725463867
Epoch: 9, Steps: 332 | Train Loss: 0.1956940 Vali Loss: 0.1142573 Test Loss: 0.1039472
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1986496
	speed: 0.3086s/iter; left time: 71.8942s
	iters: 200, epoch: 10 | loss: 0.2239646
	speed: 0.0530s/iter; left time: 7.0437s
	iters: 300, epoch: 10 | loss: 0.2054509
	speed: 0.0563s/iter; left time: 1.8568s
Epoch: 10 cost time: 18.514758586883545
Epoch: 10, Steps: 332 | Train Loss: 0.1955403 Vali Loss: 0.1148383 Test Loss: 0.1047519
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS08_PatchTST_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3465
test shape: (3465, 12, 170) (3465, 12, 170)
test shape: (3465, 12, 170) (3465, 12, 170)
mse:0.10401008278131485, mae:0.22229886054992676
