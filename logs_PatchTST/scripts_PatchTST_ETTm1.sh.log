Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_96         Model:              PatchTST            

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_96_PatchTST_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4080730
	speed: 0.0199s/iter; left time: 212.3144s
	iters: 200, epoch: 1 | loss: 0.4012430
	speed: 0.0139s/iter; left time: 146.8072s
	iters: 300, epoch: 1 | loss: 0.3321552
	speed: 0.0139s/iter; left time: 145.5072s
	iters: 400, epoch: 1 | loss: 0.3491504
	speed: 0.0148s/iter; left time: 153.2666s
	iters: 500, epoch: 1 | loss: 0.3419696
	speed: 0.0135s/iter; left time: 138.5880s
	iters: 600, epoch: 1 | loss: 0.3655832
	speed: 0.0138s/iter; left time: 139.9429s
	iters: 700, epoch: 1 | loss: 0.3973464
	speed: 0.0142s/iter; left time: 142.7581s
	iters: 800, epoch: 1 | loss: 0.4009984
	speed: 0.0139s/iter; left time: 138.2552s
	iters: 900, epoch: 1 | loss: 0.3324931
	speed: 0.0137s/iter; left time: 134.5114s
	iters: 1000, epoch: 1 | loss: 0.3038504
	speed: 0.0137s/iter; left time: 133.7479s
Epoch: 1 cost time: 15.624914646148682
Epoch: 1, Steps: 1075 | Train Loss: 0.3494674 Vali Loss: 0.4046710 Test Loss: 0.3342278
Validation loss decreased (inf --> 0.404671).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2740746
	speed: 0.0848s/iter; left time: 811.7043s
	iters: 200, epoch: 2 | loss: 0.2903482
	speed: 0.0138s/iter; left time: 130.9418s
	iters: 300, epoch: 2 | loss: 0.2908512
	speed: 0.0137s/iter; left time: 128.6756s
	iters: 400, epoch: 2 | loss: 0.3003371
	speed: 0.0137s/iter; left time: 126.6753s
	iters: 500, epoch: 2 | loss: 0.3418039
	speed: 0.0137s/iter; left time: 125.4604s
	iters: 600, epoch: 2 | loss: 0.3123588
	speed: 0.0137s/iter; left time: 124.1130s
	iters: 700, epoch: 2 | loss: 0.3518855
	speed: 0.0156s/iter; left time: 140.0170s
	iters: 800, epoch: 2 | loss: 0.3053834
	speed: 0.0143s/iter; left time: 126.9829s
	iters: 900, epoch: 2 | loss: 0.3297896
	speed: 0.0141s/iter; left time: 123.5292s
	iters: 1000, epoch: 2 | loss: 0.2836673
	speed: 0.0141s/iter; left time: 122.5989s
Epoch: 2 cost time: 15.973340272903442
Epoch: 2, Steps: 1075 | Train Loss: 0.3233670 Vali Loss: 0.4036587 Test Loss: 0.3257829
Validation loss decreased (0.404671 --> 0.403659).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3857222
	speed: 0.0993s/iter; left time: 844.0455s
	iters: 200, epoch: 3 | loss: 0.3182487
	speed: 0.0141s/iter; left time: 118.2581s
	iters: 300, epoch: 3 | loss: 0.3034935
	speed: 0.0144s/iter; left time: 119.8617s
	iters: 400, epoch: 3 | loss: 0.3362876
	speed: 0.0147s/iter; left time: 120.6242s
	iters: 500, epoch: 3 | loss: 0.3416256
	speed: 0.0141s/iter; left time: 114.3941s
	iters: 600, epoch: 3 | loss: 0.3230586
	speed: 0.0146s/iter; left time: 116.4631s
	iters: 700, epoch: 3 | loss: 0.2529827
	speed: 0.0140s/iter; left time: 110.2681s
	iters: 800, epoch: 3 | loss: 0.3044343
	speed: 0.0139s/iter; left time: 108.5714s
	iters: 900, epoch: 3 | loss: 0.3153877
	speed: 0.0139s/iter; left time: 107.0781s
	iters: 1000, epoch: 3 | loss: 0.3405152
	speed: 0.0139s/iter; left time: 105.8199s
Epoch: 3 cost time: 15.744526386260986
Epoch: 3, Steps: 1075 | Train Loss: 0.3116372 Vali Loss: 0.4143870 Test Loss: 0.3277308
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2917407
	speed: 0.0900s/iter; left time: 668.5167s
	iters: 200, epoch: 4 | loss: 0.3001585
	speed: 0.0142s/iter; left time: 104.3080s
	iters: 300, epoch: 4 | loss: 0.3201491
	speed: 0.0149s/iter; left time: 107.7475s
	iters: 400, epoch: 4 | loss: 0.3031177
	speed: 0.0152s/iter; left time: 108.4211s
	iters: 500, epoch: 4 | loss: 0.3577024
	speed: 0.0156s/iter; left time: 109.4078s
	iters: 600, epoch: 4 | loss: 0.3559772
	speed: 0.0141s/iter; left time: 97.7863s
	iters: 700, epoch: 4 | loss: 0.2567430
	speed: 0.0139s/iter; left time: 94.9938s
	iters: 800, epoch: 4 | loss: 0.3013077
	speed: 0.0146s/iter; left time: 98.1032s
	iters: 900, epoch: 4 | loss: 0.3575883
	speed: 0.0141s/iter; left time: 93.2884s
	iters: 1000, epoch: 4 | loss: 0.3131890
	speed: 0.0140s/iter; left time: 91.3233s
Epoch: 4 cost time: 15.98241400718689
Epoch: 4, Steps: 1075 | Train Loss: 0.3068253 Vali Loss: 0.4052588 Test Loss: 0.3207165
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2871865
	speed: 0.0902s/iter; left time: 572.8989s
	iters: 200, epoch: 5 | loss: 0.3154750
	speed: 0.0152s/iter; left time: 95.2897s
	iters: 300, epoch: 5 | loss: 0.3783198
	speed: 0.0144s/iter; left time: 88.7613s
	iters: 400, epoch: 5 | loss: 0.2661039
	speed: 0.0144s/iter; left time: 87.1333s
	iters: 500, epoch: 5 | loss: 0.2581955
	speed: 0.0140s/iter; left time: 83.5646s
	iters: 600, epoch: 5 | loss: 0.2891297
	speed: 0.0140s/iter; left time: 82.1381s
	iters: 700, epoch: 5 | loss: 0.3216436
	speed: 0.0142s/iter; left time: 81.7456s
	iters: 800, epoch: 5 | loss: 0.4097410
	speed: 0.0147s/iter; left time: 83.1337s
	iters: 900, epoch: 5 | loss: 0.2893750
	speed: 0.0140s/iter; left time: 77.4568s
	iters: 1000, epoch: 5 | loss: 0.3058358
	speed: 0.0144s/iter; left time: 78.6120s
Epoch: 5 cost time: 15.913852453231812
Epoch: 5, Steps: 1075 | Train Loss: 0.3044822 Vali Loss: 0.4028743 Test Loss: 0.3198201
Validation loss decreased (0.403659 --> 0.402874).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2834677
	speed: 0.0925s/iter; left time: 488.1866s
	iters: 200, epoch: 6 | loss: 0.3716860
	speed: 0.0139s/iter; left time: 71.9918s
	iters: 300, epoch: 6 | loss: 0.2966155
	speed: 0.0139s/iter; left time: 70.6700s
	iters: 400, epoch: 6 | loss: 0.3326274
	speed: 0.0141s/iter; left time: 70.0877s
	iters: 500, epoch: 6 | loss: 0.3074011
	speed: 0.0154s/iter; left time: 74.8890s
	iters: 600, epoch: 6 | loss: 0.3218556
	speed: 0.0157s/iter; left time: 75.0521s
	iters: 700, epoch: 6 | loss: 0.3163152
	speed: 0.0151s/iter; left time: 70.5626s
	iters: 800, epoch: 6 | loss: 0.3129562
	speed: 0.0160s/iter; left time: 73.1321s
	iters: 900, epoch: 6 | loss: 0.2885902
	speed: 0.0154s/iter; left time: 69.0662s
	iters: 1000, epoch: 6 | loss: 0.2805223
	speed: 0.0146s/iter; left time: 63.8748s
Epoch: 6 cost time: 16.361936330795288
Epoch: 6, Steps: 1075 | Train Loss: 0.3030493 Vali Loss: 0.4033220 Test Loss: 0.3202746
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2827696
	speed: 0.0914s/iter; left time: 384.0699s
	iters: 200, epoch: 7 | loss: 0.2619527
	speed: 0.0144s/iter; left time: 59.0786s
	iters: 300, epoch: 7 | loss: 0.3630941
	speed: 0.0146s/iter; left time: 58.5587s
	iters: 400, epoch: 7 | loss: 0.3332665
	speed: 0.0173s/iter; left time: 67.5106s
	iters: 500, epoch: 7 | loss: 0.2329414
	speed: 0.0172s/iter; left time: 65.3435s
	iters: 600, epoch: 7 | loss: 0.2983005
	speed: 0.0159s/iter; left time: 58.9083s
	iters: 700, epoch: 7 | loss: 0.3593250
	speed: 0.0146s/iter; left time: 52.6457s
	iters: 800, epoch: 7 | loss: 0.3853687
	speed: 0.0146s/iter; left time: 50.9579s
	iters: 900, epoch: 7 | loss: 0.2325090
	speed: 0.0146s/iter; left time: 49.5375s
	iters: 1000, epoch: 7 | loss: 0.3248108
	speed: 0.0140s/iter; left time: 46.3029s
Epoch: 7 cost time: 16.71449875831604
Epoch: 7, Steps: 1075 | Train Loss: 0.3025594 Vali Loss: 0.4021404 Test Loss: 0.3204451
Validation loss decreased (0.402874 --> 0.402140).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2818947
	speed: 0.0895s/iter; left time: 279.6252s
	iters: 200, epoch: 8 | loss: 0.2763161
	speed: 0.0154s/iter; left time: 46.5540s
	iters: 300, epoch: 8 | loss: 0.3303718
	speed: 0.0161s/iter; left time: 47.0574s
	iters: 400, epoch: 8 | loss: 0.2729903
	speed: 0.0158s/iter; left time: 44.6345s
	iters: 500, epoch: 8 | loss: 0.2902244
	speed: 0.0156s/iter; left time: 42.3975s
	iters: 600, epoch: 8 | loss: 0.3057681
	speed: 0.0145s/iter; left time: 37.9897s
	iters: 700, epoch: 8 | loss: 0.3451900
	speed: 0.0138s/iter; left time: 34.8498s
	iters: 800, epoch: 8 | loss: 0.2688420
	speed: 0.0147s/iter; left time: 35.6910s
	iters: 900, epoch: 8 | loss: 0.3054013
	speed: 0.0148s/iter; left time: 34.3822s
	iters: 1000, epoch: 8 | loss: 0.3094829
	speed: 0.0146s/iter; left time: 32.5106s
Epoch: 8 cost time: 16.552221059799194
Epoch: 8, Steps: 1075 | Train Loss: 0.3023245 Vali Loss: 0.4022071 Test Loss: 0.3195040
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3001426
	speed: 0.0940s/iter; left time: 192.8883s
	iters: 200, epoch: 9 | loss: 0.3287897
	speed: 0.0158s/iter; left time: 30.7590s
	iters: 300, epoch: 9 | loss: 0.2561994
	speed: 0.0136s/iter; left time: 25.1571s
	iters: 400, epoch: 9 | loss: 0.3752078
	speed: 0.0119s/iter; left time: 20.8683s
	iters: 500, epoch: 9 | loss: 0.2351105
	speed: 0.0128s/iter; left time: 21.1841s
	iters: 600, epoch: 9 | loss: 0.3128879
	speed: 0.0137s/iter; left time: 21.2503s
	iters: 700, epoch: 9 | loss: 0.2797875
	speed: 0.0164s/iter; left time: 23.8607s
	iters: 800, epoch: 9 | loss: 0.2730176
	speed: 0.0129s/iter; left time: 17.4227s
	iters: 900, epoch: 9 | loss: 0.2711850
	speed: 0.0139s/iter; left time: 17.3443s
	iters: 1000, epoch: 9 | loss: 0.2890631
	speed: 0.0124s/iter; left time: 14.3095s
Epoch: 9 cost time: 15.381236553192139
Epoch: 9, Steps: 1075 | Train Loss: 0.3019028 Vali Loss: 0.4020655 Test Loss: 0.3196612
Validation loss decreased (0.402140 --> 0.402066).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3216442
	speed: 0.0954s/iter; left time: 93.0704s
	iters: 200, epoch: 10 | loss: 0.3200591
	speed: 0.0115s/iter; left time: 10.1064s
	iters: 300, epoch: 10 | loss: 0.2858737
	speed: 0.0127s/iter; left time: 9.8915s
	iters: 400, epoch: 10 | loss: 0.3395729
	speed: 0.0143s/iter; left time: 9.6705s
	iters: 500, epoch: 10 | loss: 0.2352086
	speed: 0.0137s/iter; left time: 7.8647s
	iters: 600, epoch: 10 | loss: 0.3050588
	speed: 0.0125s/iter; left time: 5.9610s
	iters: 700, epoch: 10 | loss: 0.2767118
	speed: 0.0131s/iter; left time: 4.9100s
	iters: 800, epoch: 10 | loss: 0.3066681
	speed: 0.0141s/iter; left time: 3.8862s
	iters: 900, epoch: 10 | loss: 0.3072556
	speed: 0.0113s/iter; left time: 1.9853s
	iters: 1000, epoch: 10 | loss: 0.3603031
	speed: 0.0123s/iter; left time: 0.9310s
Epoch: 10 cost time: 14.395142316818237
Epoch: 10, Steps: 1075 | Train Loss: 0.3020649 Vali Loss: 0.4049408 Test Loss: 0.3201617
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTm1_96_96_PatchTST_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.320371150970459, mae:0.3605290353298187
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_192        Model:              PatchTST            

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_192_PatchTST_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3684342
	speed: 0.1009s/iter; left time: 260.4423s
	iters: 200, epoch: 1 | loss: 0.3822588
	speed: 0.0779s/iter; left time: 193.2756s
Epoch: 1 cost time: 22.9717378616333
Epoch: 1, Steps: 268 | Train Loss: 0.3877289 Vali Loss: 0.5383564 Test Loss: 0.3784501
Validation loss decreased (inf --> 0.538356).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3617075
	speed: 0.4409s/iter; left time: 1019.8816s
	iters: 200, epoch: 2 | loss: 0.3761376
	speed: 0.0946s/iter; left time: 209.3792s
Epoch: 2 cost time: 23.25048327445984
Epoch: 2, Steps: 268 | Train Loss: 0.3645265 Vali Loss: 0.5290654 Test Loss: 0.3742210
Validation loss decreased (0.538356 --> 0.529065).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3351310
	speed: 0.3876s/iter; left time: 792.5980s
	iters: 200, epoch: 3 | loss: 0.3615293
	speed: 0.0779s/iter; left time: 151.5058s
Epoch: 3 cost time: 20.205530166625977
Epoch: 3, Steps: 268 | Train Loss: 0.3558788 Vali Loss: 0.5245723 Test Loss: 0.3665243
Validation loss decreased (0.529065 --> 0.524572).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3676018
	speed: 0.3987s/iter; left time: 708.4891s
	iters: 200, epoch: 4 | loss: 0.3194094
	speed: 0.0534s/iter; left time: 89.5726s
Epoch: 4 cost time: 16.943567514419556
Epoch: 4, Steps: 268 | Train Loss: 0.3522408 Vali Loss: 0.5231161 Test Loss: 0.3641130
Validation loss decreased (0.524572 --> 0.523116).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3374795
	speed: 0.2538s/iter; left time: 382.9367s
	iters: 200, epoch: 5 | loss: 0.3634438
	speed: 0.0482s/iter; left time: 67.9211s
Epoch: 5 cost time: 13.289565324783325
Epoch: 5, Steps: 268 | Train Loss: 0.3504056 Vali Loss: 0.5233659 Test Loss: 0.3639322
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3240633
	speed: 0.2520s/iter; left time: 312.7740s
	iters: 200, epoch: 6 | loss: 0.3594238
	speed: 0.0483s/iter; left time: 55.0929s
Epoch: 6 cost time: 13.24398922920227
Epoch: 6, Steps: 268 | Train Loss: 0.3493934 Vali Loss: 0.5230407 Test Loss: 0.3630129
Validation loss decreased (0.523116 --> 0.523041).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3518741
	speed: 0.2588s/iter; left time: 251.8206s
	iters: 200, epoch: 7 | loss: 0.3150319
	speed: 0.0478s/iter; left time: 41.7146s
Epoch: 7 cost time: 13.169478178024292
Epoch: 7, Steps: 268 | Train Loss: 0.3489333 Vali Loss: 0.5244796 Test Loss: 0.3633039
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3840518
	speed: 0.2501s/iter; left time: 176.3552s
	iters: 200, epoch: 8 | loss: 0.3545535
	speed: 0.0484s/iter; left time: 29.2613s
Epoch: 8 cost time: 13.182535648345947
Epoch: 8, Steps: 268 | Train Loss: 0.3486863 Vali Loss: 0.5224459 Test Loss: 0.3630942
Validation loss decreased (0.523041 --> 0.522446).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3438774
	speed: 0.2524s/iter; left time: 110.2932s
	iters: 200, epoch: 9 | loss: 0.3487946
	speed: 0.0483s/iter; left time: 16.2610s
Epoch: 9 cost time: 13.27285885810852
Epoch: 9, Steps: 268 | Train Loss: 0.3485810 Vali Loss: 0.5231510 Test Loss: 0.3630995
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3308579
	speed: 0.2557s/iter; left time: 43.2212s
	iters: 200, epoch: 10 | loss: 0.3763812
	speed: 0.0486s/iter; left time: 3.3502s
Epoch: 10 cost time: 13.265281677246094
Epoch: 10, Steps: 268 | Train Loss: 0.3484546 Vali Loss: 0.5232069 Test Loss: 0.3630536
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTm1_96_192_PatchTST_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.36370566487312317, mae:0.3816909193992615
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_336        Model:              PatchTST            

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_336_PatchTST_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4778266
	speed: 0.0474s/iter; left time: 121.9824s
	iters: 200, epoch: 1 | loss: 0.4385105
	speed: 0.0418s/iter; left time: 103.4087s
Epoch: 1 cost time: 11.746821165084839
Epoch: 1, Steps: 267 | Train Loss: 0.4489797 Vali Loss: 0.6793177 Test Loss: 0.4159340
Validation loss decreased (inf --> 0.679318).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4287697
	speed: 0.2363s/iter; left time: 544.3801s
	iters: 200, epoch: 2 | loss: 0.4184125
	speed: 0.0410s/iter; left time: 90.4060s
Epoch: 2 cost time: 11.27788758277893
Epoch: 2, Steps: 267 | Train Loss: 0.4224981 Vali Loss: 0.6773198 Test Loss: 0.4108439
Validation loss decreased (0.679318 --> 0.677320).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4445042
	speed: 0.2387s/iter; left time: 486.3166s
	iters: 200, epoch: 3 | loss: 0.4136829
	speed: 0.0417s/iter; left time: 80.6913s
Epoch: 3 cost time: 11.327040910720825
Epoch: 3, Steps: 267 | Train Loss: 0.4164980 Vali Loss: 0.6734626 Test Loss: 0.4059069
Validation loss decreased (0.677320 --> 0.673463).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3610474
	speed: 0.2350s/iter; left time: 415.9026s
	iters: 200, epoch: 4 | loss: 0.4009499
	speed: 0.0417s/iter; left time: 69.6297s
Epoch: 4 cost time: 11.3334059715271
Epoch: 4, Steps: 267 | Train Loss: 0.4138251 Vali Loss: 0.6731460 Test Loss: 0.4043991
Validation loss decreased (0.673463 --> 0.673146).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3930559
	speed: 0.2400s/iter; left time: 360.6896s
	iters: 200, epoch: 5 | loss: 0.4139814
	speed: 0.0416s/iter; left time: 58.3512s
Epoch: 5 cost time: 11.365149021148682
Epoch: 5, Steps: 267 | Train Loss: 0.4125815 Vali Loss: 0.6721220 Test Loss: 0.4037484
Validation loss decreased (0.673146 --> 0.672122).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4190138
	speed: 0.2382s/iter; left time: 294.3812s
	iters: 200, epoch: 6 | loss: 0.3984960
	speed: 0.0418s/iter; left time: 47.4782s
Epoch: 6 cost time: 11.306128978729248
Epoch: 6, Steps: 267 | Train Loss: 0.4119362 Vali Loss: 0.6714025 Test Loss: 0.4036635
Validation loss decreased (0.672122 --> 0.671402).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4600009
	speed: 0.2408s/iter; left time: 233.3689s
	iters: 200, epoch: 7 | loss: 0.4270504
	speed: 0.0414s/iter; left time: 35.9778s
Epoch: 7 cost time: 11.422556161880493
Epoch: 7, Steps: 267 | Train Loss: 0.4116063 Vali Loss: 0.6710063 Test Loss: 0.4031716
Validation loss decreased (0.671402 --> 0.671006).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3747343
	speed: 0.2557s/iter; left time: 179.5033s
	iters: 200, epoch: 8 | loss: 0.4048515
	speed: 0.0447s/iter; left time: 26.9102s
Epoch: 8 cost time: 12.291116714477539
Epoch: 8, Steps: 267 | Train Loss: 0.4113815 Vali Loss: 0.6710579 Test Loss: 0.4033383
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3976161
	speed: 0.2629s/iter; left time: 114.3805s
	iters: 200, epoch: 9 | loss: 0.3984798
	speed: 0.0451s/iter; left time: 15.0992s
Epoch: 9 cost time: 12.332351446151733
Epoch: 9, Steps: 267 | Train Loss: 0.4112459 Vali Loss: 0.6717281 Test Loss: 0.4033184
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3863375
	speed: 0.2621s/iter; left time: 44.0258s
	iters: 200, epoch: 10 | loss: 0.3854958
	speed: 0.0452s/iter; left time: 3.0707s
Epoch: 10 cost time: 12.685201644897461
Epoch: 10, Steps: 267 | Train Loss: 0.4111969 Vali Loss: 0.6722038 Test Loss: 0.4033060
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_336_PatchTST_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.402490496635437, mae:0.405635267496109
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_720        Model:              PatchTST            

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_720_PatchTST_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5310246
	speed: 0.0549s/iter; left time: 139.6019s
	iters: 200, epoch: 1 | loss: 0.4996797
	speed: 0.0493s/iter; left time: 120.4086s
Epoch: 1 cost time: 13.628024339675903
Epoch: 1, Steps: 264 | Train Loss: 0.5098525 Vali Loss: 0.9982406 Test Loss: 0.4717375
Validation loss decreased (inf --> 0.998241).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4606897
	speed: 0.2520s/iter; left time: 573.8524s
	iters: 200, epoch: 2 | loss: 0.5248585
	speed: 0.0494s/iter; left time: 107.5950s
Epoch: 2 cost time: 13.362069368362427
Epoch: 2, Steps: 264 | Train Loss: 0.4855738 Vali Loss: 0.9928662 Test Loss: 0.4720467
Validation loss decreased (0.998241 --> 0.992866).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5082176
	speed: 0.2622s/iter; left time: 527.8908s
	iters: 200, epoch: 3 | loss: 0.4901214
	speed: 0.0494s/iter; left time: 94.5477s
Epoch: 3 cost time: 13.358429431915283
Epoch: 3, Steps: 264 | Train Loss: 0.4783447 Vali Loss: 0.9880992 Test Loss: 0.4654463
Validation loss decreased (0.992866 --> 0.988099).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4739268
	speed: 0.2564s/iter; left time: 448.5095s
	iters: 200, epoch: 4 | loss: 0.4571628
	speed: 0.0497s/iter; left time: 81.8921s
Epoch: 4 cost time: 13.381447553634644
Epoch: 4, Steps: 264 | Train Loss: 0.4746746 Vali Loss: 0.9847544 Test Loss: 0.4628687
Validation loss decreased (0.988099 --> 0.984754).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4566457
	speed: 0.2622s/iter; left time: 389.3041s
	iters: 200, epoch: 5 | loss: 0.4711023
	speed: 0.0492s/iter; left time: 68.1634s
Epoch: 5 cost time: 13.373777627944946
Epoch: 5, Steps: 264 | Train Loss: 0.4726446 Vali Loss: 0.9875469 Test Loss: 0.4631736
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4975358
	speed: 0.2560s/iter; left time: 312.5331s
	iters: 200, epoch: 6 | loss: 0.4838094
	speed: 0.0492s/iter; left time: 55.1586s
Epoch: 6 cost time: 13.346051454544067
Epoch: 6, Steps: 264 | Train Loss: 0.4716938 Vali Loss: 0.9833549 Test Loss: 0.4617662
Validation loss decreased (0.984754 --> 0.983355).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4750366
	speed: 0.2609s/iter; left time: 249.6800s
	iters: 200, epoch: 7 | loss: 0.4337421
	speed: 0.0492s/iter; left time: 42.1851s
Epoch: 7 cost time: 13.34227442741394
Epoch: 7, Steps: 264 | Train Loss: 0.4713051 Vali Loss: 0.9857726 Test Loss: 0.4619051
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4543657
	speed: 0.2550s/iter; left time: 176.7115s
	iters: 200, epoch: 8 | loss: 0.4820732
	speed: 0.0491s/iter; left time: 29.1162s
Epoch: 8 cost time: 13.279436111450195
Epoch: 8, Steps: 264 | Train Loss: 0.4710090 Vali Loss: 0.9845201 Test Loss: 0.4619079
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.4490122
	speed: 0.2547s/iter; left time: 109.2496s
	iters: 200, epoch: 9 | loss: 0.5000333
	speed: 0.0496s/iter; left time: 16.3140s
Epoch: 9 cost time: 13.341994762420654
Epoch: 9, Steps: 264 | Train Loss: 0.4709155 Vali Loss: 0.9851371 Test Loss: 0.4615864
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_720_PatchTST_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.4612003564834595, mae:0.4416440427303314
