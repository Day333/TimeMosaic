Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_96         Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4240184
	speed: 0.0304s/iter; left time: 323.3547s
	iters: 200, epoch: 1 | loss: 0.4026595
	speed: 0.0195s/iter; left time: 206.2292s
	iters: 300, epoch: 1 | loss: 0.4017851
	speed: 0.0198s/iter; left time: 206.7505s
	iters: 400, epoch: 1 | loss: 0.3208792
	speed: 0.0202s/iter; left time: 208.9886s
	iters: 500, epoch: 1 | loss: 0.3034428
	speed: 0.0196s/iter; left time: 201.3494s
	iters: 600, epoch: 1 | loss: 0.2954772
	speed: 0.0202s/iter; left time: 204.7095s
	iters: 700, epoch: 1 | loss: 0.3175554
	speed: 0.0197s/iter; left time: 197.9944s
	iters: 800, epoch: 1 | loss: 0.3257902
	speed: 0.0193s/iter; left time: 192.4383s
	iters: 900, epoch: 1 | loss: 0.3224327
	speed: 0.0203s/iter; left time: 199.6720s
	iters: 1000, epoch: 1 | loss: 0.3328096
	speed: 0.0195s/iter; left time: 190.2690s
Epoch: 1 cost time: 22.392343521118164
Epoch: 1, Steps: 1075 | Train Loss: 0.3449899 Vali Loss: 0.4140984 Test Loss: 0.3415007
Validation loss decreased (inf --> 0.414098).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3697730
	speed: 0.1191s/iter; left time: 1140.2607s
	iters: 200, epoch: 2 | loss: 0.2545264
	speed: 0.0197s/iter; left time: 186.5182s
	iters: 300, epoch: 2 | loss: 0.3033956
	speed: 0.0195s/iter; left time: 182.6862s
	iters: 400, epoch: 2 | loss: 0.3712268
	speed: 0.0199s/iter; left time: 184.1749s
	iters: 500, epoch: 2 | loss: 0.2536290
	speed: 0.0198s/iter; left time: 181.5913s
	iters: 600, epoch: 2 | loss: 0.3242984
	speed: 0.0198s/iter; left time: 179.9049s
	iters: 700, epoch: 2 | loss: 0.3191077
	speed: 0.0203s/iter; left time: 182.1654s
	iters: 800, epoch: 2 | loss: 0.3219152
	speed: 0.0198s/iter; left time: 175.4282s
	iters: 900, epoch: 2 | loss: 0.2840990
	speed: 0.0199s/iter; left time: 175.0689s
	iters: 1000, epoch: 2 | loss: 0.3146856
	speed: 0.0200s/iter; left time: 173.5525s
Epoch: 2 cost time: 21.753268718719482
Epoch: 2, Steps: 1075 | Train Loss: 0.3177180 Vali Loss: 0.4155931 Test Loss: 0.3351494
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3293908
	speed: 0.1187s/iter; left time: 1009.4522s
	iters: 200, epoch: 3 | loss: 0.2990641
	speed: 0.0193s/iter; left time: 162.1993s
	iters: 300, epoch: 3 | loss: 0.2910550
	speed: 0.0192s/iter; left time: 159.7893s
	iters: 400, epoch: 3 | loss: 0.3513389
	speed: 0.0198s/iter; left time: 162.1323s
	iters: 500, epoch: 3 | loss: 0.2738541
	speed: 0.0196s/iter; left time: 158.6116s
	iters: 600, epoch: 3 | loss: 0.3274806
	speed: 0.0191s/iter; left time: 153.1005s
	iters: 700, epoch: 3 | loss: 0.2842930
	speed: 0.0191s/iter; left time: 150.8037s
	iters: 800, epoch: 3 | loss: 0.2730045
	speed: 0.0191s/iter; left time: 148.6783s
	iters: 900, epoch: 3 | loss: 0.2810061
	speed: 0.0200s/iter; left time: 154.0690s
	iters: 1000, epoch: 3 | loss: 0.2142942
	speed: 0.0204s/iter; left time: 155.2884s
Epoch: 3 cost time: 21.31765341758728
Epoch: 3, Steps: 1075 | Train Loss: 0.3039062 Vali Loss: 0.4076883 Test Loss: 0.3366355
Validation loss decreased (0.414098 --> 0.407688).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3056825
	speed: 0.1256s/iter; left time: 932.5967s
	iters: 200, epoch: 4 | loss: 0.2681996
	speed: 0.0203s/iter; left time: 149.0272s
	iters: 300, epoch: 4 | loss: 0.2738916
	speed: 0.0204s/iter; left time: 147.5450s
	iters: 400, epoch: 4 | loss: 0.2905678
	speed: 0.0209s/iter; left time: 149.0446s
	iters: 500, epoch: 4 | loss: 0.3278469
	speed: 0.0198s/iter; left time: 138.7786s
	iters: 600, epoch: 4 | loss: 0.2471667
	speed: 0.0197s/iter; left time: 136.5818s
	iters: 700, epoch: 4 | loss: 0.3316741
	speed: 0.0208s/iter; left time: 142.1723s
	iters: 800, epoch: 4 | loss: 0.2909915
	speed: 0.0206s/iter; left time: 138.4174s
	iters: 900, epoch: 4 | loss: 0.3406568
	speed: 0.0199s/iter; left time: 132.0938s
	iters: 1000, epoch: 4 | loss: 0.2795976
	speed: 0.0200s/iter; left time: 130.7377s
Epoch: 4 cost time: 22.500763177871704
Epoch: 4, Steps: 1075 | Train Loss: 0.2982600 Vali Loss: 0.4192564 Test Loss: 0.3278850
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3385291
	speed: 0.1248s/iter; left time: 792.6402s
	iters: 200, epoch: 5 | loss: 0.3162630
	speed: 0.0199s/iter; left time: 124.1455s
	iters: 300, epoch: 5 | loss: 0.2522584
	speed: 0.0194s/iter; left time: 119.3217s
	iters: 400, epoch: 5 | loss: 0.3082737
	speed: 0.0212s/iter; left time: 128.0585s
	iters: 500, epoch: 5 | loss: 0.3891307
	speed: 0.0217s/iter; left time: 129.2675s
	iters: 600, epoch: 5 | loss: 0.3190331
	speed: 0.0213s/iter; left time: 124.8457s
	iters: 700, epoch: 5 | loss: 0.3275904
	speed: 0.0216s/iter; left time: 123.9509s
	iters: 800, epoch: 5 | loss: 0.3099623
	speed: 0.0207s/iter; left time: 117.1875s
	iters: 900, epoch: 5 | loss: 0.2867615
	speed: 0.0206s/iter; left time: 114.2261s
	iters: 1000, epoch: 5 | loss: 0.3173688
	speed: 0.0198s/iter; left time: 107.9774s
Epoch: 5 cost time: 22.606892347335815
Epoch: 5, Steps: 1075 | Train Loss: 0.2950283 Vali Loss: 0.4067027 Test Loss: 0.3256667
Validation loss decreased (0.407688 --> 0.406703).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3131419
	speed: 0.1258s/iter; left time: 663.6044s
	iters: 200, epoch: 6 | loss: 0.2530128
	speed: 0.0197s/iter; left time: 102.1699s
	iters: 300, epoch: 6 | loss: 0.3017328
	speed: 0.0200s/iter; left time: 101.6322s
	iters: 400, epoch: 6 | loss: 0.2739682
	speed: 0.0208s/iter; left time: 103.4251s
	iters: 500, epoch: 6 | loss: 0.3144499
	speed: 0.0200s/iter; left time: 97.3172s
	iters: 600, epoch: 6 | loss: 0.3032200
	speed: 0.0203s/iter; left time: 96.8167s
	iters: 700, epoch: 6 | loss: 0.3040562
	speed: 0.0210s/iter; left time: 98.0461s
	iters: 800, epoch: 6 | loss: 0.2917499
	speed: 0.0217s/iter; left time: 99.1031s
	iters: 900, epoch: 6 | loss: 0.2477419
	speed: 0.0207s/iter; left time: 92.6550s
	iters: 1000, epoch: 6 | loss: 0.2661056
	speed: 0.0209s/iter; left time: 91.3009s
Epoch: 6 cost time: 22.487484455108643
Epoch: 6, Steps: 1075 | Train Loss: 0.2936071 Vali Loss: 0.4126195 Test Loss: 0.3254336
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2570252
	speed: 0.1265s/iter; left time: 531.3147s
	iters: 200, epoch: 7 | loss: 0.2311855
	speed: 0.0205s/iter; left time: 84.1137s
	iters: 300, epoch: 7 | loss: 0.3040275
	speed: 0.0206s/iter; left time: 82.4939s
	iters: 400, epoch: 7 | loss: 0.2751664
	speed: 0.0203s/iter; left time: 79.0907s
	iters: 500, epoch: 7 | loss: 0.3310417
	speed: 0.0203s/iter; left time: 76.9950s
	iters: 600, epoch: 7 | loss: 0.3648267
	speed: 0.0209s/iter; left time: 77.2319s
	iters: 700, epoch: 7 | loss: 0.2343250
	speed: 0.0206s/iter; left time: 74.1547s
	iters: 800, epoch: 7 | loss: 0.2816044
	speed: 0.0219s/iter; left time: 76.8467s
	iters: 900, epoch: 7 | loss: 0.3132220
	speed: 0.0213s/iter; left time: 72.2967s
	iters: 1000, epoch: 7 | loss: 0.3045157
	speed: 0.0215s/iter; left time: 71.0427s
Epoch: 7 cost time: 22.87965989112854
Epoch: 7, Steps: 1075 | Train Loss: 0.2926295 Vali Loss: 0.4080394 Test Loss: 0.3275617
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2455546
	speed: 0.1339s/iter; left time: 418.6894s
	iters: 200, epoch: 8 | loss: 0.3692123
	speed: 0.0210s/iter; left time: 63.5469s
	iters: 300, epoch: 8 | loss: 0.3102828
	speed: 0.0208s/iter; left time: 60.9144s
	iters: 400, epoch: 8 | loss: 0.3205975
	speed: 0.0208s/iter; left time: 58.8364s
	iters: 500, epoch: 8 | loss: 0.2408392
	speed: 0.0208s/iter; left time: 56.8012s
	iters: 600, epoch: 8 | loss: 0.2917217
	speed: 0.0218s/iter; left time: 57.1549s
	iters: 700, epoch: 8 | loss: 0.2983876
	speed: 0.0202s/iter; left time: 51.1457s
	iters: 800, epoch: 8 | loss: 0.2192486
	speed: 0.0220s/iter; left time: 53.4269s
	iters: 900, epoch: 8 | loss: 0.3226358
	speed: 0.0202s/iter; left time: 46.9887s
	iters: 1000, epoch: 8 | loss: 0.2013262
	speed: 0.0205s/iter; left time: 45.7422s
Epoch: 8 cost time: 22.87722873687744
Epoch: 8, Steps: 1075 | Train Loss: 0.2923237 Vali Loss: 0.4085376 Test Loss: 0.3259745
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.3263356685638428, mae:0.3649417757987976
================================================================================
Model Profiling Summary
Total Params             : 3,830,129
Inference Time (s)       : 0.009681
GPU Mem Footprint (MB)   : 55.76
Peak Mem (MB)            : 167.89
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_192        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3819508
	speed: 0.2575s/iter; left time: 664.6315s
	iters: 200, epoch: 1 | loss: 0.3720239
	speed: 0.2198s/iter; left time: 545.2111s
Epoch: 1 cost time: 62.97404599189758
Epoch: 1, Steps: 268 | Train Loss: 0.3806961 Vali Loss: 0.5354707 Test Loss: 0.3804531
Validation loss decreased (inf --> 0.535471).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3920687
	speed: 0.6661s/iter; left time: 1540.7248s
	iters: 200, epoch: 2 | loss: 0.3483191
	speed: 0.2508s/iter; left time: 555.0467s
Epoch: 2 cost time: 65.87934970855713
Epoch: 2, Steps: 268 | Train Loss: 0.3573606 Vali Loss: 0.5423499 Test Loss: 0.3822934
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3525268
	speed: 0.6867s/iter; left time: 1404.3666s
	iters: 200, epoch: 3 | loss: 0.3344947
	speed: 0.2091s/iter; left time: 406.6145s
Epoch: 3 cost time: 62.62891125679016
Epoch: 3, Steps: 268 | Train Loss: 0.3458827 Vali Loss: 0.5295461 Test Loss: 0.3752440
Validation loss decreased (0.535471 --> 0.529546).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3266867
	speed: 0.5515s/iter; left time: 979.9447s
	iters: 200, epoch: 4 | loss: 0.3749493
	speed: 0.2225s/iter; left time: 373.1939s
Epoch: 4 cost time: 59.81388568878174
Epoch: 4, Steps: 268 | Train Loss: 0.3400646 Vali Loss: 0.5265017 Test Loss: 0.3795532
Validation loss decreased (0.529546 --> 0.526502).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3246163
	speed: 0.5501s/iter; left time: 830.1629s
	iters: 200, epoch: 5 | loss: 0.3080947
	speed: 0.2674s/iter; left time: 376.8345s
Epoch: 5 cost time: 66.2889564037323
Epoch: 5, Steps: 268 | Train Loss: 0.3369660 Vali Loss: 0.5290534 Test Loss: 0.3769475
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3304050
	speed: 0.5197s/iter; left time: 644.9708s
	iters: 200, epoch: 6 | loss: 0.3550684
	speed: 0.2127s/iter; left time: 242.6841s
Epoch: 6 cost time: 57.527019023895264
Epoch: 6, Steps: 268 | Train Loss: 0.3352384 Vali Loss: 0.5308673 Test Loss: 0.3745141
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3346033
	speed: 0.4642s/iter; left time: 451.6416s
	iters: 200, epoch: 7 | loss: 0.3237152
	speed: 0.1942s/iter; left time: 169.5610s
Epoch: 7 cost time: 51.797680139541626
Epoch: 7, Steps: 268 | Train Loss: 0.3341419 Vali Loss: 0.5265594 Test Loss: 0.3780378
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.3801029324531555, mae:0.39499130845069885
================================================================================
Model Profiling Summary
Total Params             : 10,724,817
Inference Time (s)       : 0.045788
GPU Mem Footprint (MB)   : 112.04
Peak Mem (MB)            : 578.20
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_336        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4636484
	speed: 0.0556s/iter; left time: 142.8359s
	iters: 200, epoch: 1 | loss: 0.4485251
	speed: 0.0493s/iter; left time: 121.6989s
Epoch: 1 cost time: 13.787628650665283
Epoch: 1, Steps: 267 | Train Loss: 0.4392481 Vali Loss: 0.6826608 Test Loss: 0.4144792
Validation loss decreased (inf --> 0.682661).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4044687
	speed: 0.1387s/iter; left time: 319.5890s
	iters: 200, epoch: 2 | loss: 0.4212085
	speed: 0.0502s/iter; left time: 110.5369s
Epoch: 2 cost time: 13.792256116867065
Epoch: 2, Steps: 267 | Train Loss: 0.4174020 Vali Loss: 0.6858440 Test Loss: 0.4147429
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4347922
	speed: 0.1998s/iter; left time: 407.0082s
	iters: 200, epoch: 3 | loss: 0.3995610
	speed: 0.0592s/iter; left time: 114.6797s
Epoch: 3 cost time: 15.797904014587402
Epoch: 3, Steps: 267 | Train Loss: 0.4096965 Vali Loss: 0.6904809 Test Loss: 0.4159282
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3926234
	speed: 0.1623s/iter; left time: 287.3381s
	iters: 200, epoch: 4 | loss: 0.4215987
	speed: 0.0626s/iter; left time: 104.5461s
Epoch: 4 cost time: 17.021183729171753
Epoch: 4, Steps: 267 | Train Loss: 0.4058121 Vali Loss: 0.6784517 Test Loss: 0.4064524
Validation loss decreased (0.682661 --> 0.678452).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4324888
	speed: 0.2128s/iter; left time: 319.8678s
	iters: 200, epoch: 5 | loss: 0.4487578
	speed: 0.0921s/iter; left time: 129.1827s
Epoch: 5 cost time: 22.72359609603882
Epoch: 5, Steps: 267 | Train Loss: 0.4037447 Vali Loss: 0.6736391 Test Loss: 0.4052990
Validation loss decreased (0.678452 --> 0.673639).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4107096
	speed: 0.2457s/iter; left time: 303.7059s
	iters: 200, epoch: 6 | loss: 0.3726263
	speed: 0.0537s/iter; left time: 61.0298s
Epoch: 6 cost time: 14.733289241790771
Epoch: 6, Steps: 267 | Train Loss: 0.4028906 Vali Loss: 0.6740806 Test Loss: 0.4045325
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4018064
	speed: 0.2706s/iter; left time: 262.2198s
	iters: 200, epoch: 7 | loss: 0.3970987
	speed: 0.0621s/iter; left time: 54.0005s
Epoch: 7 cost time: 19.048898696899414
Epoch: 7, Steps: 267 | Train Loss: 0.4022992 Vali Loss: 0.6760137 Test Loss: 0.4044086
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3738894
	speed: 0.1944s/iter; left time: 136.4619s
	iters: 200, epoch: 8 | loss: 0.3889880
	speed: 0.0761s/iter; left time: 45.8360s
Epoch: 8 cost time: 19.74602961540222
Epoch: 8, Steps: 267 | Train Loss: 0.4021023 Vali Loss: 0.6739745 Test Loss: 0.4044611
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.4048076570034027, mae:0.4101831316947937
================================================================================
Model Profiling Summary
Total Params             : 5,302,881
Inference Time (s)       : 0.016173
GPU Mem Footprint (MB)   : 72.50
Peak Mem (MB)            : 508.56
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_720        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5685501
	speed: 0.2269s/iter; left time: 576.6270s
	iters: 200, epoch: 1 | loss: 0.4976951
	speed: 0.2251s/iter; left time: 549.4904s
Epoch: 1 cost time: 59.78933644294739
Epoch: 1, Steps: 264 | Train Loss: 0.4992521 Vali Loss: 0.9985011 Test Loss: 0.4713585
Validation loss decreased (inf --> 0.998501).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4583209
	speed: 0.6114s/iter; left time: 1392.0552s
	iters: 200, epoch: 2 | loss: 0.4823160
	speed: 0.2177s/iter; left time: 473.9987s
Epoch: 2 cost time: 58.14498734474182
Epoch: 2, Steps: 264 | Train Loss: 0.4763388 Vali Loss: 0.9850230 Test Loss: 0.4702739
Validation loss decreased (0.998501 --> 0.985023).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5041738
	speed: 0.6224s/iter; left time: 1252.8639s
	iters: 200, epoch: 3 | loss: 0.4597368
	speed: 0.2239s/iter; left time: 428.3961s
Epoch: 3 cost time: 59.10862064361572
Epoch: 3, Steps: 264 | Train Loss: 0.4648976 Vali Loss: 1.0026596 Test Loss: 0.4658500
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4295304
	speed: 0.6111s/iter; left time: 1068.8066s
	iters: 200, epoch: 4 | loss: 0.4605613
	speed: 0.2080s/iter; left time: 343.0321s
Epoch: 4 cost time: 54.97734570503235
Epoch: 4, Steps: 264 | Train Loss: 0.4584047 Vali Loss: 0.9843453 Test Loss: 0.4628172
Validation loss decreased (0.985023 --> 0.984345).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4125989
	speed: 0.5446s/iter; left time: 808.7239s
	iters: 200, epoch: 5 | loss: 0.4869263
	speed: 0.2077s/iter; left time: 287.7029s
Epoch: 5 cost time: 55.4408962726593
Epoch: 5, Steps: 264 | Train Loss: 0.4551607 Vali Loss: 0.9898997 Test Loss: 0.4662516
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4493771
	speed: 0.5662s/iter; left time: 691.2962s
	iters: 200, epoch: 6 | loss: 0.4450336
	speed: 0.2093s/iter; left time: 234.6634s
Epoch: 6 cost time: 55.297911167144775
Epoch: 6, Steps: 264 | Train Loss: 0.4530418 Vali Loss: 0.9903798 Test Loss: 0.4626221
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5176927
	speed: 0.5654s/iter; left time: 541.0642s
	iters: 200, epoch: 7 | loss: 0.4144007
	speed: 0.2123s/iter; left time: 181.9508s
Epoch: 7 cost time: 55.45229744911194
Epoch: 7, Steps: 264 | Train Loss: 0.4520629 Vali Loss: 0.9864752 Test Loss: 0.4655207
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.4619949460029602, mae:0.44652509689331055
================================================================================
Model Profiling Summary
Total Params             : 13,969,377
Inference Time (s)       : 0.055373
GPU Mem Footprint (MB)   : 144.10
Peak Mem (MB)            : 609.66
================================================================================
