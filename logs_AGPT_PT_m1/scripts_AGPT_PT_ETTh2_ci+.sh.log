Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_96         Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            1                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.4670857
	speed: 0.0801s/iter; left time: 204.2137s
	iters: 200, epoch: 1 | loss: 0.5786312
	speed: 0.0664s/iter; left time: 162.7717s
Epoch: 1 cost time: 18.298095703125
Epoch: 1, Steps: 265 | Train Loss: 0.4629265 Vali Loss: 0.2209138 Test Loss: 0.3036458
Validation loss decreased (inf --> 0.220914).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.6110914
	speed: 0.1558s/iter; left time: 356.2365s
	iters: 200, epoch: 2 | loss: 0.2012696
	speed: 0.0665s/iter; left time: 145.3862s
Epoch: 2 cost time: 17.33042311668396
Epoch: 2, Steps: 265 | Train Loss: 0.4361015 Vali Loss: 0.2326114 Test Loss: 0.2938294
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.4793339
	speed: 0.1669s/iter; left time: 337.2846s
	iters: 200, epoch: 3 | loss: 0.2943490
	speed: 0.0635s/iter; left time: 121.9332s
Epoch: 3 cost time: 17.04163885116577
Epoch: 3, Steps: 265 | Train Loss: 0.4139858 Vali Loss: 0.2180555 Test Loss: 0.2891652
Validation loss decreased (0.220914 --> 0.218055).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.8544593
	speed: 0.1616s/iter; left time: 283.7773s
	iters: 200, epoch: 4 | loss: 0.3924049
	speed: 0.0619s/iter; left time: 102.4697s
Epoch: 4 cost time: 16.688629150390625
Epoch: 4, Steps: 265 | Train Loss: 0.3933799 Vali Loss: 0.2196461 Test Loss: 0.2914392
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 0.3464278
	speed: 0.1660s/iter; left time: 247.4472s
	iters: 200, epoch: 5 | loss: 0.3257815
	speed: 0.0582s/iter; left time: 81.0162s
Epoch: 5 cost time: 16.4203143119812
Epoch: 5, Steps: 265 | Train Loss: 0.3838686 Vali Loss: 0.2200059 Test Loss: 0.2911318
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 6 | loss: 0.2705433
	speed: 0.1634s/iter; left time: 200.3238s
	iters: 200, epoch: 6 | loss: 0.4524253
	speed: 0.0578s/iter; left time: 65.0649s
Epoch: 6 cost time: 15.377904415130615
Epoch: 6, Steps: 265 | Train Loss: 0.3794371 Vali Loss: 0.2313291 Test Loss: 0.2948499
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.2913147211074829, mae:0.3454870581626892, rmse:0.5397357940673828, mape:1.4961445331573486, mspe:409.9728698730469
================================================================================
Model Profiling Summary
Total Params             : 3,830,129
Inference Time (s)       : 0.026063
GPU Mem Footprint (MB)   : 55.78
Peak Mem (MB)            : 197.02
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_192        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            1                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5975576
	speed: 0.0735s/iter; left time: 185.2911s
	iters: 200, epoch: 1 | loss: 0.4098977
	speed: 0.0692s/iter; left time: 167.4933s
Epoch: 1 cost time: 18.02043104171753
Epoch: 1, Steps: 262 | Train Loss: 0.5727098 Vali Loss: 0.2888825 Test Loss: 0.3816763
Validation loss decreased (inf --> 0.288883).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.4712135
	speed: 0.4223s/iter; left time: 954.0869s
	iters: 200, epoch: 2 | loss: 0.5576968
	speed: 0.0702s/iter; left time: 151.4636s
Epoch: 2 cost time: 18.581984996795654
Epoch: 2, Steps: 262 | Train Loss: 0.5518682 Vali Loss: 0.2750107 Test Loss: 0.3803876
Validation loss decreased (0.288883 --> 0.275011).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.7647169
	speed: 0.5113s/iter; left time: 1020.9676s
	iters: 200, epoch: 3 | loss: 0.3242701
	speed: 0.0732s/iter; left time: 138.7961s
Epoch: 3 cost time: 19.666006088256836
Epoch: 3, Steps: 262 | Train Loss: 0.5232865 Vali Loss: 0.2843688 Test Loss: 0.3772530
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.6122851
	speed: 0.4827s/iter; left time: 837.4927s
	iters: 200, epoch: 4 | loss: 0.3888670
	speed: 0.0738s/iter; left time: 120.7404s
Epoch: 4 cost time: 20.742789268493652
Epoch: 4, Steps: 262 | Train Loss: 0.5061695 Vali Loss: 0.2790056 Test Loss: 0.3827699
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 0.4255629
	speed: 0.4701s/iter; left time: 692.4217s
	iters: 200, epoch: 5 | loss: 0.3331408
	speed: 0.0803s/iter; left time: 110.2872s
Epoch: 5 cost time: 21.17233419418335
Epoch: 5, Steps: 262 | Train Loss: 0.4970455 Vali Loss: 0.2816350 Test Loss: 0.3804791
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.37530162930488586, mae:0.39762070775032043, rmse:0.6126186847686768, mape:1.6542004346847534, mspe:435.3733215332031
================================================================================
Model Profiling Summary
Total Params             : 4,420,049
Inference Time (s)       : 0.018121
GPU Mem Footprint (MB)   : 60.56
Peak Mem (MB)            : 201.77
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_336        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            1                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.8800476
	speed: 0.1104s/iter; left time: 272.9009s
	iters: 200, epoch: 1 | loss: 0.7144774
	speed: 0.1068s/iter; left time: 253.2735s
Epoch: 1 cost time: 27.638561248779297
Epoch: 1, Steps: 257 | Train Loss: 0.6775700 Vali Loss: 0.3619135 Test Loss: 0.4291145
Validation loss decreased (inf --> 0.361914).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.7617083
	speed: 0.5803s/iter; left time: 1284.7211s
	iters: 200, epoch: 2 | loss: 0.8999993
	speed: 0.1080s/iter; left time: 228.2603s
Epoch: 2 cost time: 27.574014902114868
Epoch: 2, Steps: 257 | Train Loss: 0.6616654 Vali Loss: 0.3651598 Test Loss: 0.4187956
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.4597088
	speed: 0.6079s/iter; left time: 1189.7194s
	iters: 200, epoch: 3 | loss: 0.3894238
	speed: 0.0974s/iter; left time: 180.8971s
Epoch: 3 cost time: 26.224894523620605
Epoch: 3, Steps: 257 | Train Loss: 0.6345774 Vali Loss: 0.3661674 Test Loss: 0.4282046
EarlyStopping counter: 2 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.5569918
	speed: 0.6184s/iter; left time: 1051.2111s
	iters: 200, epoch: 4 | loss: 0.4791958
	speed: 0.1011s/iter; left time: 161.7278s
Epoch: 4 cost time: 26.2609384059906
Epoch: 4, Steps: 257 | Train Loss: 0.6131219 Vali Loss: 0.3691185 Test Loss: 0.4249715
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.4249989986419678, mae:0.4370793402194977, rmse:0.6519194841384888, mape:1.907942295074463, mspe:563.4243774414062
================================================================================
Model Profiling Summary
Total Params             : 5,302,881
Inference Time (s)       : 0.007354
GPU Mem Footprint (MB)   : 68.08
Peak Mem (MB)            : 209.20
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_720        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            1                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6471243
	speed: 0.1386s/iter; left time: 325.8785s
	iters: 200, epoch: 1 | loss: 1.0480729
	speed: 0.1525s/iter; left time: 343.2416s
Epoch: 1 cost time: 35.83825397491455
Epoch: 1, Steps: 245 | Train Loss: 0.8726908 Vali Loss: 0.6091551 Test Loss: 0.4220800
Validation loss decreased (inf --> 0.609155).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.4701131
	speed: 0.7711s/iter; left time: 1624.0310s
	iters: 200, epoch: 2 | loss: 0.6822789
	speed: 0.1430s/iter; left time: 286.7620s
Epoch: 2 cost time: 35.172929763793945
Epoch: 2, Steps: 245 | Train Loss: 0.8599926 Vali Loss: 0.6094301 Test Loss: 0.4249198
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.7712900
	speed: 0.7581s/iter; left time: 1410.7720s
	iters: 200, epoch: 3 | loss: 0.5734538
	speed: 0.1531s/iter; left time: 269.6601s
Epoch: 3 cost time: 37.969438314437866
Epoch: 3, Steps: 245 | Train Loss: 0.8394109 Vali Loss: 0.6061890 Test Loss: 0.4286638
Validation loss decreased (0.609155 --> 0.606189).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.6521427
	speed: 0.7903s/iter; left time: 1277.0871s
	iters: 200, epoch: 4 | loss: 1.0032178
	speed: 0.1554s/iter; left time: 235.6105s
Epoch: 4 cost time: 38.71804976463318
Epoch: 4, Steps: 245 | Train Loss: 0.8209711 Vali Loss: 0.6138868 Test Loss: 0.4197293
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 0.5184840
	speed: 0.7546s/iter; left time: 1034.6183s
	iters: 200, epoch: 5 | loss: 0.3243744
	speed: 0.1534s/iter; left time: 194.9114s
Epoch: 5 cost time: 37.56168746948242
Epoch: 5, Steps: 245 | Train Loss: 0.8093420 Vali Loss: 0.6094728 Test Loss: 0.4170538
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 6 | loss: 0.6563224
	speed: 0.7230s/iter; left time: 814.0666s
	iters: 200, epoch: 6 | loss: 0.7564081
	speed: 0.1266s/iter; left time: 129.8633s
Epoch: 6 cost time: 32.76871180534363
Epoch: 6, Steps: 245 | Train Loss: 0.8025885 Vali Loss: 0.6037664 Test Loss: 0.4172320
Validation loss decreased (0.606189 --> 0.603766).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 7 | loss: 0.5286471
	speed: 0.6323s/iter; left time: 557.0577s
	iters: 200, epoch: 7 | loss: 0.5518021
	speed: 0.1370s/iter; left time: 107.0321s
Epoch: 7 cost time: 33.51153802871704
Epoch: 7, Steps: 245 | Train Loss: 0.8004384 Vali Loss: 0.6077491 Test Loss: 0.4139955
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 8 | loss: 0.6915491
	speed: 0.5579s/iter; left time: 354.8112s
	iters: 200, epoch: 8 | loss: 0.8003395
	speed: 0.1348s/iter; left time: 72.2544s
Epoch: 8 cost time: 32.47319746017456
Epoch: 8, Steps: 245 | Train Loss: 0.7982820 Vali Loss: 0.6086888 Test Loss: 0.4136966
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 9 | loss: 0.8186216
	speed: 0.4986s/iter; left time: 194.9690s
	iters: 200, epoch: 9 | loss: 0.6728505
	speed: 0.0926s/iter; left time: 26.9360s
Epoch: 9 cost time: 23.254019498825073
Epoch: 9, Steps: 245 | Train Loss: 0.7984749 Vali Loss: 0.6091916 Test Loss: 0.4134321
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001_CI+<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.41535481810569763, mae:0.43708980083465576, rmse:0.644480288028717, mape:1.9362905025482178, mspe:547.3577270507812
================================================================================
Model Profiling Summary
Total Params             : 7,664,609
Inference Time (s)       : 0.017173
GPU Mem Footprint (MB)   : 87.54
Peak Mem (MB)            : 228.61
================================================================================
