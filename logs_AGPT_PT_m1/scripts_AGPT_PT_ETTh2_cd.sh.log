Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_96         Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            1                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.4078884
	speed: 0.0863s/iter; left time: 220.1387s
	iters: 200, epoch: 1 | loss: 0.5909434
	speed: 0.0796s/iter; left time: 195.1773s
Epoch: 1 cost time: 21.091171979904175
Epoch: 1, Steps: 265 | Train Loss: 0.4568208 Vali Loss: 0.2247531 Test Loss: 0.3066154
Validation loss decreased (inf --> 0.224753).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.5726578
	speed: 0.1975s/iter; left time: 451.3908s
	iters: 200, epoch: 2 | loss: 0.4453972
	speed: 0.0774s/iter; left time: 169.1971s
Epoch: 2 cost time: 20.61278986930847
Epoch: 2, Steps: 265 | Train Loss: 0.4697471 Vali Loss: 0.2792085 Test Loss: 0.3746261
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.3063234
	speed: 0.1930s/iter; left time: 390.0973s
	iters: 200, epoch: 3 | loss: 0.2449558
	speed: 0.0809s/iter; left time: 155.3434s
Epoch: 3 cost time: 20.385101795196533
Epoch: 3, Steps: 265 | Train Loss: 0.4364236 Vali Loss: 0.2269601 Test Loss: 0.3211937
EarlyStopping counter: 2 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.2255954
	speed: 0.1951s/iter; left time: 342.5432s
	iters: 200, epoch: 4 | loss: 0.7495713
	speed: 0.0707s/iter; left time: 117.0610s
Epoch: 4 cost time: 20.32610034942627
Epoch: 4, Steps: 265 | Train Loss: 0.3872772 Vali Loss: 0.2219272 Test Loss: 0.2964469
Validation loss decreased (0.224753 --> 0.221927).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 0.2502302
	speed: 0.1882s/iter; left time: 280.6264s
	iters: 200, epoch: 5 | loss: 0.4409041
	speed: 0.0474s/iter; left time: 65.9659s
Epoch: 5 cost time: 15.718654155731201
Epoch: 5, Steps: 265 | Train Loss: 0.3630423 Vali Loss: 0.2378506 Test Loss: 0.3052371
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 6 | loss: 0.5186873
	speed: 0.1838s/iter; left time: 225.3135s
	iters: 200, epoch: 6 | loss: 0.2908411
	speed: 0.0577s/iter; left time: 64.9406s
Epoch: 6 cost time: 16.439613580703735
Epoch: 6, Steps: 265 | Train Loss: 0.3542637 Vali Loss: 0.2301010 Test Loss: 0.3036732
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 7 | loss: 0.4498792
	speed: 0.1661s/iter; left time: 159.6599s
	iters: 200, epoch: 7 | loss: 0.2966285
	speed: 0.0709s/iter; left time: 61.0383s
Epoch: 7 cost time: 18.792651414871216
Epoch: 7, Steps: 265 | Train Loss: 0.3504493 Vali Loss: 0.2295172 Test Loss: 0.3059959
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.29855987429618835, mae:0.34840795397758484, rmse:0.5464063286781311, mape:1.5022640228271484, mspe:437.01025390625
================================================================================
Model Profiling Summary
Total Params             : 10,134,897
Inference Time (s)       : 0.021774
GPU Mem Footprint (MB)   : 103.88
Peak Mem (MB)            : 223.45
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_192        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3988465
	speed: 0.0970s/iter; left time: 244.4254s
	iters: 200, epoch: 1 | loss: 0.6786646
	speed: 0.0909s/iter; left time: 220.1562s
Epoch: 1 cost time: 25.662368059158325
Epoch: 1, Steps: 262 | Train Loss: 0.5727750 Vali Loss: 0.2749959 Test Loss: 0.4046035
Validation loss decreased (inf --> 0.274996).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.6748451
	speed: 0.5777s/iter; left time: 1305.0969s
	iters: 200, epoch: 2 | loss: 0.3674617
	speed: 0.1072s/iter; left time: 231.4813s
Epoch: 2 cost time: 26.99649930000305
Epoch: 2, Steps: 262 | Train Loss: 0.5490832 Vali Loss: 0.2810977 Test Loss: 0.3756706
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.5181693
	speed: 0.5734s/iter; left time: 1145.1257s
	iters: 200, epoch: 3 | loss: 0.6359991
	speed: 0.1018s/iter; left time: 193.1215s
Epoch: 3 cost time: 28.174835681915283
Epoch: 3, Steps: 262 | Train Loss: 0.4956328 Vali Loss: 0.2952671 Test Loss: 0.3949762
EarlyStopping counter: 2 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.2397157
	speed: 0.5427s/iter; left time: 941.5904s
	iters: 200, epoch: 4 | loss: 0.6277698
	speed: 0.0996s/iter; left time: 162.7804s
Epoch: 4 cost time: 24.4394690990448
Epoch: 4, Steps: 262 | Train Loss: 0.4679558 Vali Loss: 0.2892863 Test Loss: 0.3813851
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.3952813148498535, mae:0.40865954756736755, rmse:0.6287140250205994, mape:1.7653207778930664, mspe:537.6187133789062
================================================================================
Model Profiling Summary
Total Params             : 10,724,817
Inference Time (s)       : 0.017765
GPU Mem Footprint (MB)   : 108.63
Peak Mem (MB)            : 228.17
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_336        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.6769923
	speed: 0.1353s/iter; left time: 334.2605s
	iters: 200, epoch: 1 | loss: 0.6506597
	speed: 0.1276s/iter; left time: 302.5396s
Epoch: 1 cost time: 33.019383907318115
Epoch: 1, Steps: 257 | Train Loss: 0.6770342 Vali Loss: 0.3603914 Test Loss: 0.4309807
Validation loss decreased (inf --> 0.360391).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.6929690
	speed: 0.6742s/iter; left time: 1492.6714s
	iters: 200, epoch: 2 | loss: 0.5487468
	speed: 0.1218s/iter; left time: 257.5697s
Epoch: 2 cost time: 31.990659713745117
Epoch: 2, Steps: 257 | Train Loss: 0.6566510 Vali Loss: 0.3642629 Test Loss: 0.4367642
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.5190520
	speed: 0.6616s/iter; left time: 1294.7799s
	iters: 200, epoch: 3 | loss: 0.3846504
	speed: 0.1191s/iter; left time: 221.1939s
Epoch: 3 cost time: 32.3196074962616
Epoch: 3, Steps: 257 | Train Loss: 0.6115442 Vali Loss: 0.3779063 Test Loss: 0.4105856
EarlyStopping counter: 2 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.4621868
	speed: 0.6811s/iter; left time: 1157.8947s
	iters: 200, epoch: 4 | loss: 0.6155809
	speed: 0.1288s/iter; left time: 206.0580s
Epoch: 4 cost time: 36.31771779060364
Epoch: 4, Steps: 257 | Train Loss: 0.5779454 Vali Loss: 0.3823998 Test Loss: 0.4332518
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.42685747146606445, mae:0.43820446729660034, rmse:0.6533433198928833, mape:1.9081401824951172, mspe:575.4215087890625
================================================================================
Model Profiling Summary
Total Params             : 11,607,649
Inference Time (s)       : 0.022363
GPU Mem Footprint (MB)   : 116.18
Peak Mem (MB)            : 235.63
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_720        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 1.2998612
	speed: 0.1962s/iter; left time: 461.2612s
	iters: 200, epoch: 1 | loss: 1.0914665
	speed: 0.1742s/iter; left time: 392.1064s
Epoch: 1 cost time: 45.2095251083374
Epoch: 1, Steps: 245 | Train Loss: 0.8711337 Vali Loss: 0.6071268 Test Loss: 0.4281949
Validation loss decreased (inf --> 0.607127).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 0.8696407
	speed: 0.8361s/iter; left time: 1760.9094s
	iters: 200, epoch: 2 | loss: 0.9811993
	speed: 0.1819s/iter; left time: 364.8884s
Epoch: 2 cost time: 44.81060719490051
Epoch: 2, Steps: 245 | Train Loss: 0.8471402 Vali Loss: 0.6034337 Test Loss: 0.4355726
Validation loss decreased (0.607127 --> 0.603434).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 1.0980929
	speed: 0.8548s/iter; left time: 1590.8120s
	iters: 200, epoch: 3 | loss: 0.8405449
	speed: 0.1833s/iter; left time: 322.8260s
Epoch: 3 cost time: 46.517759799957275
Epoch: 3, Steps: 245 | Train Loss: 0.8026298 Vali Loss: 0.6011371 Test Loss: 0.4463317
Validation loss decreased (0.603434 --> 0.601137).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 0.6929424
	speed: 0.8587s/iter; left time: 1387.7252s
	iters: 200, epoch: 4 | loss: 0.9685026
	speed: 0.1738s/iter; left time: 263.4527s
Epoch: 4 cost time: 44.71720862388611
Epoch: 4, Steps: 245 | Train Loss: 0.7716618 Vali Loss: 0.6200822 Test Loss: 0.4446852
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 0.6546101
	speed: 0.7144s/iter; left time: 979.4788s
	iters: 200, epoch: 5 | loss: 0.8780545
	speed: 0.1346s/iter; left time: 171.0197s
Epoch: 5 cost time: 34.397674798965454
Epoch: 5, Steps: 245 | Train Loss: 0.7494841 Vali Loss: 0.6313545 Test Loss: 0.4448712
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 6 | loss: 0.5406178
	speed: 0.5643s/iter; left time: 635.3940s
	iters: 200, epoch: 6 | loss: 0.7348707
	speed: 0.1325s/iter; left time: 135.9729s
Epoch: 6 cost time: 33.7066171169281
Epoch: 6, Steps: 245 | Train Loss: 0.7403538 Vali Loss: 0.6346368 Test Loss: 0.4501908
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001_CD<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.4435620605945587, mae:0.4512437880039215, rmse:0.6660045385360718, mape:2.0733187198638916, mspe:675.9619750976562
================================================================================
Model Profiling Summary
Total Params             : 13,969,377
Inference Time (s)       : 0.061174
GPU Mem Footprint (MB)   : 135.64
Peak Mem (MB)            : 255.03
================================================================================
