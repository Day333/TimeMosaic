Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           PEMS03              Model:              AGPT_PT             

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS03.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             358                 Dec In:             358                 
  C Out:              358                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_PEMS03_AGPT_PT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15617
val 5135
test 5135
	iters: 100, epoch: 1 | loss: 0.1562297
	speed: 2.1742s/iter; left time: 10416.6967s
	iters: 200, epoch: 1 | loss: 0.2055059
	speed: 2.1430s/iter; left time: 10052.7506s
	iters: 300, epoch: 1 | loss: 0.2292005
	speed: 2.0901s/iter; left time: 9595.6143s
	iters: 400, epoch: 1 | loss: 0.1752476
	speed: 2.4268s/iter; left time: 10898.9369s
Epoch: 1 cost time: 1113.4243943691254
Epoch: 1, Steps: 489 | Train Loss: 0.2517116 Vali Loss: 0.1020460 Test Loss: 0.1021575
Validation loss decreased (inf --> 0.102046).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2598701
	speed: 7.1474s/iter; left time: 30748.0229s
	iters: 200, epoch: 2 | loss: 0.2296098
	speed: 2.4867s/iter; left time: 10449.0649s
	iters: 300, epoch: 2 | loss: 0.2319983
	speed: 2.5078s/iter; left time: 10287.0552s
	iters: 400, epoch: 2 | loss: 0.2108851
	speed: 2.5222s/iter; left time: 10093.8929s
Epoch: 2 cost time: 1197.3145234584808
Epoch: 2, Steps: 489 | Train Loss: 0.2045686 Vali Loss: 0.0990784 Test Loss: 0.1002763
Validation loss decreased (0.102046 --> 0.099078).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2427477
	speed: 5.5867s/iter; left time: 21302.0843s
	iters: 200, epoch: 3 | loss: 0.1888814
	speed: 1.9295s/iter; left time: 7164.2415s
	iters: 300, epoch: 3 | loss: 0.1500802
	speed: 2.3338s/iter; left time: 8431.9046s
	iters: 400, epoch: 3 | loss: 0.1765514
	speed: 2.3901s/iter; left time: 8396.3432s
Epoch: 3 cost time: 1033.520846605301
Epoch: 3, Steps: 489 | Train Loss: 0.1968430 Vali Loss: 0.1439171 Test Loss: 0.1435083
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1947314
	speed: 5.4596s/iter; left time: 18147.8437s
	iters: 200, epoch: 4 | loss: 0.1952783
	speed: 1.8882s/iter; left time: 6087.5525s
	iters: 300, epoch: 4 | loss: 0.1581933
	speed: 1.8905s/iter; left time: 5905.7826s
	iters: 400, epoch: 4 | loss: 0.1975836
	speed: 2.1496s/iter; left time: 6500.4215s
Epoch: 4 cost time: 972.8036980628967
Epoch: 4, Steps: 489 | Train Loss: 0.1946690 Vali Loss: 0.0926994 Test Loss: 0.0939844
Validation loss decreased (0.099078 --> 0.092699).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1983432
	speed: 6.6667s/iter; left time: 18900.0219s
	iters: 200, epoch: 5 | loss: 0.1574342
	speed: 3.1093s/iter; left time: 8503.8751s
	iters: 300, epoch: 5 | loss: 0.2057744
	speed: 3.0705s/iter; left time: 8090.6420s
	iters: 400, epoch: 5 | loss: 0.1493034
	speed: 3.0689s/iter; left time: 7779.7614s
Epoch: 5 cost time: 1469.4084284305573
Epoch: 5, Steps: 489 | Train Loss: 0.1906611 Vali Loss: 0.0877306 Test Loss: 0.0890224
Validation loss decreased (0.092699 --> 0.087731).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2071720
	speed: 8.1289s/iter; left time: 19070.2853s
	iters: 200, epoch: 6 | loss: 0.1472393
	speed: 2.5948s/iter; left time: 5827.8727s
	iters: 300, epoch: 6 | loss: 0.1514963
	speed: 2.0196s/iter; left time: 4334.0130s
	iters: 400, epoch: 6 | loss: 0.1774974
	speed: 1.9722s/iter; left time: 4035.1812s
Epoch: 6 cost time: 1112.4424662590027
Epoch: 6, Steps: 489 | Train Loss: 0.1895167 Vali Loss: 0.0900990 Test Loss: 0.0910194
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1774185
	speed: 6.9931s/iter; left time: 12986.2228s
	iters: 200, epoch: 7 | loss: 0.1924588
	speed: 2.6687s/iter; left time: 4688.8903s
	iters: 300, epoch: 7 | loss: 0.1398026
	speed: 2.5145s/iter; left time: 4166.5117s
	iters: 400, epoch: 7 | loss: 0.1761021
	speed: 2.6866s/iter; left time: 4183.0099s
Epoch: 7 cost time: 1273.6431605815887
Epoch: 7, Steps: 489 | Train Loss: 0.1881731 Vali Loss: 0.0847162 Test Loss: 0.0857088
Validation loss decreased (0.087731 --> 0.084716).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1877484
	speed: 7.4306s/iter; left time: 10165.0340s
	iters: 200, epoch: 8 | loss: 0.2060600
	speed: 2.3901s/iter; left time: 3030.6360s
	iters: 300, epoch: 8 | loss: 0.1642629
	speed: 2.0673s/iter; left time: 2414.6108s
	iters: 400, epoch: 8 | loss: 0.2034891
	speed: 2.3714s/iter; left time: 2532.6702s
Epoch: 8 cost time: 1203.4257621765137
Epoch: 8, Steps: 489 | Train Loss: 0.1873520 Vali Loss: 0.0852678 Test Loss: 0.0867179
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1565252
	speed: 8.1315s/iter; left time: 7147.5854s
	iters: 200, epoch: 9 | loss: 0.2548868
	speed: 2.7432s/iter; left time: 2136.9180s
	iters: 300, epoch: 9 | loss: 0.1843876
	speed: 2.0726s/iter; left time: 1407.2906s
	iters: 400, epoch: 9 | loss: 0.2257789
	speed: 1.8978s/iter; left time: 1098.8101s
Epoch: 9 cost time: 1121.2098939418793
Epoch: 9, Steps: 489 | Train Loss: 0.1870793 Vali Loss: 0.0859724 Test Loss: 0.0873063
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.2018156
	speed: 4.7712s/iter; left time: 1860.7560s
	iters: 200, epoch: 10 | loss: 0.2145583
	speed: 1.4467s/iter; left time: 419.5496s
	iters: 300, epoch: 10 | loss: 0.1769394
	speed: 1.4760s/iter; left time: 280.4416s
	iters: 400, epoch: 10 | loss: 0.2099924
	speed: 1.8917s/iter; left time: 170.2537s
Epoch: 10 cost time: 793.2300915718079
Epoch: 10, Steps: 489 | Train Loss: 0.1867987 Vali Loss: 0.0848090 Test Loss: 0.0861934
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : AGPT_loss_PEMS03_AGPT_PT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5135
test shape: (5135, 12, 358) (5135, 12, 358)
test shape: (5135, 12, 358) (5135, 12, 358)
mse:0.08576403558254242, mae:0.197121724486351
================================================================================
Model Profiling Summary
Total Params             : 706,779
Inference Time (s)       : 0.496932
GPU Mem Footprint (MB)   : 32.10
Peak Mem (MB)            : 1227.89
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           PEMS04              Model:              AGPT_PT             

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS04.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             307                 Dec In:             307                 
  C Out:              307                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_PEMS04_AGPT_PT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10088
val 3291
test 3292
	iters: 100, epoch: 1 | loss: 0.2331204
	speed: 1.6239s/iter; left time: 4970.8671s
	iters: 200, epoch: 1 | loss: 0.2020773
	speed: 1.6304s/iter; left time: 4827.5235s
	iters: 300, epoch: 1 | loss: 0.2011073
	speed: 1.6310s/iter; left time: 4666.3647s
Epoch: 1 cost time: 514.47398853302
Epoch: 1, Steps: 316 | Train Loss: 0.2683904 Vali Loss: 0.1470878 Test Loss: 0.1389935
Validation loss decreased (inf --> 0.147088).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2041370
	speed: 2.8668s/iter; left time: 7869.3903s
	iters: 200, epoch: 2 | loss: 0.2092372
	speed: 1.6309s/iter; left time: 4313.8178s
	iters: 300, epoch: 2 | loss: 0.1884330
	speed: 1.3710s/iter; left time: 3489.1148s
Epoch: 2 cost time: 482.3755202293396
Epoch: 2, Steps: 316 | Train Loss: 0.2129702 Vali Loss: 0.1261907 Test Loss: 0.1206047
Validation loss decreased (0.147088 --> 0.126191).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1762282
	speed: 2.2154s/iter; left time: 5381.1861s
	iters: 200, epoch: 3 | loss: 0.1649654
	speed: 1.2506s/iter; left time: 2912.7241s
	iters: 300, epoch: 3 | loss: 0.1847021
	speed: 1.5720s/iter; left time: 3503.9976s
Epoch: 3 cost time: 432.3879964351654
Epoch: 3, Steps: 316 | Train Loss: 0.2058894 Vali Loss: 0.1167192 Test Loss: 0.1109652
Validation loss decreased (0.126191 --> 0.116719).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2181433
	speed: 2.8661s/iter; left time: 6056.1075s
	iters: 200, epoch: 4 | loss: 0.2257984
	speed: 1.6324s/iter; left time: 3285.9547s
	iters: 300, epoch: 4 | loss: 0.1952414
	speed: 1.6325s/iter; left time: 3122.8915s
Epoch: 4 cost time: 514.8308811187744
Epoch: 4, Steps: 316 | Train Loss: 0.2030806 Vali Loss: 0.1139193 Test Loss: 0.1084166
Validation loss decreased (0.116719 --> 0.113919).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2120679
	speed: 2.8710s/iter; left time: 5159.2499s
	iters: 200, epoch: 5 | loss: 0.2273648
	speed: 1.6314s/iter; left time: 2768.5476s
	iters: 300, epoch: 5 | loss: 0.1862000
	speed: 1.6301s/iter; left time: 2603.2005s
Epoch: 5 cost time: 514.5276207923889
Epoch: 5, Steps: 316 | Train Loss: 0.2018563 Vali Loss: 0.1171978 Test Loss: 0.1118266
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2100143
	speed: 2.7875s/iter; left time: 4128.2688s
	iters: 200, epoch: 6 | loss: 0.1923027
	speed: 1.2506s/iter; left time: 1727.1326s
	iters: 300, epoch: 6 | loss: 0.2025793
	speed: 1.2513s/iter; left time: 1602.8918s
Epoch: 6 cost time: 424.1156711578369
Epoch: 6, Steps: 316 | Train Loss: 0.2011032 Vali Loss: 0.1150664 Test Loss: 0.1100701
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2326315
	speed: 2.3488s/iter; left time: 2736.3306s
	iters: 200, epoch: 7 | loss: 0.1726963
	speed: 1.6265s/iter; left time: 1732.2710s
	iters: 300, epoch: 7 | loss: 0.1824805
	speed: 1.6274s/iter; left time: 1570.4311s
Epoch: 7 cost time: 489.87183356285095
Epoch: 7, Steps: 316 | Train Loss: 0.2005523 Vali Loss: 0.1152425 Test Loss: 0.1097818
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1690938
	speed: 2.8726s/iter; left time: 2438.8173s
	iters: 200, epoch: 8 | loss: 0.2223127
	speed: 1.6315s/iter; left time: 1222.0299s
	iters: 300, epoch: 8 | loss: 0.2202599
	speed: 1.6291s/iter; left time: 1057.2790s
Epoch: 8 cost time: 514.4011380672455
Epoch: 8, Steps: 316 | Train Loss: 0.2004527 Vali Loss: 0.1151176 Test Loss: 0.1094299
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1888984
	speed: 2.8687s/iter; left time: 1529.0169s
	iters: 200, epoch: 9 | loss: 0.1696313
	speed: 1.6312s/iter; left time: 706.2986s
	iters: 300, epoch: 9 | loss: 0.2272631
	speed: 1.6319s/iter; left time: 543.4390s
Epoch: 9 cost time: 511.15013909339905
Epoch: 9, Steps: 316 | Train Loss: 0.2001337 Vali Loss: 0.1147788 Test Loss: 0.1093250
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.2267024
	speed: 2.2365s/iter; left time: 485.3307s
	iters: 200, epoch: 10 | loss: 0.2348010
	speed: 1.2510s/iter; left time: 146.3663s
	iters: 300, epoch: 10 | loss: 0.1938032
	speed: 1.2489s/iter; left time: 21.2305s
Epoch: 10 cost time: 394.7288360595703
Epoch: 10, Steps: 316 | Train Loss: 0.2000850 Vali Loss: 0.1133941 Test Loss: 0.1081014
Validation loss decreased (0.113919 --> 0.113394).  Saving model ...
Updating learning rate to 5.859375e-06
>>>>>>>testing : AGPT_loss_PEMS04_AGPT_PT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3292
test shape: (3292, 12, 307) (3292, 12, 307)
test shape: (3292, 12, 307) (3292, 12, 307)
mse:0.10815785825252533, mae:0.22429277002811432
================================================================================
Model Profiling Summary
Total Params             : 706,677
Inference Time (s)       : 0.334629
GPU Mem Footprint (MB)   : 32.61
Peak Mem (MB)            : 1058.07
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           PEMS07              Model:              AGPT_PT             

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS07.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             883                 Dec In:             883                 
  C Out:              883                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      1                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
Traceback (most recent call last):
  File "/root/daye/AGPT/run.py", line 193, in <module>
    exp = Exp(args)  # set experiments
          ^^^^^^^^^
  File "/root/daye/AGPT/exp/exp_AGPT.py", line 22, in __init__
    super(Exp_AGPT, self).__init__(args)
  File "/root/daye/AGPT/exp/exp_basic.py", line 32, in __init__
    self.model = self._build_model().to(self.device)
                 ^^^^^^^^^^^^^^^^^^^
  File "/root/daye/AGPT/exp/exp_AGPT.py", line 28, in _build_model
    model = nn.DataParallel(model, device_ids=self.args.device_ids)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/Time/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 159, in __init__
    _check_balance(self.device_ids)
  File "/root/anaconda3/envs/Time/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 26, in _check_balance
    dev_props = _get_devices_properties(device_ids)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/Time/lib/python3.11/site-packages/torch/_utils.py", line 762, in _get_devices_properties
    return [_get_device_attr(lambda m: m.get_device_properties(i)) for i in device_ids]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/Time/lib/python3.11/site-packages/torch/_utils.py", line 762, in <listcomp>
    return [_get_device_attr(lambda m: m.get_device_properties(i)) for i in device_ids]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/Time/lib/python3.11/site-packages/torch/_utils.py", line 741, in _get_device_attr
    return get_member(torch.cuda)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/Time/lib/python3.11/site-packages/torch/_utils.py", line 762, in <lambda>
    return [_get_device_attr(lambda m: m.get_device_properties(i)) for i in device_ids]
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/Time/lib/python3.11/site-packages/torch/cuda/__init__.py", line 456, in get_device_properties
    raise AssertionError("Invalid device id")
AssertionError: Invalid device id
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           PEMS08              Model:              AGPT_PT             

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS08.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             170                 Dec In:             170                 
  C Out:              170                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_PEMS08_AGPT_PT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10606
val 3464
test 3465
	iters: 100, epoch: 1 | loss: 0.2093424
	speed: 0.7170s/iter; left time: 2309.3591s
	iters: 200, epoch: 1 | loss: 0.2447030
	speed: 0.7068s/iter; left time: 2206.0078s
	iters: 300, epoch: 1 | loss: 0.2206826
	speed: 0.9221s/iter; left time: 2785.5524s
Epoch: 1 cost time: 264.1357111930847
Epoch: 1, Steps: 332 | Train Loss: 0.2512801 Vali Loss: 0.1392286 Test Loss: 0.1281458
Validation loss decreased (inf --> 0.139229).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2067913
	speed: 1.8518s/iter; left time: 5349.9644s
	iters: 200, epoch: 2 | loss: 0.1902186
	speed: 0.9293s/iter; left time: 2591.7966s
	iters: 300, epoch: 2 | loss: 0.2303810
	speed: 0.9257s/iter; left time: 2489.2879s
Epoch: 2 cost time: 307.2632694244385
Epoch: 2, Steps: 332 | Train Loss: 0.2120508 Vali Loss: 0.1390253 Test Loss: 0.1242566
Validation loss decreased (0.139229 --> 0.139025).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2313232
	speed: 1.8578s/iter; left time: 4750.3313s
	iters: 200, epoch: 3 | loss: 0.1686704
	speed: 0.9231s/iter; left time: 2268.1739s
	iters: 300, epoch: 3 | loss: 0.1820080
	speed: 0.9234s/iter; left time: 2176.5274s
Epoch: 3 cost time: 306.4182176589966
Epoch: 3, Steps: 332 | Train Loss: 0.2015638 Vali Loss: 0.1215575 Test Loss: 0.1122466
Validation loss decreased (0.139025 --> 0.121557).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1896490
	speed: 1.8436s/iter; left time: 4102.0083s
	iters: 200, epoch: 4 | loss: 0.1717944
	speed: 0.9237s/iter; left time: 1962.7979s
	iters: 300, epoch: 4 | loss: 0.2144923
	speed: 0.9222s/iter; left time: 1867.5097s
Epoch: 4 cost time: 306.07081365585327
Epoch: 4, Steps: 332 | Train Loss: 0.1976090 Vali Loss: 0.1173509 Test Loss: 0.1078348
Validation loss decreased (0.121557 --> 0.117351).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1883968
	speed: 1.8565s/iter; left time: 3514.2848s
	iters: 200, epoch: 5 | loss: 0.2122257
	speed: 0.9245s/iter; left time: 1657.7091s
	iters: 300, epoch: 5 | loss: 0.2041269
	speed: 0.9250s/iter; left time: 1565.9832s
Epoch: 5 cost time: 322.7499432563782
Epoch: 5, Steps: 332 | Train Loss: 0.1958879 Vali Loss: 0.1140468 Test Loss: 0.1043573
Validation loss decreased (0.117351 --> 0.114047).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1779234
	speed: 2.3959s/iter; left time: 3739.9388s
	iters: 200, epoch: 6 | loss: 0.1929834
	speed: 1.1428s/iter; left time: 1669.6129s
	iters: 300, epoch: 6 | loss: 0.1966197
	speed: 1.1452s/iter; left time: 1558.5564s
Epoch: 6 cost time: 379.09891724586487
Epoch: 6, Steps: 332 | Train Loss: 0.1949283 Vali Loss: 0.1143010 Test Loss: 0.1044096
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2169531
	speed: 2.6753s/iter; left time: 3287.9858s
	iters: 200, epoch: 7 | loss: 0.1814736
	speed: 1.4750s/iter; left time: 1665.2861s
	iters: 300, epoch: 7 | loss: 0.2175141
	speed: 1.4687s/iter; left time: 1511.2995s
Epoch: 7 cost time: 486.91669940948486
Epoch: 7, Steps: 332 | Train Loss: 0.1944297 Vali Loss: 0.1159126 Test Loss: 0.1066771
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1867110
	speed: 2.8603s/iter; left time: 2565.6729s
	iters: 200, epoch: 8 | loss: 0.2062198
	speed: 1.3739s/iter; left time: 1095.0208s
	iters: 300, epoch: 8 | loss: 0.1922908
	speed: 1.1193s/iter; left time: 780.1700s
Epoch: 8 cost time: 430.8455379009247
Epoch: 8, Steps: 332 | Train Loss: 0.1940606 Vali Loss: 0.1168454 Test Loss: 0.1076521
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1812312
	speed: 2.3303s/iter; left time: 1316.6053s
	iters: 200, epoch: 9 | loss: 0.1736199
	speed: 1.4711s/iter; left time: 684.0478s
	iters: 300, epoch: 9 | loss: 0.2275903
	speed: 1.4718s/iter; left time: 537.1972s
Epoch: 9 cost time: 461.3428084850311
Epoch: 9, Steps: 332 | Train Loss: 0.1939616 Vali Loss: 0.1151225 Test Loss: 0.1052464
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1756344
	speed: 2.8530s/iter; left time: 664.7518s
	iters: 200, epoch: 10 | loss: 0.1842834
	speed: 1.3407s/iter; left time: 178.3121s
	iters: 300, epoch: 10 | loss: 0.1960988
	speed: 1.1356s/iter; left time: 37.4757s
Epoch: 10 cost time: 430.05957102775574
Epoch: 10, Steps: 332 | Train Loss: 0.1935973 Vali Loss: 0.1139676 Test Loss: 0.1045303
Validation loss decreased (0.114047 --> 0.113968).  Saving model ...
Updating learning rate to 5.859375e-06
>>>>>>>testing : AGPT_loss_PEMS08_AGPT_PT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3465
test shape: (3465, 12, 170) (3465, 12, 170)
test shape: (3465, 12, 170) (3465, 12, 170)
mse:0.10474183410406113, mae:0.22465641796588898
================================================================================
Model Profiling Summary
Total Params             : 706,403
Inference Time (s)       : 0.158494
GPU Mem Footprint (MB)   : 27.48
Peak Mem (MB)            : 595.38
================================================================================
