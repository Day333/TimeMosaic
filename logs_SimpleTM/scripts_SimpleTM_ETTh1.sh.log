Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_96         Model:              SimpleTM            

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_96_SimpleTM_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3927101
	speed: 0.0493s/iter; left time: 125.6890s
	iters: 200, epoch: 1 | loss: 0.3841783
	speed: 0.0344s/iter; left time: 84.2656s
Epoch: 1 cost time: 11.165678262710571
Epoch: 1, Steps: 265 | Train Loss: 0.3912354 Vali Loss: 0.6934807 Test Loss: 0.3886394
Validation loss decreased (inf --> 0.693481).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3610483
	speed: 0.1113s/iter; left time: 254.4651s
	iters: 200, epoch: 2 | loss: 0.3136709
	speed: 0.0315s/iter; left time: 68.8151s
Epoch: 2 cost time: 9.002640008926392
Epoch: 2, Steps: 265 | Train Loss: 0.3569218 Vali Loss: 0.6902125 Test Loss: 0.3833095
Validation loss decreased (0.693481 --> 0.690212).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4262400
	speed: 0.1157s/iter; left time: 233.7496s
	iters: 200, epoch: 3 | loss: 0.3029223
	speed: 0.0329s/iter; left time: 63.1148s
Epoch: 3 cost time: 9.920446872711182
Epoch: 3, Steps: 265 | Train Loss: 0.3459490 Vali Loss: 0.7229187 Test Loss: 0.3785356
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3323106
	speed: 0.1186s/iter; left time: 208.2824s
	iters: 200, epoch: 4 | loss: 0.3282311
	speed: 0.0273s/iter; left time: 45.1772s
Epoch: 4 cost time: 8.854172229766846
Epoch: 4, Steps: 265 | Train Loss: 0.3418340 Vali Loss: 0.6761582 Test Loss: 0.3795864
Validation loss decreased (0.690212 --> 0.676158).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2627273
	speed: 0.1096s/iter; left time: 163.4184s
	iters: 200, epoch: 5 | loss: 0.3570523
	speed: 0.0291s/iter; left time: 40.4514s
Epoch: 5 cost time: 8.701664686203003
Epoch: 5, Steps: 265 | Train Loss: 0.3395167 Vali Loss: 0.6800376 Test Loss: 0.3775904
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3372712
	speed: 0.1098s/iter; left time: 134.6407s
	iters: 200, epoch: 6 | loss: 0.3410834
	speed: 0.0367s/iter; left time: 41.3776s
Epoch: 6 cost time: 10.324710369110107
Epoch: 6, Steps: 265 | Train Loss: 0.3376816 Vali Loss: 0.6789512 Test Loss: 0.3771570
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3117151
	speed: 0.1083s/iter; left time: 104.0715s
	iters: 200, epoch: 7 | loss: 0.3275821
	speed: 0.0444s/iter; left time: 38.1981s
Epoch: 7 cost time: 10.764254331588745
Epoch: 7, Steps: 265 | Train Loss: 0.3376937 Vali Loss: 0.6820535 Test Loss: 0.3772767
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTh1_96_96_SimpleTM_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.3791355788707733, mae:0.39586272835731506, rmse:0.6157398819923401, mape:10.005880355834961, mspe:49622.5703125
================================================================================
Model Profiling Summary
Total Params             : 3,252,376
Inference Time (s)       : 0.009077
GPU Mem Footprint (MB)   : 41.61
Peak Mem (MB)            : 819.30
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_192        Model:              SimpleTM            

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            8                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_192_SimpleTM_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3830442
	speed: 0.0880s/iter; left time: 221.8660s
	iters: 200, epoch: 1 | loss: 0.4123453
	speed: 0.0722s/iter; left time: 174.6904s
Epoch: 1 cost time: 21.162600994110107
Epoch: 1, Steps: 262 | Train Loss: 0.4606382 Vali Loss: 0.9997274 Test Loss: 0.4440500
Validation loss decreased (inf --> 0.999727).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4344345
	speed: 0.7073s/iter; left time: 1597.7382s
	iters: 200, epoch: 2 | loss: 0.3915689
	speed: 0.0743s/iter; left time: 160.3449s
Epoch: 2 cost time: 20.522232055664062
Epoch: 2, Steps: 262 | Train Loss: 0.4231041 Vali Loss: 1.0178155 Test Loss: 0.4379696
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3661706
	speed: 0.7534s/iter; left time: 1504.5562s
	iters: 200, epoch: 3 | loss: 0.3196459
	speed: 0.0859s/iter; left time: 162.9705s
Epoch: 3 cost time: 22.937975883483887
Epoch: 3, Steps: 262 | Train Loss: 0.4111779 Vali Loss: 0.9954458 Test Loss: 0.4358046
Validation loss decreased (0.999727 --> 0.995446).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3803431
	speed: 0.7754s/iter; left time: 1345.2694s
	iters: 200, epoch: 4 | loss: 0.4131989
	speed: 0.0873s/iter; left time: 142.7482s
Epoch: 4 cost time: 23.587169647216797
Epoch: 4, Steps: 262 | Train Loss: 0.4070747 Vali Loss: 0.9891693 Test Loss: 0.4329293
Validation loss decreased (0.995446 --> 0.989169).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3370144
	speed: 0.7752s/iter; left time: 1141.8225s
	iters: 200, epoch: 5 | loss: 0.4531871
	speed: 0.0885s/iter; left time: 121.4823s
Epoch: 5 cost time: 24.89493465423584
Epoch: 5, Steps: 262 | Train Loss: 0.4049729 Vali Loss: 0.9974833 Test Loss: 0.4307587
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4456033
	speed: 0.7650s/iter; left time: 926.3716s
	iters: 200, epoch: 6 | loss: 0.4968793
	speed: 0.0829s/iter; left time: 92.1375s
Epoch: 6 cost time: 22.163792610168457
Epoch: 6, Steps: 262 | Train Loss: 0.4016329 Vali Loss: 0.9911869 Test Loss: 0.4309057
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4196372
	speed: 0.6276s/iter; left time: 595.5738s
	iters: 200, epoch: 7 | loss: 0.3885117
	speed: 0.0690s/iter; left time: 58.5732s
Epoch: 7 cost time: 18.695739269256592
Epoch: 7, Steps: 262 | Train Loss: 0.4017730 Vali Loss: 0.9937279 Test Loss: 0.4307811
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTh1_96_192_SimpleTM_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.4322793781757355, mae:0.42487388849258423, rmse:0.6574795842170715, mape:10.094078063964844, mspe:43805.51171875
================================================================================
Model Profiling Summary
Total Params             : 3,301,624
Inference Time (s)       : 0.018197
GPU Mem Footprint (MB)   : 42.28
Peak Mem (MB)            : 819.89
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_336        Model:              SimpleTM            

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            8                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_336_SimpleTM_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.4856957
	speed: 0.1211s/iter; left time: 299.2518s
	iters: 200, epoch: 1 | loss: 0.4924855
	speed: 0.1131s/iter; left time: 268.2042s
Epoch: 1 cost time: 30.381048679351807
Epoch: 1, Steps: 257 | Train Loss: 0.5258985 Vali Loss: 1.2905816 Test Loss: 0.4832265
Validation loss decreased (inf --> 1.290582).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4777189
	speed: 0.8023s/iter; left time: 1776.3251s
	iters: 200, epoch: 2 | loss: 0.4887128
	speed: 0.1220s/iter; left time: 257.8482s
Epoch: 2 cost time: 32.34813666343689
Epoch: 2, Steps: 257 | Train Loss: 0.4895485 Vali Loss: 1.2894469 Test Loss: 0.4867076
Validation loss decreased (1.290582 --> 1.289447).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4644144
	speed: 0.7820s/iter; left time: 1530.2928s
	iters: 200, epoch: 3 | loss: 0.4525275
	speed: 0.1269s/iter; left time: 235.6846s
Epoch: 3 cost time: 33.27537202835083
Epoch: 3, Steps: 257 | Train Loss: 0.4758520 Vali Loss: 1.2878170 Test Loss: 0.4793786
Validation loss decreased (1.289447 --> 1.287817).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4477333
	speed: 0.8050s/iter; left time: 1368.5716s
	iters: 200, epoch: 4 | loss: 0.4210836
	speed: 0.1365s/iter; left time: 218.3559s
Epoch: 4 cost time: 34.70088744163513
Epoch: 4, Steps: 257 | Train Loss: 0.4693688 Vali Loss: 1.2877405 Test Loss: 0.4794382
Validation loss decreased (1.287817 --> 1.287740).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4635384
	speed: 0.7915s/iter; left time: 1142.1579s
	iters: 200, epoch: 5 | loss: 0.4201156
	speed: 0.1268s/iter; left time: 170.3183s
Epoch: 5 cost time: 33.54438757896423
Epoch: 5, Steps: 257 | Train Loss: 0.4663647 Vali Loss: 1.2863830 Test Loss: 0.4767904
Validation loss decreased (1.287740 --> 1.286383).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5271346
	speed: 0.7952s/iter; left time: 943.0956s
	iters: 200, epoch: 6 | loss: 0.5260214
	speed: 0.1250s/iter; left time: 135.8011s
Epoch: 6 cost time: 31.746906518936157
Epoch: 6, Steps: 257 | Train Loss: 0.4647183 Vali Loss: 1.2865525 Test Loss: 0.4778307
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5034338
	speed: 0.8243s/iter; left time: 765.7367s
	iters: 200, epoch: 7 | loss: 0.4828998
	speed: 0.1270s/iter; left time: 105.2551s
Epoch: 7 cost time: 33.067835092544556
Epoch: 7, Steps: 257 | Train Loss: 0.4632093 Vali Loss: 1.2887008 Test Loss: 0.4774370
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5198874
	speed: 0.7571s/iter; left time: 508.7588s
	iters: 200, epoch: 8 | loss: 0.5006850
	speed: 0.1145s/iter; left time: 65.4804s
Epoch: 8 cost time: 30.17503547668457
Epoch: 8, Steps: 257 | Train Loss: 0.4630193 Vali Loss: 1.2881870 Test Loss: 0.4774501
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTh1_96_336_SimpleTM_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.4758952856063843, mae:0.44791004061698914, rmse:0.6898516416549683, mape:10.29347038269043, mspe:45597.265625
================================================================================
Model Profiling Summary
Total Params             : 3,375,496
Inference Time (s)       : 0.045818
GPU Mem Footprint (MB)   : 43.61
Peak Mem (MB)            : 821.10
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_720        Model:              SimpleTM            

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_720_SimpleTM_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.5870880
	speed: 0.1332s/iter; left time: 313.1795s
	iters: 200, epoch: 1 | loss: 0.5923859
	speed: 0.1265s/iter; left time: 284.6706s
Epoch: 1 cost time: 31.368887901306152
Epoch: 1, Steps: 245 | Train Loss: 0.6520078 Vali Loss: 1.5732260 Test Loss: 0.4961146
Validation loss decreased (inf --> 1.573226).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5856759
	speed: 0.6137s/iter; left time: 1292.3584s
	iters: 200, epoch: 2 | loss: 0.5376774
	speed: 0.1263s/iter; left time: 253.3297s
Epoch: 2 cost time: 30.972344636917114
Epoch: 2, Steps: 245 | Train Loss: 0.6106393 Vali Loss: 1.5770094 Test Loss: 0.4929330
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5632204
	speed: 0.6357s/iter; left time: 1182.9964s
	iters: 200, epoch: 3 | loss: 0.5242201
	speed: 0.1139s/iter; left time: 200.5661s
Epoch: 3 cost time: 28.30460810661316
Epoch: 3, Steps: 245 | Train Loss: 0.5934905 Vali Loss: 1.5723935 Test Loss: 0.4858828
Validation loss decreased (1.573226 --> 1.572394).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5251240
	speed: 0.6079s/iter; left time: 982.4426s
	iters: 200, epoch: 4 | loss: 0.5412058
	speed: 0.1223s/iter; left time: 185.3896s
Epoch: 4 cost time: 30.324532747268677
Epoch: 4, Steps: 245 | Train Loss: 0.5839224 Vali Loss: 1.5721960 Test Loss: 0.4777121
Validation loss decreased (1.572394 --> 1.572196).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5546933
	speed: 0.6491s/iter; left time: 889.9371s
	iters: 200, epoch: 5 | loss: 0.5456352
	speed: 0.1234s/iter; left time: 156.8791s
Epoch: 5 cost time: 30.803038358688354
Epoch: 5, Steps: 245 | Train Loss: 0.5788418 Vali Loss: 1.5676823 Test Loss: 0.4814678
Validation loss decreased (1.572196 --> 1.567682).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5491950
	speed: 0.6903s/iter; left time: 777.2323s
	iters: 200, epoch: 6 | loss: 0.4939452
	speed: 0.1318s/iter; left time: 135.2683s
Epoch: 6 cost time: 32.21300745010376
Epoch: 6, Steps: 245 | Train Loss: 0.5779878 Vali Loss: 1.5675526 Test Loss: 0.4828936
Validation loss decreased (1.567682 --> 1.567553).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5910832
	speed: 0.6970s/iter; left time: 614.0537s
	iters: 200, epoch: 7 | loss: 0.6906437
	speed: 0.1299s/iter; left time: 101.4210s
Epoch: 7 cost time: 31.99704623222351
Epoch: 7, Steps: 245 | Train Loss: 0.5762911 Vali Loss: 1.5662538 Test Loss: 0.4829227
Validation loss decreased (1.567553 --> 1.566254).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5280042
	speed: 0.6135s/iter; left time: 390.1854s
	iters: 200, epoch: 8 | loss: 0.6025830
	speed: 0.1088s/iter; left time: 58.3189s
Epoch: 8 cost time: 28.103792905807495
Epoch: 8, Steps: 245 | Train Loss: 0.5758689 Vali Loss: 1.5686965 Test Loss: 0.4826028
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5897715
	speed: 0.5558s/iter; left time: 217.3277s
	iters: 200, epoch: 9 | loss: 0.5794340
	speed: 0.1049s/iter; left time: 30.5153s
Epoch: 9 cost time: 26.721972465515137
Epoch: 9, Steps: 245 | Train Loss: 0.5757291 Vali Loss: 1.5660287 Test Loss: 0.4823375
Validation loss decreased (1.566254 --> 1.566029).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5314719
	speed: 0.5861s/iter; left time: 85.5768s
	iters: 200, epoch: 10 | loss: 0.5460364
	speed: 0.1189s/iter; left time: 5.4686s
Epoch: 10 cost time: 29.90313172340393
Epoch: 10, Steps: 245 | Train Loss: 0.5751392 Vali Loss: 1.5684603 Test Loss: 0.4822167
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTh1_96_720_SimpleTM_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.4812254309654236, mae:0.472705215215683, rmse:0.6937041282653809, mape:11.358416557312012, mspe:52027.51953125
================================================================================
Model Profiling Summary
Total Params             : 3,572,488
Inference Time (s)       : 0.009027
GPU Mem Footprint (MB)   : 46.56
Peak Mem (MB)            : 823.72
================================================================================
