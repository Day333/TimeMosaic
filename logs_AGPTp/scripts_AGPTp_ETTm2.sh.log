Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_96         Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_96_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2498828
	speed: 0.0513s/iter; left time: 546.8332s
	iters: 200, epoch: 1 | loss: 0.1134194
	speed: 0.0411s/iter; left time: 434.1318s
	iters: 300, epoch: 1 | loss: 0.1337204
	speed: 0.0330s/iter; left time: 345.2179s
	iters: 400, epoch: 1 | loss: 0.1409790
	speed: 0.0329s/iter; left time: 340.3460s
	iters: 500, epoch: 1 | loss: 0.2062173
	speed: 0.0440s/iter; left time: 450.9881s
	iters: 600, epoch: 1 | loss: 0.1344045
	speed: 0.0753s/iter; left time: 764.3021s
	iters: 700, epoch: 1 | loss: 0.1097185
	speed: 0.0749s/iter; left time: 753.1898s
	iters: 800, epoch: 1 | loss: 0.1320396
	speed: 0.0698s/iter; left time: 694.9001s
	iters: 900, epoch: 1 | loss: 0.1863615
	speed: 0.0751s/iter; left time: 739.5098s
	iters: 1000, epoch: 1 | loss: 0.1310060
	speed: 0.0754s/iter; left time: 735.7072s
Epoch: 1 cost time: 63.31962966918945
Epoch: 1, Steps: 1075 | Train Loss: 0.2360164 Vali Loss: 0.1282500 Test Loss: 0.1777347
Validation loss decreased (inf --> 0.128250).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3025951
	speed: 0.4539s/iter; left time: 4346.4976s
	iters: 200, epoch: 2 | loss: 0.2750312
	speed: 0.0652s/iter; left time: 617.9209s
	iters: 300, epoch: 2 | loss: 0.2204848
	speed: 0.0759s/iter; left time: 711.8468s
	iters: 400, epoch: 2 | loss: 0.1981913
	speed: 0.0760s/iter; left time: 704.9616s
	iters: 500, epoch: 2 | loss: 0.2360586
	speed: 0.0748s/iter; left time: 686.7515s
	iters: 600, epoch: 2 | loss: 0.2341601
	speed: 0.0668s/iter; left time: 606.5624s
	iters: 700, epoch: 2 | loss: 0.1787134
	speed: 0.0719s/iter; left time: 644.9573s
	iters: 800, epoch: 2 | loss: 0.2679144
	speed: 0.0706s/iter; left time: 627.0319s
	iters: 900, epoch: 2 | loss: 0.3112289
	speed: 0.0742s/iter; left time: 650.9401s
	iters: 1000, epoch: 2 | loss: 0.1462272
	speed: 0.0677s/iter; left time: 586.9391s
Epoch: 2 cost time: 76.07857179641724
Epoch: 2, Steps: 1075 | Train Loss: 0.2241460 Vali Loss: 0.1318421 Test Loss: 0.1819895
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2441678
	speed: 0.4003s/iter; left time: 3402.7272s
	iters: 200, epoch: 3 | loss: 0.1646316
	speed: 0.0642s/iter; left time: 539.7259s
	iters: 300, epoch: 3 | loss: 0.2676089
	speed: 0.0779s/iter; left time: 646.4882s
	iters: 400, epoch: 3 | loss: 0.0917571
	speed: 0.0788s/iter; left time: 646.5675s
	iters: 500, epoch: 3 | loss: 0.1622675
	speed: 0.0663s/iter; left time: 537.4206s
	iters: 600, epoch: 3 | loss: 0.1846088
	speed: 0.0606s/iter; left time: 484.5667s
	iters: 700, epoch: 3 | loss: 0.1036916
	speed: 0.0678s/iter; left time: 535.5857s
	iters: 800, epoch: 3 | loss: 0.2064543
	speed: 0.0654s/iter; left time: 510.0483s
	iters: 900, epoch: 3 | loss: 0.3019111
	speed: 0.0679s/iter; left time: 523.2139s
	iters: 1000, epoch: 3 | loss: 0.3101267
	speed: 0.0743s/iter; left time: 565.0212s
Epoch: 3 cost time: 73.76228404045105
Epoch: 3, Steps: 1075 | Train Loss: 0.2140270 Vali Loss: 0.1276295 Test Loss: 0.1786778
Validation loss decreased (0.128250 --> 0.127630).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1953744
	speed: 0.4348s/iter; left time: 3229.1270s
	iters: 200, epoch: 4 | loss: 0.2662649
	speed: 0.0663s/iter; left time: 485.7000s
	iters: 300, epoch: 4 | loss: 0.1814088
	speed: 0.0712s/iter; left time: 514.2828s
	iters: 400, epoch: 4 | loss: 0.3537342
	speed: 0.0737s/iter; left time: 525.5160s
	iters: 500, epoch: 4 | loss: 0.1728289
	speed: 0.0773s/iter; left time: 543.4209s
	iters: 600, epoch: 4 | loss: 0.1403174
	speed: 0.0692s/iter; left time: 479.1133s
	iters: 700, epoch: 4 | loss: 0.1557968
	speed: 0.0645s/iter; left time: 440.0971s
	iters: 800, epoch: 4 | loss: 0.1982931
	speed: 0.0737s/iter; left time: 495.4369s
	iters: 900, epoch: 4 | loss: 0.2015423
	speed: 0.0768s/iter; left time: 508.5506s
	iters: 1000, epoch: 4 | loss: 0.1191990
	speed: 0.0744s/iter; left time: 485.2583s
Epoch: 4 cost time: 76.60341453552246
Epoch: 4, Steps: 1075 | Train Loss: 0.2063256 Vali Loss: 0.1300175 Test Loss: 0.1820158
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2225381
	speed: 0.3950s/iter; left time: 2508.8276s
	iters: 200, epoch: 5 | loss: 0.1942230
	speed: 0.0784s/iter; left time: 490.3555s
	iters: 300, epoch: 5 | loss: 0.1353803
	speed: 0.0677s/iter; left time: 416.5943s
	iters: 400, epoch: 5 | loss: 0.1452329
	speed: 0.0717s/iter; left time: 433.5824s
	iters: 500, epoch: 5 | loss: 0.1372697
	speed: 0.0723s/iter; left time: 430.3125s
	iters: 600, epoch: 5 | loss: 0.3361254
	speed: 0.0722s/iter; left time: 422.4294s
	iters: 700, epoch: 5 | loss: 0.1738004
	speed: 0.0679s/iter; left time: 390.2259s
	iters: 800, epoch: 5 | loss: 0.1076308
	speed: 0.0728s/iter; left time: 411.1438s
	iters: 900, epoch: 5 | loss: 0.1372532
	speed: 0.0786s/iter; left time: 436.2482s
	iters: 1000, epoch: 5 | loss: 0.1630196
	speed: 0.0734s/iter; left time: 400.1092s
Epoch: 5 cost time: 79.15970420837402
Epoch: 5, Steps: 1075 | Train Loss: 0.2008210 Vali Loss: 0.1311070 Test Loss: 0.1840263
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1197860
	speed: 0.4588s/iter; left time: 2420.6465s
	iters: 200, epoch: 6 | loss: 0.1327972
	speed: 0.0782s/iter; left time: 404.5467s
	iters: 300, epoch: 6 | loss: 0.2407098
	speed: 0.0811s/iter; left time: 411.8366s
	iters: 400, epoch: 6 | loss: 0.1770853
	speed: 0.0714s/iter; left time: 355.1752s
	iters: 500, epoch: 6 | loss: 0.1069538
	speed: 0.0589s/iter; left time: 287.1101s
	iters: 600, epoch: 6 | loss: 0.3855856
	speed: 0.0580s/iter; left time: 276.7831s
	iters: 700, epoch: 6 | loss: 0.1599904
	speed: 0.0668s/iter; left time: 312.5692s
	iters: 800, epoch: 6 | loss: 0.2481647
	speed: 0.0627s/iter; left time: 286.7112s
	iters: 900, epoch: 6 | loss: 0.1420266
	speed: 0.0565s/iter; left time: 252.7478s
	iters: 1000, epoch: 6 | loss: 0.2446321
	speed: 0.0576s/iter; left time: 252.2214s
Epoch: 6 cost time: 70.76050186157227
Epoch: 6, Steps: 1075 | Train Loss: 0.1981338 Vali Loss: 0.1324699 Test Loss: 0.1878206
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm2_96_96_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.1788916438817978, mae:0.2600537836551666
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_192        Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_192_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3124962
	speed: 0.1020s/iter; left time: 263.2786s
	iters: 200, epoch: 1 | loss: 0.2973742
	speed: 0.1071s/iter; left time: 265.7065s
Epoch: 1 cost time: 29.120485067367554
Epoch: 1, Steps: 268 | Train Loss: 0.3343308 Vali Loss: 0.1786379 Test Loss: 0.2510366
Validation loss decreased (inf --> 0.178638).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2771029
	speed: 0.3187s/iter; left time: 737.1220s
	iters: 200, epoch: 2 | loss: 0.4699575
	speed: 0.1240s/iter; left time: 274.3656s
Epoch: 2 cost time: 33.52658438682556
Epoch: 2, Steps: 268 | Train Loss: 0.3211711 Vali Loss: 0.1755581 Test Loss: 0.2451793
Validation loss decreased (0.178638 --> 0.175558).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2582897
	speed: 0.3346s/iter; left time: 684.2556s
	iters: 200, epoch: 3 | loss: 0.4553721
	speed: 0.1304s/iter; left time: 253.5893s
Epoch: 3 cost time: 34.15907406806946
Epoch: 3, Steps: 268 | Train Loss: 0.3141248 Vali Loss: 0.1729955 Test Loss: 0.2429894
Validation loss decreased (0.175558 --> 0.172995).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4370177
	speed: 0.3724s/iter; left time: 661.8048s
	iters: 200, epoch: 4 | loss: 0.3810682
	speed: 0.1221s/iter; left time: 204.7122s
Epoch: 4 cost time: 33.133795499801636
Epoch: 4, Steps: 268 | Train Loss: 0.3092407 Vali Loss: 0.1723834 Test Loss: 0.2418774
Validation loss decreased (0.172995 --> 0.172383).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3701803
	speed: 0.3352s/iter; left time: 505.8687s
	iters: 200, epoch: 5 | loss: 0.2156175
	speed: 0.1212s/iter; left time: 170.8402s
Epoch: 5 cost time: 32.78273963928223
Epoch: 5, Steps: 268 | Train Loss: 0.3062925 Vali Loss: 0.1747530 Test Loss: 0.2446331
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3684100
	speed: 0.3238s/iter; left time: 401.7955s
	iters: 200, epoch: 6 | loss: 0.2065761
	speed: 0.1266s/iter; left time: 144.4870s
Epoch: 6 cost time: 33.35817265510559
Epoch: 6, Steps: 268 | Train Loss: 0.3037531 Vali Loss: 0.1763805 Test Loss: 0.2469550
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3011714
	speed: 0.3159s/iter; left time: 307.4052s
	iters: 200, epoch: 7 | loss: 0.3951266
	speed: 0.1243s/iter; left time: 108.5451s
Epoch: 7 cost time: 33.390129804611206
Epoch: 7, Steps: 268 | Train Loss: 0.3028083 Vali Loss: 0.1766301 Test Loss: 0.2470720
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm2_96_192_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.24266944825649261, mae:0.3014429211616516
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_336        Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_336_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4184476
	speed: 0.0497s/iter; left time: 525.7503s
	iters: 200, epoch: 1 | loss: 0.7471218
	speed: 0.0412s/iter; left time: 431.5085s
	iters: 300, epoch: 1 | loss: 0.4293288
	speed: 0.0410s/iter; left time: 425.1923s
	iters: 400, epoch: 1 | loss: 0.6456659
	speed: 0.0419s/iter; left time: 430.4785s
	iters: 500, epoch: 1 | loss: 0.3201471
	speed: 0.0409s/iter; left time: 416.1464s
	iters: 600, epoch: 1 | loss: 0.4010847
	speed: 0.0406s/iter; left time: 408.9101s
	iters: 700, epoch: 1 | loss: 0.3222516
	speed: 0.0413s/iter; left time: 411.6995s
	iters: 800, epoch: 1 | loss: 1.0176479
	speed: 0.0409s/iter; left time: 403.6639s
	iters: 900, epoch: 1 | loss: 0.3446879
	speed: 0.0405s/iter; left time: 395.7005s
	iters: 1000, epoch: 1 | loss: 0.3740274
	speed: 0.0416s/iter; left time: 402.3461s
Epoch: 1 cost time: 44.73913311958313
Epoch: 1, Steps: 1067 | Train Loss: 0.4378768 Vali Loss: 0.2229754 Test Loss: 0.3114327
Validation loss decreased (inf --> 0.222975).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4648004
	speed: 0.3435s/iter; left time: 3264.6959s
	iters: 200, epoch: 2 | loss: 0.3427330
	speed: 0.0442s/iter; left time: 415.6706s
	iters: 300, epoch: 2 | loss: 0.2334460
	speed: 0.0418s/iter; left time: 388.5800s
	iters: 400, epoch: 2 | loss: 0.6606209
	speed: 0.0408s/iter; left time: 375.7256s
	iters: 500, epoch: 2 | loss: 0.7850350
	speed: 0.0414s/iter; left time: 377.1785s
	iters: 600, epoch: 2 | loss: 0.5649523
	speed: 0.0408s/iter; left time: 367.4339s
	iters: 700, epoch: 2 | loss: 0.7452443
	speed: 0.0413s/iter; left time: 367.5407s
	iters: 800, epoch: 2 | loss: 0.7350641
	speed: 0.0331s/iter; left time: 291.7110s
	iters: 900, epoch: 2 | loss: 0.3091851
	speed: 0.0332s/iter; left time: 289.2210s
	iters: 1000, epoch: 2 | loss: 1.0180024
	speed: 0.0323s/iter; left time: 278.1742s
Epoch: 2 cost time: 41.795429706573486
Epoch: 2, Steps: 1067 | Train Loss: 0.4264102 Vali Loss: 0.2261379 Test Loss: 0.3107602
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2304949
	speed: 0.2677s/iter; left time: 2258.3107s
	iters: 200, epoch: 3 | loss: 0.4997589
	speed: 0.0334s/iter; left time: 278.6678s
	iters: 300, epoch: 3 | loss: 0.4342091
	speed: 0.0358s/iter; left time: 294.6392s
	iters: 400, epoch: 3 | loss: 0.5114397
	speed: 0.0389s/iter; left time: 316.5028s
	iters: 500, epoch: 3 | loss: 0.4860567
	speed: 0.0445s/iter; left time: 357.9076s
	iters: 600, epoch: 3 | loss: 0.6483373
	speed: 0.0425s/iter; left time: 337.1527s
	iters: 700, epoch: 3 | loss: 0.5341050
	speed: 0.0464s/iter; left time: 363.9192s
	iters: 800, epoch: 3 | loss: 0.5766102
	speed: 0.0457s/iter; left time: 353.6520s
	iters: 900, epoch: 3 | loss: 0.2218845
	speed: 0.0428s/iter; left time: 326.7849s
	iters: 1000, epoch: 3 | loss: 0.3645831
	speed: 0.0431s/iter; left time: 324.9288s
Epoch: 3 cost time: 43.6997492313385
Epoch: 3, Steps: 1067 | Train Loss: 0.4182905 Vali Loss: 0.2209562 Test Loss: 0.3023465
Validation loss decreased (0.222975 --> 0.220956).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3499573
	speed: 0.3599s/iter; left time: 2652.1960s
	iters: 200, epoch: 4 | loss: 0.2731863
	speed: 0.0412s/iter; left time: 299.2007s
	iters: 300, epoch: 4 | loss: 0.3457370
	speed: 0.0420s/iter; left time: 300.8703s
	iters: 400, epoch: 4 | loss: 0.7540246
	speed: 0.0444s/iter; left time: 313.7394s
	iters: 500, epoch: 4 | loss: 0.3952713
	speed: 0.0422s/iter; left time: 294.0834s
	iters: 600, epoch: 4 | loss: 0.4782379
	speed: 0.0433s/iter; left time: 297.3029s
	iters: 700, epoch: 4 | loss: 0.3768139
	speed: 0.0438s/iter; left time: 296.7818s
	iters: 800, epoch: 4 | loss: 0.3953350
	speed: 0.0404s/iter; left time: 269.7144s
	iters: 900, epoch: 4 | loss: 0.6539641
	speed: 0.0409s/iter; left time: 268.5641s
	iters: 1000, epoch: 4 | loss: 1.1872087
	speed: 0.0414s/iter; left time: 267.5702s
Epoch: 4 cost time: 45.05896043777466
Epoch: 4, Steps: 1067 | Train Loss: 0.4125872 Vali Loss: 0.2205784 Test Loss: 0.3038132
Validation loss decreased (0.220956 --> 0.220578).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5700436
	speed: 0.3266s/iter; left time: 2058.6807s
	iters: 200, epoch: 5 | loss: 0.9676997
	speed: 0.0409s/iter; left time: 253.4634s
	iters: 300, epoch: 5 | loss: 0.4506150
	speed: 0.0417s/iter; left time: 254.7899s
	iters: 400, epoch: 5 | loss: 0.1963370
	speed: 0.0408s/iter; left time: 244.6730s
	iters: 500, epoch: 5 | loss: 0.4492016
	speed: 0.0434s/iter; left time: 256.1907s
	iters: 600, epoch: 5 | loss: 1.0816951
	speed: 0.0431s/iter; left time: 250.3594s
	iters: 700, epoch: 5 | loss: 0.3170517
	speed: 0.0443s/iter; left time: 252.5221s
	iters: 800, epoch: 5 | loss: 0.3352615
	speed: 0.0428s/iter; left time: 239.8952s
	iters: 900, epoch: 5 | loss: 0.5080945
	speed: 0.0417s/iter; left time: 229.5585s
	iters: 1000, epoch: 5 | loss: 0.2679929
	speed: 0.0408s/iter; left time: 220.4088s
Epoch: 5 cost time: 45.000593185424805
Epoch: 5, Steps: 1067 | Train Loss: 0.4085892 Vali Loss: 0.2224702 Test Loss: 0.3046373
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4220107
	speed: 0.3286s/iter; left time: 1720.3361s
	iters: 200, epoch: 6 | loss: 0.3780616
	speed: 0.0401s/iter; left time: 206.0188s
	iters: 300, epoch: 6 | loss: 0.4934112
	speed: 0.0409s/iter; left time: 205.8049s
	iters: 400, epoch: 6 | loss: 0.5526190
	speed: 0.0430s/iter; left time: 212.1336s
	iters: 500, epoch: 6 | loss: 0.3602902
	speed: 0.0424s/iter; left time: 204.8964s
	iters: 600, epoch: 6 | loss: 0.1924016
	speed: 0.0463s/iter; left time: 219.4633s
	iters: 700, epoch: 6 | loss: 0.2399399
	speed: 0.0473s/iter; left time: 219.4076s
	iters: 800, epoch: 6 | loss: 0.3640479
	speed: 0.0475s/iter; left time: 215.5704s
	iters: 900, epoch: 6 | loss: 0.2210029
	speed: 0.0462s/iter; left time: 205.0627s
	iters: 1000, epoch: 6 | loss: 1.0224632
	speed: 0.0448s/iter; left time: 194.3267s
Epoch: 6 cost time: 47.20223665237427
Epoch: 6, Steps: 1067 | Train Loss: 0.4065379 Vali Loss: 0.2228567 Test Loss: 0.3052138
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5768723
	speed: 0.4557s/iter; left time: 1899.9992s
	iters: 200, epoch: 7 | loss: 0.4668854
	speed: 0.0512s/iter; left time: 208.2885s
	iters: 300, epoch: 7 | loss: 0.4252619
	speed: 0.0507s/iter; left time: 201.2244s
	iters: 400, epoch: 7 | loss: 0.4277945
	speed: 0.0532s/iter; left time: 205.8619s
	iters: 500, epoch: 7 | loss: 0.1691161
	speed: 0.0495s/iter; left time: 186.4607s
	iters: 600, epoch: 7 | loss: 0.6747256
	speed: 0.0523s/iter; left time: 191.8741s
	iters: 700, epoch: 7 | loss: 0.4696865
	speed: 0.0492s/iter; left time: 175.6012s
	iters: 800, epoch: 7 | loss: 0.3150140
	speed: 0.0443s/iter; left time: 153.7612s
	iters: 900, epoch: 7 | loss: 0.8687241
	speed: 0.0453s/iter; left time: 152.7181s
	iters: 1000, epoch: 7 | loss: 0.3405571
	speed: 0.0448s/iter; left time: 146.5853s
Epoch: 7 cost time: 51.78874921798706
Epoch: 7, Steps: 1067 | Train Loss: 0.4056502 Vali Loss: 0.2223314 Test Loss: 0.3053923
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm2_96_336_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.30405277013778687, mae:0.3440108299255371
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_720        Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_720_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4883005
	speed: 0.1059s/iter; left time: 269.0782s
	iters: 200, epoch: 1 | loss: 0.6661319
	speed: 0.1034s/iter; left time: 252.4167s
Epoch: 1 cost time: 28.08188486099243
Epoch: 1, Steps: 264 | Train Loss: 0.5861532 Vali Loss: 0.3012435 Test Loss: 0.4125388
Validation loss decreased (inf --> 0.301243).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4348288
	speed: 0.3873s/iter; left time: 881.8812s
	iters: 200, epoch: 2 | loss: 0.6782523
	speed: 0.1254s/iter; left time: 273.0214s
Epoch: 2 cost time: 34.101462841033936
Epoch: 2, Steps: 264 | Train Loss: 0.5702760 Vali Loss: 0.2913899 Test Loss: 0.4061669
Validation loss decreased (0.301243 --> 0.291390).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5238597
	speed: 0.3409s/iter; left time: 686.3278s
	iters: 200, epoch: 3 | loss: 0.6209770
	speed: 0.1262s/iter; left time: 241.3332s
Epoch: 3 cost time: 33.74187421798706
Epoch: 3, Steps: 264 | Train Loss: 0.5608489 Vali Loss: 0.2910175 Test Loss: 0.4040742
Validation loss decreased (0.291390 --> 0.291017).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5625381
	speed: 0.3915s/iter; left time: 684.6594s
	iters: 200, epoch: 4 | loss: 0.7346529
	speed: 0.1396s/iter; left time: 230.1795s
Epoch: 4 cost time: 36.22041320800781
Epoch: 4, Steps: 264 | Train Loss: 0.5512727 Vali Loss: 0.2949345 Test Loss: 0.4134314
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4416704
	speed: 0.3938s/iter; left time: 584.8005s
	iters: 200, epoch: 5 | loss: 0.7008739
	speed: 0.1622s/iter; left time: 224.5893s
Epoch: 5 cost time: 40.653398513793945
Epoch: 5, Steps: 264 | Train Loss: 0.5445687 Vali Loss: 0.2976281 Test Loss: 0.4183745
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3737700
	speed: 0.4592s/iter; left time: 560.7056s
	iters: 200, epoch: 6 | loss: 0.4462434
	speed: 0.1370s/iter; left time: 153.5549s
Epoch: 6 cost time: 37.11041879653931
Epoch: 6, Steps: 264 | Train Loss: 0.5396661 Vali Loss: 0.2961586 Test Loss: 0.4189399
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm2_96_720_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.40158191323280334, mae:0.40092748403549194
