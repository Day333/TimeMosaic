Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_96         Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_96_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.3913918
	speed: 0.0535s/iter; left time: 569.6829s
	iters: 200, epoch: 1 | loss: 0.2707801
	speed: 0.0809s/iter; left time: 853.8887s
	iters: 300, epoch: 1 | loss: 0.3234139
	speed: 0.0805s/iter; left time: 841.1146s
	iters: 400, epoch: 1 | loss: 0.3305924
	speed: 0.0831s/iter; left time: 859.6787s
	iters: 500, epoch: 1 | loss: 0.3278973
	speed: 0.0789s/iter; left time: 808.6348s
	iters: 600, epoch: 1 | loss: 0.2810315
	speed: 0.0820s/iter; left time: 832.5065s
	iters: 700, epoch: 1 | loss: 0.2570246
	speed: 0.0825s/iter; left time: 829.1876s
	iters: 800, epoch: 1 | loss: 0.3238934
	speed: 0.0787s/iter; left time: 782.6854s
	iters: 900, epoch: 1 | loss: 0.3441873
	speed: 0.0829s/iter; left time: 816.3903s
	iters: 1000, epoch: 1 | loss: 0.3194506
	speed: 0.0815s/iter; left time: 795.1495s
Epoch: 1 cost time: 84.26793694496155
Epoch: 1, Steps: 1075 | Train Loss: 0.3268655 Vali Loss: 0.4307233 Test Loss: 0.3542445
Validation loss decreased (inf --> 0.430723).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3166304
	speed: 0.6061s/iter; left time: 5803.9157s
	iters: 200, epoch: 2 | loss: 0.2752926
	speed: 0.0821s/iter; left time: 777.7388s
	iters: 300, epoch: 2 | loss: 0.3632965
	speed: 0.0759s/iter; left time: 711.9952s
	iters: 400, epoch: 2 | loss: 0.2241257
	speed: 0.0697s/iter; left time: 646.7737s
	iters: 500, epoch: 2 | loss: 0.2940882
	speed: 0.0689s/iter; left time: 631.8279s
	iters: 600, epoch: 2 | loss: 0.2238056
	speed: 0.0652s/iter; left time: 591.8002s
	iters: 700, epoch: 2 | loss: 0.3035746
	speed: 0.0624s/iter; left time: 560.4730s
	iters: 800, epoch: 2 | loss: 0.2773217
	speed: 0.0682s/iter; left time: 605.1620s
	iters: 900, epoch: 2 | loss: 0.3230218
	speed: 0.0707s/iter; left time: 620.1674s
	iters: 1000, epoch: 2 | loss: 0.3318821
	speed: 0.0577s/iter; left time: 500.5935s
Epoch: 2 cost time: 74.69645261764526
Epoch: 2, Steps: 1075 | Train Loss: 0.3008289 Vali Loss: 0.4184566 Test Loss: 0.3407917
Validation loss decreased (0.430723 --> 0.418457).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3240605
	speed: 0.5665s/iter; left time: 4815.5149s
	iters: 200, epoch: 3 | loss: 0.2567495
	speed: 0.0778s/iter; left time: 653.6760s
	iters: 300, epoch: 3 | loss: 0.3266678
	speed: 0.0812s/iter; left time: 674.1808s
	iters: 400, epoch: 3 | loss: 0.3247956
	speed: 0.0817s/iter; left time: 670.1349s
	iters: 500, epoch: 3 | loss: 0.2831212
	speed: 0.0769s/iter; left time: 623.2325s
	iters: 600, epoch: 3 | loss: 0.3034437
	speed: 0.0814s/iter; left time: 651.3948s
	iters: 700, epoch: 3 | loss: 0.3283524
	speed: 0.0795s/iter; left time: 628.4361s
	iters: 800, epoch: 3 | loss: 0.2821173
	speed: 0.0812s/iter; left time: 633.5986s
	iters: 900, epoch: 3 | loss: 0.2798581
	speed: 0.0811s/iter; left time: 624.6276s
	iters: 1000, epoch: 3 | loss: 0.2224887
	speed: 0.0751s/iter; left time: 570.8702s
Epoch: 3 cost time: 85.59821391105652
Epoch: 3, Steps: 1075 | Train Loss: 0.2913121 Vali Loss: 0.4096126 Test Loss: 0.3429214
Validation loss decreased (0.418457 --> 0.409613).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2635839
	speed: 0.5123s/iter; left time: 3804.5951s
	iters: 200, epoch: 4 | loss: 0.2369607
	speed: 0.0604s/iter; left time: 442.3591s
	iters: 300, epoch: 4 | loss: 0.2901645
	speed: 0.0579s/iter; left time: 418.0397s
	iters: 400, epoch: 4 | loss: 0.2429633
	speed: 0.0580s/iter; left time: 413.4851s
	iters: 500, epoch: 4 | loss: 0.2851425
	speed: 0.0606s/iter; left time: 425.5452s
	iters: 600, epoch: 4 | loss: 0.2872419
	speed: 0.0644s/iter; left time: 446.2938s
	iters: 700, epoch: 4 | loss: 0.2078918
	speed: 0.0704s/iter; left time: 480.2732s
	iters: 800, epoch: 4 | loss: 0.2683064
	speed: 0.0717s/iter; left time: 481.9228s
	iters: 900, epoch: 4 | loss: 0.2347544
	speed: 0.0713s/iter; left time: 472.5099s
	iters: 1000, epoch: 4 | loss: 0.2490534
	speed: 0.0710s/iter; left time: 463.3261s
Epoch: 4 cost time: 70.34915685653687
Epoch: 4, Steps: 1075 | Train Loss: 0.2862939 Vali Loss: 0.4001562 Test Loss: 0.3317977
Validation loss decreased (0.409613 --> 0.400156).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2179183
	speed: 0.5443s/iter; left time: 3456.8776s
	iters: 200, epoch: 5 | loss: 0.2817963
	speed: 0.0714s/iter; left time: 446.1382s
	iters: 300, epoch: 5 | loss: 0.3210597
	speed: 0.0718s/iter; left time: 441.4853s
	iters: 400, epoch: 5 | loss: 0.2390506
	speed: 0.0713s/iter; left time: 431.1678s
	iters: 500, epoch: 5 | loss: 0.2872595
	speed: 0.0718s/iter; left time: 427.4012s
	iters: 600, epoch: 5 | loss: 0.2511766
	speed: 0.0712s/iter; left time: 416.7334s
	iters: 700, epoch: 5 | loss: 0.2897431
	speed: 0.0706s/iter; left time: 405.9257s
	iters: 800, epoch: 5 | loss: 0.2403884
	speed: 0.0719s/iter; left time: 406.0775s
	iters: 900, epoch: 5 | loss: 0.2841545
	speed: 0.0683s/iter; left time: 378.9789s
	iters: 1000, epoch: 5 | loss: 0.2994653
	speed: 0.0612s/iter; left time: 333.7995s
Epoch: 5 cost time: 74.63479566574097
Epoch: 5, Steps: 1075 | Train Loss: 0.2835221 Vali Loss: 0.4043311 Test Loss: 0.3316858
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2871650
	speed: 0.4726s/iter; left time: 2493.2674s
	iters: 200, epoch: 6 | loss: 0.3211454
	speed: 0.0710s/iter; left time: 367.6004s
	iters: 300, epoch: 6 | loss: 0.2480168
	speed: 0.0712s/iter; left time: 361.4246s
	iters: 400, epoch: 6 | loss: 0.2928880
	speed: 0.0708s/iter; left time: 352.4967s
	iters: 500, epoch: 6 | loss: 0.2975237
	speed: 0.0712s/iter; left time: 347.3529s
	iters: 600, epoch: 6 | loss: 0.3065262
	speed: 0.0714s/iter; left time: 341.2428s
	iters: 700, epoch: 6 | loss: 0.2365443
	speed: 0.0579s/iter; left time: 270.9431s
	iters: 800, epoch: 6 | loss: 0.2768300
	speed: 0.0596s/iter; left time: 272.8367s
	iters: 900, epoch: 6 | loss: 0.2577158
	speed: 0.0572s/iter; left time: 256.1138s
	iters: 1000, epoch: 6 | loss: 0.2521250
	speed: 0.0570s/iter; left time: 249.3311s
Epoch: 6 cost time: 70.49495005607605
Epoch: 6, Steps: 1075 | Train Loss: 0.2822809 Vali Loss: 0.4036933 Test Loss: 0.3310403
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3106796
	speed: 0.4286s/iter; left time: 1800.3894s
	iters: 200, epoch: 7 | loss: 0.3429916
	speed: 0.0587s/iter; left time: 240.9020s
	iters: 300, epoch: 7 | loss: 0.2468400
	speed: 0.0542s/iter; left time: 216.9987s
	iters: 400, epoch: 7 | loss: 0.2653258
	speed: 0.0353s/iter; left time: 137.7222s
	iters: 500, epoch: 7 | loss: 0.2638029
	speed: 0.0459s/iter; left time: 174.5210s
	iters: 600, epoch: 7 | loss: 0.2925832
	speed: 0.0484s/iter; left time: 179.1987s
	iters: 700, epoch: 7 | loss: 0.3229924
	speed: 0.0483s/iter; left time: 173.9476s
	iters: 800, epoch: 7 | loss: 0.2452241
	speed: 0.0453s/iter; left time: 158.5113s
	iters: 900, epoch: 7 | loss: 0.3291315
	speed: 0.0461s/iter; left time: 156.9490s
	iters: 1000, epoch: 7 | loss: 0.2406875
	speed: 0.0431s/iter; left time: 142.2675s
Epoch: 7 cost time: 51.88523507118225
Epoch: 7, Steps: 1075 | Train Loss: 0.2827377 Vali Loss: 0.4007652 Test Loss: 0.3328881
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_96_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.33249107003211975, mae:0.36793479323387146
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_192        Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_192_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3844876
	speed: 0.1937s/iter; left time: 500.0447s
	iters: 200, epoch: 1 | loss: 0.3536390
	speed: 0.1883s/iter; left time: 467.1097s
Epoch: 1 cost time: 51.00880670547485
Epoch: 1, Steps: 268 | Train Loss: 0.3641233 Vali Loss: 0.5300031 Test Loss: 0.3783994
Validation loss decreased (inf --> 0.530003).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3779916
	speed: 0.5145s/iter; left time: 1189.9394s
	iters: 200, epoch: 2 | loss: 0.3267929
	speed: 0.1994s/iter; left time: 441.3624s
Epoch: 2 cost time: 52.050419092178345
Epoch: 2, Steps: 268 | Train Loss: 0.3381708 Vali Loss: 0.5254321 Test Loss: 0.3788072
Validation loss decreased (0.530003 --> 0.525432).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2922246
	speed: 0.5756s/iter; left time: 1177.0410s
	iters: 200, epoch: 3 | loss: 0.3559688
	speed: 0.2158s/iter; left time: 419.7682s
Epoch: 3 cost time: 57.731926918029785
Epoch: 3, Steps: 268 | Train Loss: 0.3285105 Vali Loss: 0.5197959 Test Loss: 0.3760926
Validation loss decreased (0.525432 --> 0.519796).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3110977
	speed: 0.5691s/iter; left time: 1011.3686s
	iters: 200, epoch: 4 | loss: 0.3288139
	speed: 0.2225s/iter; left time: 373.1027s
Epoch: 4 cost time: 59.447468996047974
Epoch: 4, Steps: 268 | Train Loss: 0.3235822 Vali Loss: 0.5176902 Test Loss: 0.3772527
Validation loss decreased (0.519796 --> 0.517690).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3431278
	speed: 0.6348s/iter; left time: 957.9195s
	iters: 200, epoch: 5 | loss: 0.3473294
	speed: 0.2040s/iter; left time: 287.4476s
Epoch: 5 cost time: 55.2863667011261
Epoch: 5, Steps: 268 | Train Loss: 0.3206978 Vali Loss: 0.5171986 Test Loss: 0.3744211
Validation loss decreased (0.517690 --> 0.517199).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3076017
	speed: 0.5701s/iter; left time: 707.5222s
	iters: 200, epoch: 6 | loss: 0.3517759
	speed: 0.2176s/iter; left time: 248.2716s
Epoch: 6 cost time: 58.19771862030029
Epoch: 6, Steps: 268 | Train Loss: 0.3193706 Vali Loss: 0.5179832 Test Loss: 0.3740902
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3398007
	speed: 0.5618s/iter; left time: 546.6343s
	iters: 200, epoch: 7 | loss: 0.3246183
	speed: 0.2150s/iter; left time: 187.6797s
Epoch: 7 cost time: 56.61827278137207
Epoch: 7, Steps: 268 | Train Loss: 0.3187066 Vali Loss: 0.5180119 Test Loss: 0.3732327
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3420416
	speed: 0.5981s/iter; left time: 421.6523s
	iters: 200, epoch: 8 | loss: 0.3360508
	speed: 0.1931s/iter; left time: 116.8352s
Epoch: 8 cost time: 51.35493779182434
Epoch: 8, Steps: 268 | Train Loss: 0.3183711 Vali Loss: 0.5176910 Test Loss: 0.3734211
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_192_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.37482911348342896, mae:0.3888165056705475
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_336        Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_336_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4484735
	speed: 0.1160s/iter; left time: 298.3267s
	iters: 200, epoch: 1 | loss: 0.3887479
	speed: 0.1172s/iter; left time: 289.5162s
Epoch: 1 cost time: 31.555351734161377
Epoch: 1, Steps: 267 | Train Loss: 0.4297190 Vali Loss: 0.6803691 Test Loss: 0.4145370
Validation loss decreased (inf --> 0.680369).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4218925
	speed: 0.5220s/iter; left time: 1202.6484s
	iters: 200, epoch: 2 | loss: 0.3563471
	speed: 0.1089s/iter; left time: 239.9566s
Epoch: 2 cost time: 31.84456181526184
Epoch: 2, Steps: 267 | Train Loss: 0.4006876 Vali Loss: 0.6753126 Test Loss: 0.4117666
Validation loss decreased (0.680369 --> 0.675313).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4067150
	speed: 0.3353s/iter; left time: 683.0932s
	iters: 200, epoch: 3 | loss: 0.4150378
	speed: 0.1085s/iter; left time: 210.2539s
Epoch: 3 cost time: 28.988781690597534
Epoch: 3, Steps: 267 | Train Loss: 0.3935659 Vali Loss: 0.6730680 Test Loss: 0.4083053
Validation loss decreased (0.675313 --> 0.673068).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3997690
	speed: 0.3485s/iter; left time: 616.8625s
	iters: 200, epoch: 4 | loss: 0.3925737
	speed: 0.1015s/iter; left time: 169.5308s
Epoch: 4 cost time: 27.82889461517334
Epoch: 4, Steps: 267 | Train Loss: 0.3906978 Vali Loss: 0.6686579 Test Loss: 0.4092394
Validation loss decreased (0.673068 --> 0.668658).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4436401
	speed: 0.4083s/iter; left time: 613.7387s
	iters: 200, epoch: 5 | loss: 0.3946998
	speed: 0.0984s/iter; left time: 138.0374s
Epoch: 5 cost time: 27.451147079467773
Epoch: 5, Steps: 267 | Train Loss: 0.3892887 Vali Loss: 0.6673353 Test Loss: 0.4077556
Validation loss decreased (0.668658 --> 0.667335).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3862472
	speed: 0.4366s/iter; left time: 539.6282s
	iters: 200, epoch: 6 | loss: 0.4030088
	speed: 0.1080s/iter; left time: 122.7252s
Epoch: 6 cost time: 29.325018167495728
Epoch: 6, Steps: 267 | Train Loss: 0.3884727 Vali Loss: 0.6676629 Test Loss: 0.4079541
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3853527
	speed: 0.3881s/iter; left time: 376.0736s
	iters: 200, epoch: 7 | loss: 0.4043313
	speed: 0.1083s/iter; left time: 94.1061s
Epoch: 7 cost time: 28.322800636291504
Epoch: 7, Steps: 267 | Train Loss: 0.3881545 Vali Loss: 0.6666937 Test Loss: 0.4079319
Validation loss decreased (0.667335 --> 0.666694).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4148252
	speed: 0.3421s/iter; left time: 240.1237s
	iters: 200, epoch: 8 | loss: 0.3849789
	speed: 0.1147s/iter; left time: 69.0594s
Epoch: 8 cost time: 29.853597402572632
Epoch: 8, Steps: 267 | Train Loss: 0.3878908 Vali Loss: 0.6679394 Test Loss: 0.4080122
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.4147880
	speed: 0.3293s/iter; left time: 143.2335s
	iters: 200, epoch: 9 | loss: 0.3843194
	speed: 0.1141s/iter; left time: 38.2335s
Epoch: 9 cost time: 29.91813564300537
Epoch: 9, Steps: 267 | Train Loss: 0.3879117 Vali Loss: 0.6679448 Test Loss: 0.4080267
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3637715
	speed: 0.3158s/iter; left time: 53.0487s
	iters: 200, epoch: 10 | loss: 0.3838957
	speed: 0.0982s/iter; left time: 6.6752s
Epoch: 10 cost time: 26.626919746398926
Epoch: 10, Steps: 267 | Train Loss: 0.3878850 Vali Loss: 0.6670449 Test Loss: 0.4080778
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_336_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.40709221363067627, mae:0.4093570411205292
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_720        Model:              AGPTp               

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_720_AGPTp_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4670646
	speed: 0.1966s/iter; left time: 499.4813s
	iters: 200, epoch: 1 | loss: 0.4611301
	speed: 0.2103s/iter; left time: 513.2527s
Epoch: 1 cost time: 53.023539304733276
Epoch: 1, Steps: 264 | Train Loss: 0.4890845 Vali Loss: 0.9912598 Test Loss: 0.4792074
Validation loss decreased (inf --> 0.991260).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4421962
	speed: 0.4973s/iter; left time: 1132.4207s
	iters: 200, epoch: 2 | loss: 0.4644758
	speed: 0.1902s/iter; left time: 414.1715s
Epoch: 2 cost time: 50.56436061859131
Epoch: 2, Steps: 264 | Train Loss: 0.4617589 Vali Loss: 0.9809529 Test Loss: 0.4755132
Validation loss decreased (0.991260 --> 0.980953).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4754751
	speed: 0.5399s/iter; left time: 1086.7337s
	iters: 200, epoch: 3 | loss: 0.4805489
	speed: 0.2013s/iter; left time: 385.0367s
Epoch: 3 cost time: 54.77178144454956
Epoch: 3, Steps: 264 | Train Loss: 0.4522479 Vali Loss: 0.9803180 Test Loss: 0.4700651
Validation loss decreased (0.980953 --> 0.980318).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4652421
	speed: 0.5451s/iter; left time: 953.3903s
	iters: 200, epoch: 4 | loss: 0.4130079
	speed: 0.2165s/iter; left time: 357.0715s
Epoch: 4 cost time: 57.38255786895752
Epoch: 4, Steps: 264 | Train Loss: 0.4468258 Vali Loss: 0.9769626 Test Loss: 0.4690114
Validation loss decreased (0.980318 --> 0.976963).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4652967
	speed: 0.5715s/iter; left time: 848.6205s
	iters: 200, epoch: 5 | loss: 0.4025122
	speed: 0.2163s/iter; left time: 299.5910s
Epoch: 5 cost time: 57.815330028533936
Epoch: 5, Steps: 264 | Train Loss: 0.4437722 Vali Loss: 0.9747010 Test Loss: 0.4703249
Validation loss decreased (0.976963 --> 0.974701).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4775717
	speed: 0.5358s/iter; left time: 654.1599s
	iters: 200, epoch: 6 | loss: 0.4610931
	speed: 0.2008s/iter; left time: 225.0855s
Epoch: 6 cost time: 54.068007707595825
Epoch: 6, Steps: 264 | Train Loss: 0.4422530 Vali Loss: 0.9764059 Test Loss: 0.4706685
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4311414
	speed: 0.5578s/iter; left time: 533.8524s
	iters: 200, epoch: 7 | loss: 0.4306015
	speed: 0.2170s/iter; left time: 185.9441s
Epoch: 7 cost time: 57.50853967666626
Epoch: 7, Steps: 264 | Train Loss: 0.4412060 Vali Loss: 0.9761846 Test Loss: 0.4696001
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4086525
	speed: 0.5554s/iter; left time: 384.9168s
	iters: 200, epoch: 8 | loss: 0.4711630
	speed: 0.2166s/iter; left time: 128.4731s
Epoch: 8 cost time: 56.670278549194336
Epoch: 8, Steps: 264 | Train Loss: 0.4407558 Vali Loss: 0.9755098 Test Loss: 0.4700561
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_720_AGPTp_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.46916911005973816, mae:0.4484007656574249
