Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_96         Model:              PatchMLP            

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_96_PatchMLP_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2197759
	speed: 0.0240s/iter; left time: 256.0878s
	iters: 200, epoch: 1 | loss: 0.1802255
	speed: 0.0163s/iter; left time: 172.0677s
	iters: 300, epoch: 1 | loss: 0.2352815
	speed: 0.0175s/iter; left time: 183.0530s
	iters: 400, epoch: 1 | loss: 0.3061923
	speed: 0.0216s/iter; left time: 223.3372s
	iters: 500, epoch: 1 | loss: 0.2665199
	speed: 0.0203s/iter; left time: 207.7291s
	iters: 600, epoch: 1 | loss: 0.2222434
	speed: 0.0219s/iter; left time: 222.4532s
	iters: 700, epoch: 1 | loss: 0.2371737
	speed: 0.0157s/iter; left time: 157.3159s
	iters: 800, epoch: 1 | loss: 0.1277364
	speed: 0.0147s/iter; left time: 146.5790s
	iters: 900, epoch: 1 | loss: 0.1511157
	speed: 0.0197s/iter; left time: 194.3763s
	iters: 1000, epoch: 1 | loss: 0.1470893
	speed: 0.0166s/iter; left time: 162.1764s
Epoch: 1 cost time: 19.799671173095703
Epoch: 1, Steps: 1075 | Train Loss: 0.2460757 Vali Loss: 0.1324912 Test Loss: 0.1821970
Validation loss decreased (inf --> 0.132491).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7119401
	speed: 0.1314s/iter; left time: 1258.1422s
	iters: 200, epoch: 2 | loss: 0.3301743
	speed: 0.0165s/iter; left time: 156.1173s
	iters: 300, epoch: 2 | loss: 0.2514627
	speed: 0.0223s/iter; left time: 208.8064s
	iters: 400, epoch: 2 | loss: 0.2812481
	speed: 0.0162s/iter; left time: 150.5005s
	iters: 500, epoch: 2 | loss: 0.1666350
	speed: 0.0180s/iter; left time: 165.4591s
	iters: 600, epoch: 2 | loss: 0.2413613
	speed: 0.0255s/iter; left time: 231.4439s
	iters: 700, epoch: 2 | loss: 0.1372899
	speed: 0.0212s/iter; left time: 190.3433s
	iters: 800, epoch: 2 | loss: 0.1620207
	speed: 0.0214s/iter; left time: 189.7899s
	iters: 900, epoch: 2 | loss: 0.1444330
	speed: 0.0154s/iter; left time: 135.4210s
	iters: 1000, epoch: 2 | loss: 0.1744178
	speed: 0.0199s/iter; left time: 172.2951s
Epoch: 2 cost time: 22.31130838394165
Epoch: 2, Steps: 1075 | Train Loss: 0.2045321 Vali Loss: 0.1301152 Test Loss: 0.1785497
Validation loss decreased (0.132491 --> 0.130115).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1353899
	speed: 0.1528s/iter; left time: 1299.0219s
	iters: 200, epoch: 3 | loss: 0.3319920
	speed: 0.0184s/iter; left time: 154.6051s
	iters: 300, epoch: 3 | loss: 0.1942095
	speed: 0.0185s/iter; left time: 153.4019s
	iters: 400, epoch: 3 | loss: 0.2885394
	speed: 0.0175s/iter; left time: 143.2034s
	iters: 500, epoch: 3 | loss: 0.3518082
	speed: 0.0242s/iter; left time: 196.1815s
	iters: 600, epoch: 3 | loss: 0.2177770
	speed: 0.0210s/iter; left time: 168.3940s
	iters: 700, epoch: 3 | loss: 0.1008384
	speed: 0.0191s/iter; left time: 150.7568s
	iters: 800, epoch: 3 | loss: 0.2607782
	speed: 0.0191s/iter; left time: 148.9622s
	iters: 900, epoch: 3 | loss: 0.1402136
	speed: 0.0187s/iter; left time: 143.8968s
	iters: 1000, epoch: 3 | loss: 0.1653502
	speed: 0.0170s/iter; left time: 129.4645s
Epoch: 3 cost time: 21.960119485855103
Epoch: 3, Steps: 1075 | Train Loss: 0.1891399 Vali Loss: 0.1287772 Test Loss: 0.1778780
Validation loss decreased (0.130115 --> 0.128777).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1899984
	speed: 0.1332s/iter; left time: 989.3002s
	iters: 200, epoch: 4 | loss: 0.1431121
	speed: 0.0150s/iter; left time: 109.5663s
	iters: 300, epoch: 4 | loss: 0.2320660
	speed: 0.0170s/iter; left time: 122.9487s
	iters: 400, epoch: 4 | loss: 0.2377523
	speed: 0.0198s/iter; left time: 141.3254s
	iters: 500, epoch: 4 | loss: 0.2341079
	speed: 0.0187s/iter; left time: 131.1421s
	iters: 600, epoch: 4 | loss: 0.2099185
	speed: 0.0161s/iter; left time: 111.1990s
	iters: 700, epoch: 4 | loss: 0.2081846
	speed: 0.0233s/iter; left time: 159.0786s
	iters: 800, epoch: 4 | loss: 0.1139802
	speed: 0.0205s/iter; left time: 137.5887s
	iters: 900, epoch: 4 | loss: 0.2156339
	speed: 0.0138s/iter; left time: 91.3462s
	iters: 1000, epoch: 4 | loss: 0.1793270
	speed: 0.0217s/iter; left time: 141.8232s
Epoch: 4 cost time: 19.96115803718567
Epoch: 4, Steps: 1075 | Train Loss: 0.1828910 Vali Loss: 0.1294183 Test Loss: 0.1794974
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1455702
	speed: 0.1413s/iter; left time: 897.1265s
	iters: 200, epoch: 5 | loss: 0.2473774
	speed: 0.0203s/iter; left time: 127.1613s
	iters: 300, epoch: 5 | loss: 0.2797127
	speed: 0.0160s/iter; left time: 98.4249s
	iters: 400, epoch: 5 | loss: 0.1410881
	speed: 0.0205s/iter; left time: 124.2023s
	iters: 500, epoch: 5 | loss: 0.1701271
	speed: 0.0256s/iter; left time: 152.0603s
	iters: 600, epoch: 5 | loss: 0.4735673
	speed: 0.0173s/iter; left time: 101.0536s
	iters: 700, epoch: 5 | loss: 0.1890379
	speed: 0.0216s/iter; left time: 123.9604s
	iters: 800, epoch: 5 | loss: 0.2044465
	speed: 0.0233s/iter; left time: 131.8424s
	iters: 900, epoch: 5 | loss: 0.1516741
	speed: 0.0212s/iter; left time: 117.9035s
	iters: 1000, epoch: 5 | loss: 0.1598080
	speed: 0.0214s/iter; left time: 116.4618s
Epoch: 5 cost time: 23.25168251991272
Epoch: 5, Steps: 1075 | Train Loss: 0.1795389 Vali Loss: 0.1293093 Test Loss: 0.1793687
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1612012
	speed: 0.1281s/iter; left time: 675.8485s
	iters: 200, epoch: 6 | loss: 0.1366334
	speed: 0.0221s/iter; left time: 114.5001s
	iters: 300, epoch: 6 | loss: 0.1021497
	speed: 0.0239s/iter; left time: 121.4618s
	iters: 400, epoch: 6 | loss: 0.1443607
	speed: 0.0170s/iter; left time: 84.5061s
	iters: 500, epoch: 6 | loss: 0.0991165
	speed: 0.0192s/iter; left time: 93.6261s
	iters: 600, epoch: 6 | loss: 0.2529825
	speed: 0.0187s/iter; left time: 89.1563s
	iters: 700, epoch: 6 | loss: 0.0881842
	speed: 0.0201s/iter; left time: 93.8757s
	iters: 800, epoch: 6 | loss: 0.1449922
	speed: 0.0192s/iter; left time: 87.9572s
	iters: 900, epoch: 6 | loss: 0.1072504
	speed: 0.0192s/iter; left time: 86.1448s
	iters: 1000, epoch: 6 | loss: 0.1945679
	speed: 0.0199s/iter; left time: 86.9618s
Epoch: 6 cost time: 21.924692392349243
Epoch: 6, Steps: 1075 | Train Loss: 0.1776872 Vali Loss: 0.1293389 Test Loss: 0.1799092
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm2_96_96_PatchMLP_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.17814408242702484, mae:0.262098103761673, rmse:0.4220711886882782, mape:1.1641227006912231, mspe:252.57742309570312
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_192        Model:              PatchMLP            

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_192_PatchMLP_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.4123242
	speed: 0.2383s/iter; left time: 615.1779s
	iters: 200, epoch: 1 | loss: 0.3653283
	speed: 0.2256s/iter; left time: 559.7314s
Epoch: 1 cost time: 61.37338137626648
Epoch: 1, Steps: 268 | Train Loss: 0.3672798 Vali Loss: 0.1826161 Test Loss: 0.2548503
Validation loss decreased (inf --> 0.182616).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3054788
	speed: 1.2170s/iter; left time: 2814.9538s
	iters: 200, epoch: 2 | loss: 0.2413226
	speed: 0.2218s/iter; left time: 490.7356s
Epoch: 2 cost time: 61.1686224937439
Epoch: 2, Steps: 268 | Train Loss: 0.3188921 Vali Loss: 0.1792110 Test Loss: 0.2475496
Validation loss decreased (0.182616 --> 0.179211).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2476784
	speed: 1.3085s/iter; left time: 2675.8401s
	iters: 200, epoch: 3 | loss: 0.3264723
	speed: 0.2337s/iter; left time: 454.5759s
Epoch: 3 cost time: 63.014793157577515
Epoch: 3, Steps: 268 | Train Loss: 0.3015087 Vali Loss: 0.1783842 Test Loss: 0.2445042
Validation loss decreased (0.179211 --> 0.178384).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2546544
	speed: 1.1556s/iter; left time: 2053.5155s
	iters: 200, epoch: 4 | loss: 0.2401599
	speed: 0.2092s/iter; left time: 350.7776s
Epoch: 4 cost time: 56.665738344192505
Epoch: 4, Steps: 268 | Train Loss: 0.2940614 Vali Loss: 0.1772767 Test Loss: 0.2441116
Validation loss decreased (0.178384 --> 0.177277).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2749828
	speed: 1.2032s/iter; left time: 1815.6179s
	iters: 200, epoch: 5 | loss: 0.2925181
	speed: 0.2103s/iter; left time: 296.3406s
Epoch: 5 cost time: 56.54425573348999
Epoch: 5, Steps: 268 | Train Loss: 0.2908766 Vali Loss: 0.1771102 Test Loss: 0.2437710
Validation loss decreased (0.177277 --> 0.177110).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2330103
	speed: 1.2115s/iter; left time: 1503.4195s
	iters: 200, epoch: 6 | loss: 0.1943747
	speed: 0.2088s/iter; left time: 238.1898s
Epoch: 6 cost time: 56.9403932094574
Epoch: 6, Steps: 268 | Train Loss: 0.2891665 Vali Loss: 0.1769276 Test Loss: 0.2437138
Validation loss decreased (0.177110 --> 0.176928).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2226845
	speed: 1.2945s/iter; left time: 1259.5429s
	iters: 200, epoch: 7 | loss: 0.2070440
	speed: 0.2330s/iter; left time: 203.3862s
Epoch: 7 cost time: 63.035826206207275
Epoch: 7, Steps: 268 | Train Loss: 0.2884946 Vali Loss: 0.1769432 Test Loss: 0.2437041
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2434851
	speed: 1.3477s/iter; left time: 950.1563s
	iters: 200, epoch: 8 | loss: 0.3087120
	speed: 0.2302s/iter; left time: 139.2438s
Epoch: 8 cost time: 62.26735806465149
Epoch: 8, Steps: 268 | Train Loss: 0.2877343 Vali Loss: 0.1769422 Test Loss: 0.2436772
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1986226
	speed: 1.3381s/iter; left time: 584.7593s
	iters: 200, epoch: 9 | loss: 0.2457990
	speed: 0.2351s/iter; left time: 79.2193s
Epoch: 9 cost time: 63.16129469871521
Epoch: 9, Steps: 268 | Train Loss: 0.2879051 Vali Loss: 0.1768952 Test Loss: 0.2436956
Validation loss decreased (0.176928 --> 0.176895).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2765890
	speed: 1.2692s/iter; left time: 214.4952s
	iters: 200, epoch: 10 | loss: 0.2734881
	speed: 0.2203s/iter; left time: 15.2005s
Epoch: 10 cost time: 59.70446467399597
Epoch: 10, Steps: 268 | Train Loss: 0.2874495 Vali Loss: 0.1770558 Test Loss: 0.2436895
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTm2_96_192_PatchMLP_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.24440492689609528, mae:0.30663567781448364, rmse:0.49437326192855835, mape:1.327688217163086, mspe:281.47613525390625
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_336        Model:              PatchMLP            

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_336_PatchMLP_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5558226
	speed: 0.1196s/iter; left time: 1263.8370s
	iters: 200, epoch: 1 | loss: 0.3752047
	speed: 0.1054s/iter; left time: 1103.6317s
	iters: 300, epoch: 1 | loss: 0.6382843
	speed: 0.1125s/iter; left time: 1166.8389s
	iters: 400, epoch: 1 | loss: 0.4357091
	speed: 0.1086s/iter; left time: 1115.8037s
	iters: 500, epoch: 1 | loss: 0.4061939
	speed: 0.1168s/iter; left time: 1187.6985s
	iters: 600, epoch: 1 | loss: 0.6346645
	speed: 0.1088s/iter; left time: 1095.4748s
	iters: 700, epoch: 1 | loss: 0.6541996
	speed: 0.1081s/iter; left time: 1078.2626s
	iters: 800, epoch: 1 | loss: 0.4996190
	speed: 0.1084s/iter; left time: 1069.8972s
	iters: 900, epoch: 1 | loss: 0.4107562
	speed: 0.1095s/iter; left time: 1070.2140s
	iters: 1000, epoch: 1 | loss: 0.5384145
	speed: 0.1120s/iter; left time: 1083.3015s
Epoch: 1 cost time: 118.2466516494751
Epoch: 1, Steps: 1067 | Train Loss: 0.4503554 Vali Loss: 0.2225381 Test Loss: 0.3099118
Validation loss decreased (inf --> 0.222538).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6319819
	speed: 2.8299s/iter; left time: 26894.9719s
	iters: 200, epoch: 2 | loss: 0.3162905
	speed: 0.1171s/iter; left time: 1100.7842s
	iters: 300, epoch: 2 | loss: 0.7282735
	speed: 0.1210s/iter; left time: 1126.1573s
	iters: 400, epoch: 2 | loss: 0.3773794
	speed: 0.1212s/iter; left time: 1115.1991s
	iters: 500, epoch: 2 | loss: 0.2054745
	speed: 0.1198s/iter; left time: 1090.2100s
	iters: 600, epoch: 2 | loss: 0.4409096
	speed: 0.1192s/iter; left time: 1072.9807s
	iters: 700, epoch: 2 | loss: 0.4172102
	speed: 0.1157s/iter; left time: 1030.2935s
	iters: 800, epoch: 2 | loss: 1.0350491
	speed: 0.1187s/iter; left time: 1045.2441s
	iters: 900, epoch: 2 | loss: 0.3040693
	speed: 0.1220s/iter; left time: 1061.5758s
	iters: 1000, epoch: 2 | loss: 0.4838543
	speed: 0.1178s/iter; left time: 1013.7070s
Epoch: 2 cost time: 128.64949250221252
Epoch: 2, Steps: 1067 | Train Loss: 0.4237673 Vali Loss: 0.2208041 Test Loss: 0.3065589
Validation loss decreased (0.222538 --> 0.220804).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1885293
	speed: 2.6411s/iter; left time: 22282.5734s
	iters: 200, epoch: 3 | loss: 0.4960562
	speed: 0.1022s/iter; left time: 851.7080s
	iters: 300, epoch: 3 | loss: 0.3379199
	speed: 0.1007s/iter; left time: 829.1090s
	iters: 400, epoch: 3 | loss: 0.3981129
	speed: 0.1036s/iter; left time: 843.3848s
	iters: 500, epoch: 3 | loss: 0.5014465
	speed: 0.1000s/iter; left time: 803.5501s
	iters: 600, epoch: 3 | loss: 0.3732569
	speed: 0.1026s/iter; left time: 814.0922s
	iters: 700, epoch: 3 | loss: 0.3073095
	speed: 0.1014s/iter; left time: 794.9043s
	iters: 800, epoch: 3 | loss: 0.6954857
	speed: 0.1006s/iter; left time: 778.0874s
	iters: 900, epoch: 3 | loss: 0.3131116
	speed: 0.1027s/iter; left time: 784.0699s
	iters: 1000, epoch: 3 | loss: 1.0745523
	speed: 0.1030s/iter; left time: 776.1610s
Epoch: 3 cost time: 109.56410026550293
Epoch: 3, Steps: 1067 | Train Loss: 0.4132018 Vali Loss: 0.2196656 Test Loss: 0.3071926
Validation loss decreased (0.220804 --> 0.219666).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3236948
	speed: 2.5558s/iter; left time: 18836.4916s
	iters: 200, epoch: 4 | loss: 0.5096421
	speed: 0.1134s/iter; left time: 824.2639s
	iters: 300, epoch: 4 | loss: 0.2556392
	speed: 0.1173s/iter; left time: 840.6850s
	iters: 400, epoch: 4 | loss: 0.1779958
	speed: 0.1122s/iter; left time: 792.9539s
	iters: 500, epoch: 4 | loss: 0.2563034
	speed: 0.1150s/iter; left time: 801.5683s
	iters: 600, epoch: 4 | loss: 0.4444916
	speed: 0.1160s/iter; left time: 796.6330s
	iters: 700, epoch: 4 | loss: 0.3651814
	speed: 0.1111s/iter; left time: 752.0175s
	iters: 800, epoch: 4 | loss: 0.2141831
	speed: 0.1148s/iter; left time: 765.5384s
	iters: 900, epoch: 4 | loss: 0.2346285
	speed: 0.1136s/iter; left time: 746.3976s
	iters: 1000, epoch: 4 | loss: 0.4611729
	speed: 0.1183s/iter; left time: 765.1198s
Epoch: 4 cost time: 122.72216582298279
Epoch: 4, Steps: 1067 | Train Loss: 0.4072525 Vali Loss: 0.2186400 Test Loss: 0.3062979
Validation loss decreased (0.219666 --> 0.218640).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2425238
	speed: 2.7017s/iter; left time: 17029.0876s
	iters: 200, epoch: 5 | loss: 0.4737009
	speed: 0.1055s/iter; left time: 654.3653s
	iters: 300, epoch: 5 | loss: 0.5402832
	speed: 0.1093s/iter; left time: 666.9830s
	iters: 400, epoch: 5 | loss: 0.2216462
	speed: 0.1105s/iter; left time: 663.3176s
	iters: 500, epoch: 5 | loss: 0.6053304
	speed: 0.1125s/iter; left time: 664.0736s
	iters: 600, epoch: 5 | loss: 0.6845051
	speed: 0.1119s/iter; left time: 649.3991s
	iters: 700, epoch: 5 | loss: 0.2982384
	speed: 0.1113s/iter; left time: 634.8691s
	iters: 800, epoch: 5 | loss: 0.2638729
	speed: 0.1088s/iter; left time: 609.4638s
	iters: 900, epoch: 5 | loss: 0.5958034
	speed: 0.1054s/iter; left time: 579.9839s
	iters: 1000, epoch: 5 | loss: 0.3390895
	speed: 0.1091s/iter; left time: 589.6158s
Epoch: 5 cost time: 117.23950386047363
Epoch: 5, Steps: 1067 | Train Loss: 0.4050937 Vali Loss: 0.2188309 Test Loss: 0.3069413
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2989442
	speed: 2.5087s/iter; left time: 13135.4110s
	iters: 200, epoch: 6 | loss: 0.3202000
	speed: 0.1085s/iter; left time: 557.3945s
	iters: 300, epoch: 6 | loss: 0.7379307
	speed: 0.1097s/iter; left time: 552.5082s
	iters: 400, epoch: 6 | loss: 0.3393613
	speed: 0.1057s/iter; left time: 521.6012s
	iters: 500, epoch: 6 | loss: 0.2221064
	speed: 0.1116s/iter; left time: 539.5793s
	iters: 600, epoch: 6 | loss: 0.1674318
	speed: 0.1099s/iter; left time: 520.5001s
	iters: 700, epoch: 6 | loss: 0.2680924
	speed: 0.1066s/iter; left time: 494.1012s
	iters: 800, epoch: 6 | loss: 0.5188993
	speed: 0.1092s/iter; left time: 495.3720s
	iters: 900, epoch: 6 | loss: 0.4131307
	speed: 0.1078s/iter; left time: 478.3463s
	iters: 1000, epoch: 6 | loss: 0.5770614
	speed: 0.1125s/iter; left time: 487.7444s
Epoch: 6 cost time: 117.01464605331421
Epoch: 6, Steps: 1067 | Train Loss: 0.4034829 Vali Loss: 0.2188043 Test Loss: 0.3067819
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2931388
	speed: 2.7038s/iter; left time: 11272.2380s
	iters: 200, epoch: 7 | loss: 0.5200900
	speed: 0.1173s/iter; left time: 477.4298s
	iters: 300, epoch: 7 | loss: 0.2478420
	speed: 0.1124s/iter; left time: 446.1124s
	iters: 400, epoch: 7 | loss: 0.5411739
	speed: 0.1150s/iter; left time: 444.8908s
	iters: 500, epoch: 7 | loss: 0.7661108
	speed: 0.1152s/iter; left time: 434.1792s
	iters: 600, epoch: 7 | loss: 0.7446097
	speed: 0.1112s/iter; left time: 407.8857s
	iters: 700, epoch: 7 | loss: 0.2224236
	speed: 0.1115s/iter; left time: 397.8530s
	iters: 800, epoch: 7 | loss: 0.2787292
	speed: 0.1116s/iter; left time: 387.0184s
	iters: 900, epoch: 7 | loss: 0.3973654
	speed: 0.1148s/iter; left time: 386.7488s
	iters: 1000, epoch: 7 | loss: 0.2761289
	speed: 0.1134s/iter; left time: 370.7837s
Epoch: 7 cost time: 121.98482036590576
Epoch: 7, Steps: 1067 | Train Loss: 0.4030946 Vali Loss: 0.2188280 Test Loss: 0.3069502
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm2_96_336_PatchMLP_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.30653321743011475, mae:0.3434702455997467, rmse:0.5536544322967529, mape:1.426724910736084, mspe:310.92840576171875
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm2_96_720        Model:              PatchMLP            

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm2_96_720_PatchMLP_2048_fixedFalse_0.0001_0.001_CI>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5024744
	speed: 0.2115s/iter; left time: 537.3367s
	iters: 200, epoch: 1 | loss: 0.7364291
	speed: 0.2103s/iter; left time: 513.4021s
Epoch: 1 cost time: 56.26000952720642
Epoch: 1, Steps: 264 | Train Loss: 0.6138531 Vali Loss: 0.3073949 Test Loss: 0.4225915
Validation loss decreased (inf --> 0.307395).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3709225
	speed: 1.2279s/iter; left time: 2795.9442s
	iters: 200, epoch: 2 | loss: 0.6279222
	speed: 0.2145s/iter; left time: 467.0175s
Epoch: 2 cost time: 58.85086393356323
Epoch: 2, Steps: 264 | Train Loss: 0.5476514 Vali Loss: 0.3152574 Test Loss: 0.4283110
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6682320
	speed: 1.2827s/iter; left time: 2582.0380s
	iters: 200, epoch: 3 | loss: 0.4242042
	speed: 0.2506s/iter; left time: 479.4488s
Epoch: 3 cost time: 65.8851809501648
Epoch: 3, Steps: 264 | Train Loss: 0.5181843 Vali Loss: 0.3155382 Test Loss: 0.4286207
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5659267
	speed: 1.3432s/iter; left time: 2349.2715s
	iters: 200, epoch: 4 | loss: 0.4429654
	speed: 0.2452s/iter; left time: 404.3535s
Epoch: 4 cost time: 65.09709692001343
Epoch: 4, Steps: 264 | Train Loss: 0.5071932 Vali Loss: 0.3150797 Test Loss: 0.4290906
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm2_96_720_PatchMLP_2048_fixedFalse_0.0001_0.001_CI<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.4196990728378296, mae:0.4128158688545227, rmse:0.6478418707847595, mape:1.6912736892700195, mspe:430.1995849609375
