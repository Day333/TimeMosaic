Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_96         Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4137251
	speed: 0.2313s/iter; left time: 2463.5833s
	iters: 200, epoch: 1 | loss: 0.4115053
	speed: 0.2307s/iter; left time: 2434.2186s
	iters: 300, epoch: 1 | loss: 0.3949969
	speed: 0.2257s/iter; left time: 2358.6469s
	iters: 400, epoch: 1 | loss: 0.3070329
	speed: 0.2159s/iter; left time: 2235.2983s
	iters: 500, epoch: 1 | loss: 0.3013275
	speed: 0.2301s/iter; left time: 2358.4428s
	iters: 600, epoch: 1 | loss: 0.2938636
	speed: 0.2197s/iter; left time: 2230.6166s
	iters: 700, epoch: 1 | loss: 0.3216852
	speed: 0.2113s/iter; left time: 2123.4688s
	iters: 800, epoch: 1 | loss: 0.3274186
	speed: 0.2241s/iter; left time: 2229.6123s
	iters: 900, epoch: 1 | loss: 0.3255163
	speed: 0.2309s/iter; left time: 2274.8250s
	iters: 1000, epoch: 1 | loss: 0.3203992
	speed: 0.2301s/iter; left time: 2243.7934s
Epoch: 1 cost time: 240.93556666374207
Epoch: 1, Steps: 1075 | Train Loss: 0.3455147 Vali Loss: 0.4159215 Test Loss: 0.3367646
Validation loss decreased (inf --> 0.415922).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3651729
	speed: 1.2569s/iter; left time: 12036.3462s
	iters: 200, epoch: 2 | loss: 0.2585096
	speed: 0.2315s/iter; left time: 2193.5480s
	iters: 300, epoch: 2 | loss: 0.3041135
	speed: 0.2243s/iter; left time: 2102.9971s
	iters: 400, epoch: 2 | loss: 0.3697234
	speed: 0.2072s/iter; left time: 1921.6672s
	iters: 500, epoch: 2 | loss: 0.2597628
	speed: 0.2243s/iter; left time: 2057.8792s
	iters: 600, epoch: 2 | loss: 0.3265950
	speed: 0.2227s/iter; left time: 2020.9121s
	iters: 700, epoch: 2 | loss: 0.3254799
	speed: 0.2062s/iter; left time: 1850.9573s
	iters: 800, epoch: 2 | loss: 0.3138115
	speed: 0.2163s/iter; left time: 1920.2671s
	iters: 900, epoch: 2 | loss: 0.2771727
	speed: 0.2201s/iter; left time: 1931.7108s
	iters: 1000, epoch: 2 | loss: 0.3151079
	speed: 0.2130s/iter; left time: 1848.2894s
Epoch: 2 cost time: 233.26654839515686
Epoch: 2, Steps: 1075 | Train Loss: 0.3202369 Vali Loss: 0.4231760 Test Loss: 0.3386363
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3176099
	speed: 1.2223s/iter; left time: 10391.0585s
	iters: 200, epoch: 3 | loss: 0.3074861
	speed: 0.2313s/iter; left time: 1943.2193s
	iters: 300, epoch: 3 | loss: 0.2989990
	speed: 0.2108s/iter; left time: 1749.6967s
	iters: 400, epoch: 3 | loss: 0.3379770
	speed: 0.1946s/iter; left time: 1595.6725s
	iters: 500, epoch: 3 | loss: 0.2779777
	speed: 0.2313s/iter; left time: 1873.5758s
	iters: 600, epoch: 3 | loss: 0.3381512
	speed: 0.2306s/iter; left time: 1845.0547s
	iters: 700, epoch: 3 | loss: 0.2840088
	speed: 0.2162s/iter; left time: 1708.1269s
	iters: 800, epoch: 3 | loss: 0.2683802
	speed: 0.2173s/iter; left time: 1694.7881s
	iters: 900, epoch: 3 | loss: 0.2935852
	speed: 0.2270s/iter; left time: 1748.4505s
	iters: 1000, epoch: 3 | loss: 0.2149637
	speed: 0.2154s/iter; left time: 1637.5596s
Epoch: 3 cost time: 237.77082920074463
Epoch: 3, Steps: 1075 | Train Loss: 0.3068305 Vali Loss: 0.4049281 Test Loss: 0.3337532
Validation loss decreased (0.415922 --> 0.404928).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3097409
	speed: 1.2937s/iter; left time: 9607.2436s
	iters: 200, epoch: 4 | loss: 0.2687972
	speed: 0.2241s/iter; left time: 1642.0873s
	iters: 300, epoch: 4 | loss: 0.2800695
	speed: 0.2221s/iter; left time: 1605.0448s
	iters: 400, epoch: 4 | loss: 0.2954102
	speed: 0.2043s/iter; left time: 1455.5197s
	iters: 500, epoch: 4 | loss: 0.3296769
	speed: 0.1769s/iter; left time: 1242.6527s
	iters: 600, epoch: 4 | loss: 0.2506338
	speed: 0.1802s/iter; left time: 1248.3667s
	iters: 700, epoch: 4 | loss: 0.3352208
	speed: 0.1729s/iter; left time: 1179.9887s
	iters: 800, epoch: 4 | loss: 0.2991707
	speed: 0.1566s/iter; left time: 1053.2740s
	iters: 900, epoch: 4 | loss: 0.3333220
	speed: 0.1662s/iter; left time: 1101.3619s
	iters: 1000, epoch: 4 | loss: 0.2848112
	speed: 0.1836s/iter; left time: 1198.4381s
Epoch: 4 cost time: 204.07813811302185
Epoch: 4, Steps: 1075 | Train Loss: 0.3010726 Vali Loss: 0.4127491 Test Loss: 0.3238096
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3534733
	speed: 1.0523s/iter; left time: 6683.1991s
	iters: 200, epoch: 5 | loss: 0.3102091
	speed: 0.1895s/iter; left time: 1184.6593s
	iters: 300, epoch: 5 | loss: 0.2437761
	speed: 0.1908s/iter; left time: 1173.8172s
	iters: 400, epoch: 5 | loss: 0.3271747
	speed: 0.1882s/iter; left time: 1138.9720s
	iters: 500, epoch: 5 | loss: 0.3980201
	speed: 0.1802s/iter; left time: 1072.5931s
	iters: 600, epoch: 5 | loss: 0.3157122
	speed: 0.1847s/iter; left time: 1080.6901s
	iters: 700, epoch: 5 | loss: 0.3411957
	speed: 0.1789s/iter; left time: 1028.7072s
	iters: 800, epoch: 5 | loss: 0.3038983
	speed: 0.1872s/iter; left time: 1057.9483s
	iters: 900, epoch: 5 | loss: 0.2920813
	speed: 0.1818s/iter; left time: 1009.0600s
	iters: 1000, epoch: 5 | loss: 0.3250411
	speed: 0.1907s/iter; left time: 1039.6876s
Epoch: 5 cost time: 198.95144271850586
Epoch: 5, Steps: 1075 | Train Loss: 0.2979573 Vali Loss: 0.4080285 Test Loss: 0.3247416
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3076226
	speed: 1.0287s/iter; left time: 5427.4815s
	iters: 200, epoch: 6 | loss: 0.2533545
	speed: 0.1666s/iter; left time: 862.5777s
	iters: 300, epoch: 6 | loss: 0.2942529
	speed: 0.1680s/iter; left time: 852.7283s
	iters: 400, epoch: 6 | loss: 0.2744537
	speed: 0.1726s/iter; left time: 858.7069s
	iters: 500, epoch: 6 | loss: 0.3224457
	speed: 0.1700s/iter; left time: 828.8201s
	iters: 600, epoch: 6 | loss: 0.3029997
	speed: 0.1610s/iter; left time: 769.1087s
	iters: 700, epoch: 6 | loss: 0.2979326
	speed: 0.1878s/iter; left time: 878.0568s
	iters: 800, epoch: 6 | loss: 0.2942357
	speed: 0.1913s/iter; left time: 875.3813s
	iters: 900, epoch: 6 | loss: 0.2587498
	speed: 0.1912s/iter; left time: 855.9243s
	iters: 1000, epoch: 6 | loss: 0.2621900
	speed: 0.1810s/iter; left time: 792.1370s
Epoch: 6 cost time: 190.49222493171692
Epoch: 6, Steps: 1075 | Train Loss: 0.2968327 Vali Loss: 0.4113043 Test Loss: 0.3221645
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.3345101475715637, mae:0.36894652247428894
================================================================================
Model Profiling Summary
Total Params             : 3,830,115
Inference Time (s)       : 0.071653
GPU Mem Footprint (MB)   : 55.78
Peak Mem (MB)            : 149.97
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_192        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3801602
	speed: 1.3557s/iter; left time: 3499.0463s
	iters: 200, epoch: 1 | loss: 0.3712580
	speed: 1.2726s/iter; left time: 3157.3408s
Epoch: 1 cost time: 353.2831470966339
Epoch: 1, Steps: 268 | Train Loss: 0.3818470 Vali Loss: 0.5414912 Test Loss: 0.3820246
Validation loss decreased (inf --> 0.541491).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3977683
	speed: 2.7296s/iter; left time: 6313.6012s
	iters: 200, epoch: 2 | loss: 0.3537990
	speed: 1.1049s/iter; left time: 2445.1591s
Epoch: 2 cost time: 302.52197790145874
Epoch: 2, Steps: 268 | Train Loss: 0.3606220 Vali Loss: 0.5421854 Test Loss: 0.3803476
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3602270
	speed: 2.1169s/iter; left time: 4329.0837s
	iters: 200, epoch: 3 | loss: 0.3342273
	speed: 0.9402s/iter; left time: 1828.6580s
Epoch: 3 cost time: 251.57664465904236
Epoch: 3, Steps: 268 | Train Loss: 0.3503646 Vali Loss: 0.5272692 Test Loss: 0.3728816
Validation loss decreased (0.541491 --> 0.527269).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3325537
	speed: 1.9351s/iter; left time: 3438.6637s
	iters: 200, epoch: 4 | loss: 0.3772866
	speed: 0.9387s/iter; left time: 1574.2128s
Epoch: 4 cost time: 248.80813264846802
Epoch: 4, Steps: 268 | Train Loss: 0.3453674 Vali Loss: 0.5257387 Test Loss: 0.3705325
Validation loss decreased (0.527269 --> 0.525739).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3313760
	speed: 2.1665s/iter; left time: 3269.2720s
	iters: 200, epoch: 5 | loss: 0.3145323
	speed: 0.9873s/iter; left time: 1391.0506s
Epoch: 5 cost time: 267.1798105239868
Epoch: 5, Steps: 268 | Train Loss: 0.3427240 Vali Loss: 0.5309088 Test Loss: 0.3697543
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3390138
	speed: 2.1611s/iter; left time: 2681.9377s
	iters: 200, epoch: 6 | loss: 0.3639640
	speed: 0.9876s/iter; left time: 1126.8355s
Epoch: 6 cost time: 267.171648979187
Epoch: 6, Steps: 268 | Train Loss: 0.3414252 Vali Loss: 0.5310560 Test Loss: 0.3689618
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3379409
	speed: 2.1497s/iter; left time: 2091.6985s
	iters: 200, epoch: 7 | loss: 0.3258964
	speed: 0.9668s/iter; left time: 843.9877s
Epoch: 7 cost time: 262.6585545539856
Epoch: 7, Steps: 268 | Train Loss: 0.3406706 Vali Loss: 0.5263584 Test Loss: 0.3710328
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.3709619343280792, mae:0.38810092210769653
================================================================================
Model Profiling Summary
Total Params             : 10,724,803
Inference Time (s)       : 0.270281
GPU Mem Footprint (MB)   : 112.04
Peak Mem (MB)            : 503.02
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_336        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3829506
	speed: 0.3876s/iter; left time: 996.5236s
	iters: 200, epoch: 1 | loss: 0.4008847
	speed: 0.3717s/iter; left time: 918.5161s
Epoch: 1 cost time: 100.6272349357605
Epoch: 1, Steps: 267 | Train Loss: 0.4403139 Vali Loss: 0.6861547 Test Loss: 0.4162909
Validation loss decreased (inf --> 0.686155).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4086330
	speed: 0.8660s/iter; left time: 1995.3218s
	iters: 200, epoch: 2 | loss: 0.4073178
	speed: 0.3889s/iter; left time: 857.1327s
Epoch: 2 cost time: 103.93002653121948
Epoch: 2, Steps: 267 | Train Loss: 0.4181710 Vali Loss: 0.6878462 Test Loss: 0.4123922
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3834544
	speed: 0.8931s/iter; left time: 1819.2188s
	iters: 200, epoch: 3 | loss: 0.4048848
	speed: 0.3898s/iter; left time: 755.1027s
Epoch: 3 cost time: 103.6443989276886
Epoch: 3, Steps: 267 | Train Loss: 0.4094434 Vali Loss: 0.6793080 Test Loss: 0.4059876
Validation loss decreased (0.686155 --> 0.679308).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4130895
	speed: 0.8659s/iter; left time: 1532.5693s
	iters: 200, epoch: 4 | loss: 0.3835146
	speed: 0.3904s/iter; left time: 651.9037s
Epoch: 4 cost time: 102.86741590499878
Epoch: 4, Steps: 267 | Train Loss: 0.4061765 Vali Loss: 0.6769934 Test Loss: 0.4029008
Validation loss decreased (0.679308 --> 0.676993).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3805422
	speed: 0.8924s/iter; left time: 1341.3060s
	iters: 200, epoch: 5 | loss: 0.4192390
	speed: 0.3906s/iter; left time: 548.0070s
Epoch: 5 cost time: 104.1439700126648
Epoch: 5, Steps: 267 | Train Loss: 0.4042918 Vali Loss: 0.6768128 Test Loss: 0.4027594
Validation loss decreased (0.676993 --> 0.676813).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4228019
	speed: 0.8813s/iter; left time: 1089.3225s
	iters: 200, epoch: 6 | loss: 0.4149953
	speed: 0.3638s/iter; left time: 413.3206s
Epoch: 6 cost time: 96.19550228118896
Epoch: 6, Steps: 267 | Train Loss: 0.4034074 Vali Loss: 0.6721759 Test Loss: 0.4019975
Validation loss decreased (0.676813 --> 0.672176).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3927642
	speed: 0.7615s/iter; left time: 737.8758s
	iters: 200, epoch: 7 | loss: 0.3989159
	speed: 0.3316s/iter; left time: 288.1660s
Epoch: 7 cost time: 88.54819369316101
Epoch: 7, Steps: 267 | Train Loss: 0.4028548 Vali Loss: 0.6763057 Test Loss: 0.4016379
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3963242
	speed: 0.7395s/iter; left time: 519.1560s
	iters: 200, epoch: 8 | loss: 0.4258784
	speed: 0.3064s/iter; left time: 184.4655s
Epoch: 8 cost time: 83.8636200428009
Epoch: 8, Steps: 267 | Train Loss: 0.4027305 Vali Loss: 0.6763693 Test Loss: 0.4012367
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3816326
	speed: 0.7617s/iter; left time: 331.3542s
	iters: 200, epoch: 9 | loss: 0.4075045
	speed: 0.3315s/iter; left time: 111.0676s
Epoch: 9 cost time: 88.55529832839966
Epoch: 9, Steps: 267 | Train Loss: 0.4024667 Vali Loss: 0.6754134 Test Loss: 0.4016084
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.40139877796173096, mae:0.40875276923179626
================================================================================
Model Profiling Summary
Total Params             : 5,304,915
Inference Time (s)       : 0.096699
GPU Mem Footprint (MB)   : 72.52
Peak Mem (MB)            : 437.16
================================================================================
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm1_96_720        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm1_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5711020
	speed: 0.8618s/iter; left time: 2189.9458s
	iters: 200, epoch: 1 | loss: 0.4988828
	speed: 0.8635s/iter; left time: 2107.8723s
Epoch: 1 cost time: 224.82466769218445
Epoch: 1, Steps: 264 | Train Loss: 0.5001341 Vali Loss: 0.9913918 Test Loss: 0.4703006
Validation loss decreased (inf --> 0.991392).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4622737
	speed: 1.7762s/iter; left time: 4044.3479s
	iters: 200, epoch: 2 | loss: 0.4838530
	speed: 0.8058s/iter; left time: 1754.2769s
Epoch: 2 cost time: 219.95745754241943
Epoch: 2, Steps: 264 | Train Loss: 0.4790595 Vali Loss: 0.9810984 Test Loss: 0.4707965
Validation loss decreased (0.991392 --> 0.981098).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5074040
	speed: 1.7863s/iter; left time: 3595.7550s
	iters: 200, epoch: 3 | loss: 0.4616950
	speed: 0.8679s/iter; left time: 1660.3285s
Epoch: 3 cost time: 225.22569179534912
Epoch: 3, Steps: 264 | Train Loss: 0.4688723 Vali Loss: 0.9912786 Test Loss: 0.4642522
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4424663
	speed: 1.7993s/iter; left time: 3146.9178s
	iters: 200, epoch: 4 | loss: 0.4672311
	speed: 0.8699s/iter; left time: 1434.5173s
Epoch: 4 cost time: 224.0761034488678
Epoch: 4, Steps: 264 | Train Loss: 0.4630678 Vali Loss: 0.9791883 Test Loss: 0.4614972
Validation loss decreased (0.981098 --> 0.979188).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4187424
	speed: 1.8047s/iter; left time: 2680.0535s
	iters: 200, epoch: 5 | loss: 0.4928567
	speed: 0.8308s/iter; left time: 1150.6973s
Epoch: 5 cost time: 225.61726784706116
Epoch: 5, Steps: 264 | Train Loss: 0.4603296 Vali Loss: 0.9799256 Test Loss: 0.4600148
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4542143
	speed: 1.8140s/iter; left time: 2214.8504s
	iters: 200, epoch: 6 | loss: 0.4522096
	speed: 0.8682s/iter; left time: 973.3070s
Epoch: 6 cost time: 235.4121172428131
Epoch: 6, Steps: 264 | Train Loss: 0.4585638 Vali Loss: 0.9823588 Test Loss: 0.4582099
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5217136
	speed: 2.1466s/iter; left time: 2054.2517s
	iters: 200, epoch: 7 | loss: 0.4212805
	speed: 0.9837s/iter; left time: 843.0354s
Epoch: 7 cost time: 264.46522641181946
Epoch: 7, Steps: 264 | Train Loss: 0.4576036 Vali Loss: 0.9802548 Test Loss: 0.4597661
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm1_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.460568904876709, mae:0.44641467928886414
================================================================================
Model Profiling Summary
Total Params             : 13,969,363
Inference Time (s)       : 0.276335
GPU Mem Footprint (MB)   : 144.09
Peak Mem (MB)            : 534.77
================================================================================
