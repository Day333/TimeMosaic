Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS03              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS03.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             358                 Dec In:             358                 
  C Out:              358                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15617
val 5135
test 5135
	iters: 100, epoch: 1 | loss: 0.2410136
	speed: 0.3620s/iter; left time: 1734.5105s
	iters: 200, epoch: 1 | loss: 0.1961690
	speed: 0.3310s/iter; left time: 1552.7374s
	iters: 300, epoch: 1 | loss: 0.2548554
	speed: 0.3451s/iter; left time: 1584.5013s
	iters: 400, epoch: 1 | loss: 0.2221420
	speed: 0.3468s/iter; left time: 1557.3653s
Epoch: 1 cost time: 167.29643082618713
Epoch: 1, Steps: 489 | Train Loss: 0.2507309 Vali Loss: 0.1399979 Test Loss: 0.1382285
Validation loss decreased (inf --> 0.139998).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1822216
	speed: 1.1587s/iter; left time: 4984.8936s
	iters: 200, epoch: 2 | loss: 0.2154800
	speed: 0.3125s/iter; left time: 1313.3059s
	iters: 300, epoch: 2 | loss: 0.1995906
	speed: 0.2740s/iter; left time: 1123.7722s
	iters: 400, epoch: 2 | loss: 0.2202242
	speed: 0.2783s/iter; left time: 1113.7069s
Epoch: 2 cost time: 145.15718507766724
Epoch: 2, Steps: 489 | Train Loss: 0.2077242 Vali Loss: 0.1619712 Test Loss: 0.1618009
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1974706
	speed: 1.1739s/iter; left time: 4476.1142s
	iters: 200, epoch: 3 | loss: 0.1860173
	speed: 0.3440s/iter; left time: 1277.3435s
	iters: 300, epoch: 3 | loss: 0.2161361
	speed: 0.3444s/iter; left time: 1244.4639s
	iters: 400, epoch: 3 | loss: 0.2048576
	speed: 0.3094s/iter; left time: 1086.8704s
Epoch: 3 cost time: 161.1699116230011
Epoch: 3, Steps: 489 | Train Loss: 0.1975698 Vali Loss: 0.1117890 Test Loss: 0.1131776
Validation loss decreased (0.139998 --> 0.111789).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1924537
	speed: 1.1147s/iter; left time: 3705.1602s
	iters: 200, epoch: 4 | loss: 0.1810834
	speed: 0.2941s/iter; left time: 948.2860s
	iters: 300, epoch: 4 | loss: 0.1907638
	speed: 0.2830s/iter; left time: 884.0659s
	iters: 400, epoch: 4 | loss: 0.1884256
	speed: 0.3407s/iter; left time: 1030.2775s
Epoch: 4 cost time: 151.88621282577515
Epoch: 4, Steps: 489 | Train Loss: 0.1927155 Vali Loss: 0.0932336 Test Loss: 0.0954658
Validation loss decreased (0.111789 --> 0.093234).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2106988
	speed: 1.1545s/iter; left time: 3272.9584s
	iters: 200, epoch: 5 | loss: 0.2008079
	speed: 0.3214s/iter; left time: 879.1066s
	iters: 300, epoch: 5 | loss: 0.1710262
	speed: 0.2981s/iter; left time: 785.5579s
	iters: 400, epoch: 5 | loss: 0.1846374
	speed: 0.3180s/iter; left time: 806.1806s
Epoch: 5 cost time: 153.19261074066162
Epoch: 5, Steps: 489 | Train Loss: 0.1897999 Vali Loss: 0.0970676 Test Loss: 0.0986280
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1654888
	speed: 1.1708s/iter; left time: 2746.7366s
	iters: 200, epoch: 6 | loss: 0.1922899
	speed: 0.3050s/iter; left time: 684.9365s
	iters: 300, epoch: 6 | loss: 0.1925871
	speed: 0.3237s/iter; left time: 694.7003s
	iters: 400, epoch: 6 | loss: 0.1688269
	speed: 0.3221s/iter; left time: 659.0623s
Epoch: 6 cost time: 149.00510358810425
Epoch: 6, Steps: 489 | Train Loss: 0.1880862 Vali Loss: 0.0897025 Test Loss: 0.0916265
Validation loss decreased (0.093234 --> 0.089703).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1964912
	speed: 1.1190s/iter; left time: 2077.9172s
	iters: 200, epoch: 7 | loss: 0.1977374
	speed: 0.3544s/iter; left time: 622.7666s
	iters: 300, epoch: 7 | loss: 0.1852112
	speed: 0.3131s/iter; left time: 518.7814s
	iters: 400, epoch: 7 | loss: 0.1782118
	speed: 0.3391s/iter; left time: 528.0231s
Epoch: 7 cost time: 158.9661304950714
Epoch: 7, Steps: 489 | Train Loss: 0.1870265 Vali Loss: 0.0886058 Test Loss: 0.0903590
Validation loss decreased (0.089703 --> 0.088606).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2408367
	speed: 1.0926s/iter; left time: 1494.6302s
	iters: 200, epoch: 8 | loss: 0.2037961
	speed: 0.3247s/iter; left time: 411.6919s
	iters: 300, epoch: 8 | loss: 0.2110796
	speed: 0.3325s/iter; left time: 388.3642s
	iters: 400, epoch: 8 | loss: 0.1967881
	speed: 0.3253s/iter; left time: 347.3949s
Epoch: 8 cost time: 154.9431025981903
Epoch: 8, Steps: 489 | Train Loss: 0.1871879 Vali Loss: 0.0910371 Test Loss: 0.0929818
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1498783
	speed: 1.2486s/iter; left time: 1097.4924s
	iters: 200, epoch: 9 | loss: 0.1678008
	speed: 0.2942s/iter; left time: 229.1734s
	iters: 300, epoch: 9 | loss: 0.1665897
	speed: 0.2353s/iter; left time: 159.7539s
	iters: 400, epoch: 9 | loss: 0.1852274
	speed: 0.2676s/iter; left time: 154.9205s
Epoch: 9 cost time: 133.58489990234375
Epoch: 9, Steps: 489 | Train Loss: 0.1873531 Vali Loss: 0.0926198 Test Loss: 0.0946303
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1827120
	speed: 1.0928s/iter; left time: 426.1818s
	iters: 200, epoch: 10 | loss: 0.1655590
	speed: 0.3259s/iter; left time: 94.5084s
	iters: 300, epoch: 10 | loss: 0.1942736
	speed: 0.3013s/iter; left time: 57.2561s
	iters: 400, epoch: 10 | loss: 0.2068917
	speed: 0.3216s/iter; left time: 28.9458s
Epoch: 10 cost time: 152.6819965839386
Epoch: 10, Steps: 489 | Train Loss: 0.1861643 Vali Loss: 0.0909664 Test Loss: 0.0929374
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5135
test shape: (5135, 12, 358) (5135, 12, 358)
test shape: (5135, 12, 358) (5135, 12, 358)
mse:0.09039562195539474, mae:0.20706748962402344
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS04              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS04.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             307                 Dec In:             307                 
  C Out:              307                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10088
val 3291
test 3292
	iters: 100, epoch: 1 | loss: 0.2431923
	speed: 0.1689s/iter; left time: 517.1471s
	iters: 200, epoch: 1 | loss: 0.2226894
	speed: 0.1618s/iter; left time: 478.9815s
	iters: 300, epoch: 1 | loss: 0.2545962
	speed: 0.2334s/iter; left time: 667.7533s
Epoch: 1 cost time: 60.79690337181091
Epoch: 1, Steps: 316 | Train Loss: 0.2729750 Vali Loss: 0.3710478 Test Loss: 0.3473413
Validation loss decreased (inf --> 0.371048).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2248006
	speed: 0.6000s/iter; left time: 1647.0304s
	iters: 200, epoch: 2 | loss: 0.2294411
	speed: 0.2372s/iter; left time: 627.3379s
	iters: 300, epoch: 2 | loss: 0.2121712
	speed: 0.2344s/iter; left time: 596.6407s
Epoch: 2 cost time: 79.01910519599915
Epoch: 2, Steps: 316 | Train Loss: 0.2260376 Vali Loss: 0.1383095 Test Loss: 0.1307945
Validation loss decreased (0.371048 --> 0.138309).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1922395
	speed: 0.6094s/iter; left time: 1480.1995s
	iters: 200, epoch: 3 | loss: 0.2160404
	speed: 0.2542s/iter; left time: 591.9881s
	iters: 300, epoch: 3 | loss: 0.1853403
	speed: 0.2248s/iter; left time: 501.1854s
Epoch: 3 cost time: 79.3774483203888
Epoch: 3, Steps: 316 | Train Loss: 0.2087863 Vali Loss: 0.1217951 Test Loss: 0.1167731
Validation loss decreased (0.138309 --> 0.121795).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1764978
	speed: 0.5577s/iter; left time: 1178.3297s
	iters: 200, epoch: 4 | loss: 0.1893514
	speed: 0.2385s/iter; left time: 480.0369s
	iters: 300, epoch: 4 | loss: 0.2012251
	speed: 0.1855s/iter; left time: 354.8340s
Epoch: 4 cost time: 69.44097638130188
Epoch: 4, Steps: 316 | Train Loss: 0.2049699 Vali Loss: 0.1185821 Test Loss: 0.1130193
Validation loss decreased (0.121795 --> 0.118582).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1916018
	speed: 0.5794s/iter; left time: 1041.1182s
	iters: 200, epoch: 5 | loss: 0.2135909
	speed: 0.2729s/iter; left time: 463.1576s
	iters: 300, epoch: 5 | loss: 0.1970744
	speed: 0.2495s/iter; left time: 398.4770s
Epoch: 5 cost time: 83.20997428894043
Epoch: 5, Steps: 316 | Train Loss: 0.2029615 Vali Loss: 0.1161219 Test Loss: 0.1110636
Validation loss decreased (0.118582 --> 0.116122).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1952419
	speed: 0.5721s/iter; left time: 847.2132s
	iters: 200, epoch: 6 | loss: 0.1921706
	speed: 0.2737s/iter; left time: 378.0369s
	iters: 300, epoch: 6 | loss: 0.2184215
	speed: 0.2704s/iter; left time: 346.3524s
Epoch: 6 cost time: 85.41484236717224
Epoch: 6, Steps: 316 | Train Loss: 0.2019740 Vali Loss: 0.1140397 Test Loss: 0.1087336
Validation loss decreased (0.116122 --> 0.114040).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2068732
	speed: 0.5198s/iter; left time: 605.5683s
	iters: 200, epoch: 7 | loss: 0.1999271
	speed: 0.2329s/iter; left time: 248.0565s
	iters: 300, epoch: 7 | loss: 0.1872067
	speed: 0.2334s/iter; left time: 225.1835s
Epoch: 7 cost time: 73.88870215415955
Epoch: 7, Steps: 316 | Train Loss: 0.2016186 Vali Loss: 0.1159570 Test Loss: 0.1106328
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2017156
	speed: 0.4738s/iter; left time: 402.2153s
	iters: 200, epoch: 8 | loss: 0.2180715
	speed: 0.2815s/iter; left time: 210.8429s
	iters: 300, epoch: 8 | loss: 0.2281486
	speed: 0.2791s/iter; left time: 181.1455s
Epoch: 8 cost time: 83.28075575828552
Epoch: 8, Steps: 316 | Train Loss: 0.2011188 Vali Loss: 0.1165641 Test Loss: 0.1113355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1898648
	speed: 0.5696s/iter; left time: 303.6019s
	iters: 200, epoch: 9 | loss: 0.1802746
	speed: 0.2757s/iter; left time: 119.3774s
	iters: 300, epoch: 9 | loss: 0.2268580
	speed: 0.2773s/iter; left time: 92.3426s
Epoch: 9 cost time: 85.0253643989563
Epoch: 9, Steps: 316 | Train Loss: 0.2009588 Vali Loss: 0.1185488 Test Loss: 0.1130707
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1866792
	speed: 0.5505s/iter; left time: 119.4532s
	iters: 200, epoch: 10 | loss: 0.2218310
	speed: 0.2179s/iter; left time: 25.4993s
	iters: 300, epoch: 10 | loss: 0.2103059
	speed: 0.1916s/iter; left time: 3.2573s
Epoch: 10 cost time: 66.99723148345947
Epoch: 10, Steps: 316 | Train Loss: 0.2007842 Vali Loss: 0.1168146 Test Loss: 0.1115823
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3292
test shape: (3292, 12, 307) (3292, 12, 307)
test shape: (3292, 12, 307) (3292, 12, 307)
mse:0.10879100859165192, mae:0.22391283512115479
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS07              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS07.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             883                 Dec In:             883                 
  C Out:              883                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16827
val 5538
test 5538
	iters: 100, epoch: 1 | loss: 0.2687713
	speed: 0.5621s/iter; left time: 2900.9094s
	iters: 200, epoch: 1 | loss: 0.2418754
	speed: 0.5342s/iter; left time: 2703.5808s
	iters: 300, epoch: 1 | loss: 0.1796077
	speed: 0.5635s/iter; left time: 2795.6675s
	iters: 400, epoch: 1 | loss: 0.2149259
	speed: 0.5601s/iter; left time: 2722.5135s
	iters: 500, epoch: 1 | loss: 0.1928703
	speed: 0.4457s/iter; left time: 2122.1007s
Epoch: 1 cost time: 278.231463432312
Epoch: 1, Steps: 526 | Train Loss: 0.2509287 Vali Loss: 0.1090066 Test Loss: 0.1111570
Validation loss decreased (inf --> 0.109007).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2156925
	speed: 1.4352s/iter; left time: 6652.3826s
	iters: 200, epoch: 2 | loss: 0.1867502
	speed: 0.5565s/iter; left time: 2523.5115s
	iters: 300, epoch: 2 | loss: 0.1746047
	speed: 0.4855s/iter; left time: 2153.0013s
	iters: 400, epoch: 2 | loss: 0.1948880
	speed: 0.4288s/iter; left time: 1858.7863s
	iters: 500, epoch: 2 | loss: 0.1836227
	speed: 0.5415s/iter; left time: 2293.3068s
Epoch: 2 cost time: 272.36422204971313
Epoch: 2, Steps: 526 | Train Loss: 0.2031027 Vali Loss: 0.0873297 Test Loss: 0.0881985
Validation loss decreased (0.109007 --> 0.087330).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1623894
	speed: 1.4459s/iter; left time: 5941.1259s
	iters: 200, epoch: 3 | loss: 0.1858961
	speed: 0.5334s/iter; left time: 2138.5274s
	iters: 300, epoch: 3 | loss: 0.2016902
	speed: 0.4601s/iter; left time: 1798.5985s
	iters: 400, epoch: 3 | loss: 0.1613850
	speed: 0.5348s/iter; left time: 2037.1699s
	iters: 500, epoch: 3 | loss: 0.1715037
	speed: 0.5432s/iter; left time: 2014.5862s
Epoch: 3 cost time: 275.9280049800873
Epoch: 3, Steps: 526 | Train Loss: 0.1932043 Vali Loss: 0.0869027 Test Loss: 0.0885900
Validation loss decreased (0.087330 --> 0.086903).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1620629
	speed: 1.4125s/iter; left time: 5061.1371s
	iters: 200, epoch: 4 | loss: 0.1845607
	speed: 0.4587s/iter; left time: 1597.7275s
	iters: 300, epoch: 4 | loss: 0.1847957
	speed: 0.5655s/iter; left time: 1913.1111s
	iters: 400, epoch: 4 | loss: 0.1997191
	speed: 0.5631s/iter; left time: 1848.8125s
	iters: 500, epoch: 4 | loss: 0.1464773
	speed: 0.5273s/iter; left time: 1678.4864s
Epoch: 4 cost time: 273.00797033309937
Epoch: 4, Steps: 526 | Train Loss: 0.1903790 Vali Loss: 0.0859761 Test Loss: 0.0879198
Validation loss decreased (0.086903 --> 0.085976).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2147566
	speed: 1.3464s/iter; left time: 4115.9288s
	iters: 200, epoch: 5 | loss: 0.1921887
	speed: 0.4531s/iter; left time: 1339.7080s
	iters: 300, epoch: 5 | loss: 0.1692157
	speed: 0.6410s/iter; left time: 1831.2306s
	iters: 400, epoch: 5 | loss: 0.1859658
	speed: 0.6624s/iter; left time: 1826.1469s
	iters: 500, epoch: 5 | loss: 0.2095999
	speed: 0.5895s/iter; left time: 1566.3678s
Epoch: 5 cost time: 296.824556350708
Epoch: 5, Steps: 526 | Train Loss: 0.1885274 Vali Loss: 0.0877057 Test Loss: 0.0893458
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1922089
	speed: 1.6955s/iter; left time: 4291.2764s
	iters: 200, epoch: 6 | loss: 0.1854592
	speed: 0.6211s/iter; left time: 1509.9702s
	iters: 300, epoch: 6 | loss: 0.1453982
	speed: 0.6325s/iter; left time: 1474.3448s
	iters: 400, epoch: 6 | loss: 0.2040458
	speed: 0.6168s/iter; left time: 1376.1910s
	iters: 500, epoch: 6 | loss: 0.1917074
	speed: 0.5847s/iter; left time: 1246.0987s
Epoch: 6 cost time: 328.7070195674896
Epoch: 6, Steps: 526 | Train Loss: 0.1874923 Vali Loss: 0.0842022 Test Loss: 0.0853484
Validation loss decreased (0.085976 --> 0.084202).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1772740
	speed: 2.0870s/iter; left time: 4184.3417s
	iters: 200, epoch: 7 | loss: 0.1782621
	speed: 0.7543s/iter; left time: 1436.9498s
	iters: 300, epoch: 7 | loss: 0.1994679
	speed: 0.8146s/iter; left time: 1470.4266s
	iters: 400, epoch: 7 | loss: 0.1858078
	speed: 0.6821s/iter; left time: 1162.9998s
	iters: 500, epoch: 7 | loss: 0.1891986
	speed: 0.7941s/iter; left time: 1274.4888s
Epoch: 7 cost time: 401.50072622299194
Epoch: 7, Steps: 526 | Train Loss: 0.1869015 Vali Loss: 0.0841552 Test Loss: 0.0858074
Validation loss decreased (0.084202 --> 0.084155).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2026275
	speed: 1.6770s/iter; left time: 2480.2968s
	iters: 200, epoch: 8 | loss: 0.1677720
	speed: 0.5878s/iter; left time: 810.6257s
	iters: 300, epoch: 8 | loss: 0.2143132
	speed: 0.5866s/iter; left time: 750.2898s
	iters: 400, epoch: 8 | loss: 0.1932966
	speed: 0.5126s/iter; left time: 604.3290s
	iters: 500, epoch: 8 | loss: 0.2001934
	speed: 0.5886s/iter; left time: 635.1046s
Epoch: 8 cost time: 295.4281575679779
Epoch: 8, Steps: 526 | Train Loss: 0.1865620 Vali Loss: 0.0850433 Test Loss: 0.0867802
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1569129
	speed: 1.3523s/iter; left time: 1288.7299s
	iters: 200, epoch: 9 | loss: 0.2052869
	speed: 0.5874s/iter; left time: 501.0257s
	iters: 300, epoch: 9 | loss: 0.1866856
	speed: 0.5858s/iter; left time: 441.1335s
	iters: 400, epoch: 9 | loss: 0.2032503
	speed: 0.5160s/iter; left time: 336.9642s
	iters: 500, epoch: 9 | loss: 0.2011891
	speed: 0.5830s/iter; left time: 322.4100s
Epoch: 9 cost time: 286.7779335975647
Epoch: 9, Steps: 526 | Train Loss: 0.1863447 Vali Loss: 0.0834315 Test Loss: 0.0851200
Validation loss decreased (0.084155 --> 0.083431).  Saving model ...
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1909337
	speed: 1.5055s/iter; left time: 642.8337s
	iters: 200, epoch: 10 | loss: 0.1979046
	speed: 0.5868s/iter; left time: 191.8717s
	iters: 300, epoch: 10 | loss: 0.1967989
	speed: 0.5856s/iter; left time: 132.9210s
	iters: 400, epoch: 10 | loss: 0.1827991
	speed: 0.4983s/iter; left time: 63.2858s
	iters: 500, epoch: 10 | loss: 0.2109827
	speed: 0.5844s/iter; left time: 15.7785s
Epoch: 10 cost time: 295.352787733078
Epoch: 10, Steps: 526 | Train Loss: 0.1862669 Vali Loss: 0.0840730 Test Loss: 0.0858436
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5538
test shape: (5538, 12, 883) (5538, 12, 883)
test shape: (5538, 12, 883) (5538, 12, 883)
mse:0.0848744735121727, mae:0.20228715240955353
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS08              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS08.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             170                 Dec In:             170                 
  C Out:              170                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10606
val 3464
test 3465
	iters: 100, epoch: 1 | loss: 0.2707019
	speed: 0.1449s/iter; left time: 466.8284s
	iters: 200, epoch: 1 | loss: 0.2701244
	speed: 0.1412s/iter; left time: 440.7980s
	iters: 300, epoch: 1 | loss: 0.1964667
	speed: 0.1394s/iter; left time: 421.1260s
Epoch: 1 cost time: 46.971853494644165
Epoch: 1, Steps: 332 | Train Loss: 0.2683295 Vali Loss: 0.1923863 Test Loss: 0.1862371
Validation loss decreased (inf --> 0.192386).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1851408
	speed: 0.3204s/iter; left time: 925.7583s
	iters: 200, epoch: 2 | loss: 0.2049273
	speed: 0.0997s/iter; left time: 277.9706s
	iters: 300, epoch: 2 | loss: 0.2137103
	speed: 0.1044s/iter; left time: 280.7508s
Epoch: 2 cost time: 37.10036897659302
Epoch: 2, Steps: 332 | Train Loss: 0.2138822 Vali Loss: 0.1362167 Test Loss: 0.1255488
Validation loss decreased (0.192386 --> 0.136217).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2024714
	speed: 0.3466s/iter; left time: 886.2580s
	iters: 200, epoch: 3 | loss: 0.2390240
	speed: 0.1393s/iter; left time: 342.1666s
	iters: 300, epoch: 3 | loss: 0.1756093
	speed: 0.1405s/iter; left time: 331.1630s
Epoch: 3 cost time: 46.55024838447571
Epoch: 3, Steps: 332 | Train Loss: 0.2024895 Vali Loss: 0.1150774 Test Loss: 0.1039882
Validation loss decreased (0.136217 --> 0.115077).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2157926
	speed: 0.3461s/iter; left time: 770.0267s
	iters: 200, epoch: 4 | loss: 0.2203835
	speed: 0.1391s/iter; left time: 295.5868s
	iters: 300, epoch: 4 | loss: 0.2097564
	speed: 0.1396s/iter; left time: 282.6038s
Epoch: 4 cost time: 46.173157930374146
Epoch: 4, Steps: 332 | Train Loss: 0.1988412 Vali Loss: 0.1117429 Test Loss: 0.1011072
Validation loss decreased (0.115077 --> 0.111743).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2104907
	speed: 0.3057s/iter; left time: 578.7544s
	iters: 200, epoch: 5 | loss: 0.2129013
	speed: 0.1396s/iter; left time: 250.2640s
	iters: 300, epoch: 5 | loss: 0.1923410
	speed: 0.1389s/iter; left time: 235.1208s
Epoch: 5 cost time: 44.80165386199951
Epoch: 5, Steps: 332 | Train Loss: 0.1964199 Vali Loss: 0.1110658 Test Loss: 0.1005016
Validation loss decreased (0.111743 --> 0.111066).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2090088
	speed: 0.3457s/iter; left time: 539.6616s
	iters: 200, epoch: 6 | loss: 0.1858834
	speed: 0.1407s/iter; left time: 205.5484s
	iters: 300, epoch: 6 | loss: 0.1886906
	speed: 0.1399s/iter; left time: 190.4198s
Epoch: 6 cost time: 46.67106747627258
Epoch: 6, Steps: 332 | Train Loss: 0.1952261 Vali Loss: 0.1172616 Test Loss: 0.1080635
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2099589
	speed: 0.3358s/iter; left time: 412.7196s
	iters: 200, epoch: 7 | loss: 0.2184460
	speed: 0.1012s/iter; left time: 114.2070s
	iters: 300, epoch: 7 | loss: 0.2032031
	speed: 0.1056s/iter; left time: 108.6604s
Epoch: 7 cost time: 37.50027132034302
Epoch: 7, Steps: 332 | Train Loss: 0.1943541 Vali Loss: 0.1125104 Test Loss: 0.1026484
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1840592
	speed: 0.3370s/iter; left time: 302.2974s
	iters: 200, epoch: 8 | loss: 0.2017835
	speed: 0.1398s/iter; left time: 111.4511s
	iters: 300, epoch: 8 | loss: 0.1745905
	speed: 0.1390s/iter; left time: 96.8760s
Epoch: 8 cost time: 46.579208850860596
Epoch: 8, Steps: 332 | Train Loss: 0.1939353 Vali Loss: 0.1149304 Test Loss: 0.1057245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1882353
	speed: 0.3539s/iter; left time: 199.9449s
	iters: 200, epoch: 9 | loss: 0.1919771
	speed: 0.1411s/iter; left time: 65.6014s
	iters: 300, epoch: 9 | loss: 0.2034369
	speed: 0.1401s/iter; left time: 51.1325s
Epoch: 9 cost time: 46.92660140991211
Epoch: 9, Steps: 332 | Train Loss: 0.1936127 Vali Loss: 0.1134123 Test Loss: 0.1036874
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1922941
	speed: 0.3058s/iter; left time: 71.2628s
	iters: 200, epoch: 10 | loss: 0.1735471
	speed: 0.1404s/iter; left time: 18.6731s
	iters: 300, epoch: 10 | loss: 0.2198660
	speed: 0.1423s/iter; left time: 4.6943s
Epoch: 10 cost time: 44.62963056564331
Epoch: 10, Steps: 332 | Train Loss: 0.1934892 Vali Loss: 0.1126194 Test Loss: 0.1030597
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3465
test shape: (3465, 12, 170) (3465, 12, 170)
test shape: (3465, 12, 170) (3465, 12, 170)
mse:0.10077567398548126, mae:0.21366310119628906
