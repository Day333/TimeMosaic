Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_96         Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            288                 Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_96_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34177
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.3272698
	speed: 0.0548s/iter; left time: 580.5635s
	iters: 200, epoch: 1 | loss: 0.3075587
	speed: 0.1574s/iter; left time: 1651.4678s
	iters: 300, epoch: 1 | loss: 0.3240064
	speed: 0.2133s/iter; left time: 2216.2923s
	iters: 400, epoch: 1 | loss: 0.3292431
	speed: 0.2357s/iter; left time: 2425.3812s
	iters: 500, epoch: 1 | loss: 0.2961567
	speed: 0.2302s/iter; left time: 2346.4507s
	iters: 600, epoch: 1 | loss: 0.3072658
	speed: 0.2330s/iter; left time: 2351.2642s
	iters: 700, epoch: 1 | loss: 0.2852240
	speed: 0.2359s/iter; left time: 2357.1182s
	iters: 800, epoch: 1 | loss: 0.2936803
	speed: 0.2279s/iter; left time: 2253.8661s
	iters: 900, epoch: 1 | loss: 0.3205385
	speed: 0.2366s/iter; left time: 2316.6998s
	iters: 1000, epoch: 1 | loss: 0.2202459
	speed: 0.2306s/iter; left time: 2234.8461s
Epoch: 1 cost time: 221.17138361930847
Epoch: 1, Steps: 1069 | Train Loss: 0.3219368 Vali Loss: 0.5508646 Test Loss: 0.4234877
Validation loss decreased (inf --> 0.550865).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2766303
	speed: 1.8690s/iter; left time: 17796.4835s
	iters: 200, epoch: 2 | loss: 0.2579276
	speed: 0.2380s/iter; left time: 2242.1843s
	iters: 300, epoch: 2 | loss: 0.2513749
	speed: 0.2341s/iter; left time: 2182.4630s
	iters: 400, epoch: 2 | loss: 0.2638382
	speed: 0.2222s/iter; left time: 2049.4133s
	iters: 500, epoch: 2 | loss: 0.2699776
	speed: 0.2364s/iter; left time: 2156.4371s
	iters: 600, epoch: 2 | loss: 0.2783087
	speed: 0.2343s/iter; left time: 2113.9965s
	iters: 700, epoch: 2 | loss: 0.3091468
	speed: 0.2219s/iter; left time: 1980.0036s
	iters: 800, epoch: 2 | loss: 0.2733851
	speed: 0.2382s/iter; left time: 2101.2910s
	iters: 900, epoch: 2 | loss: 0.3087599
	speed: 0.2341s/iter; left time: 2042.0976s
	iters: 1000, epoch: 2 | loss: 0.2570338
	speed: 0.2395s/iter; left time: 2064.5805s
Epoch: 2 cost time: 249.56900477409363
Epoch: 2, Steps: 1069 | Train Loss: 0.2960635 Vali Loss: 0.4043840 Test Loss: 0.3219352
Validation loss decreased (0.550865 --> 0.404384).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2848253
	speed: 1.8433s/iter; left time: 15581.4952s
	iters: 200, epoch: 3 | loss: 0.2743350
	speed: 0.2144s/iter; left time: 1790.6048s
	iters: 300, epoch: 3 | loss: 0.3786849
	speed: 0.2129s/iter; left time: 1756.6633s
	iters: 400, epoch: 3 | loss: 0.2810422
	speed: 0.2132s/iter; left time: 1738.1022s
	iters: 500, epoch: 3 | loss: 0.2467078
	speed: 0.2148s/iter; left time: 1729.5006s
	iters: 600, epoch: 3 | loss: 0.2585028
	speed: 0.2124s/iter; left time: 1688.9371s
	iters: 700, epoch: 3 | loss: 0.2673058
	speed: 0.2116s/iter; left time: 1661.8553s
	iters: 800, epoch: 3 | loss: 0.2803776
	speed: 0.2138s/iter; left time: 1657.6979s
	iters: 900, epoch: 3 | loss: 0.2903660
	speed: 0.2128s/iter; left time: 1628.8745s
	iters: 1000, epoch: 3 | loss: 0.2836505
	speed: 0.2119s/iter; left time: 1600.2584s
Epoch: 3 cost time: 227.91367077827454
Epoch: 3, Steps: 1069 | Train Loss: 0.2718937 Vali Loss: 0.4148362 Test Loss: 0.3064503
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2949817
	speed: 1.7679s/iter; left time: 13053.8563s
	iters: 200, epoch: 4 | loss: 0.3243277
	speed: 0.2127s/iter; left time: 1549.3111s
	iters: 300, epoch: 4 | loss: 0.2589392
	speed: 0.2145s/iter; left time: 1540.9209s
	iters: 400, epoch: 4 | loss: 0.2562843
	speed: 0.2147s/iter; left time: 1520.7944s
	iters: 500, epoch: 4 | loss: 0.2450640
	speed: 0.2165s/iter; left time: 1511.9812s
	iters: 600, epoch: 4 | loss: 0.2746401
	speed: 0.2145s/iter; left time: 1476.6503s
	iters: 700, epoch: 4 | loss: 0.2042753
	speed: 0.2138s/iter; left time: 1450.0955s
	iters: 800, epoch: 4 | loss: 0.2455647
	speed: 0.2126s/iter; left time: 1420.7785s
	iters: 900, epoch: 4 | loss: 0.2613349
	speed: 0.2134s/iter; left time: 1404.8255s
	iters: 1000, epoch: 4 | loss: 0.2751389
	speed: 0.2127s/iter; left time: 1378.8290s
Epoch: 4 cost time: 228.82418704032898
Epoch: 4, Steps: 1069 | Train Loss: 0.2616179 Vali Loss: 0.4109398 Test Loss: 0.3003901
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2472764
	speed: 1.7906s/iter; left time: 11307.8511s
	iters: 200, epoch: 5 | loss: 0.2406034
	speed: 0.2114s/iter; left time: 1313.9590s
	iters: 300, epoch: 5 | loss: 0.2418069
	speed: 0.2129s/iter; left time: 1301.9007s
	iters: 400, epoch: 5 | loss: 0.2188560
	speed: 0.2138s/iter; left time: 1286.2573s
	iters: 500, epoch: 5 | loss: 0.2346812
	speed: 0.2129s/iter; left time: 1259.5557s
	iters: 600, epoch: 5 | loss: 0.3210733
	speed: 0.2124s/iter; left time: 1235.3546s
	iters: 700, epoch: 5 | loss: 0.2047002
	speed: 0.2129s/iter; left time: 1216.8286s
	iters: 800, epoch: 5 | loss: 0.2454819
	speed: 0.2163s/iter; left time: 1214.5283s
	iters: 900, epoch: 5 | loss: 0.2357190
	speed: 0.2172s/iter; left time: 1197.7293s
	iters: 1000, epoch: 5 | loss: 0.2181403
	speed: 0.2090s/iter; left time: 1131.9570s
Epoch: 5 cost time: 226.94488167762756
Epoch: 5, Steps: 1069 | Train Loss: 0.2560551 Vali Loss: 0.3951742 Test Loss: 0.2975001
Validation loss decreased (0.404384 --> 0.395174).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2631183
	speed: 1.4933s/iter; left time: 7833.6400s
	iters: 200, epoch: 6 | loss: 0.2521679
	speed: 0.1732s/iter; left time: 891.2811s
	iters: 300, epoch: 6 | loss: 0.2967861
	speed: 0.1726s/iter; left time: 870.9401s
	iters: 400, epoch: 6 | loss: 0.2984270
	speed: 0.1746s/iter; left time: 863.7313s
	iters: 500, epoch: 6 | loss: 0.2183100
	speed: 0.1787s/iter; left time: 865.7534s
	iters: 600, epoch: 6 | loss: 0.2736714
	speed: 0.1877s/iter; left time: 890.6696s
	iters: 700, epoch: 6 | loss: 0.2352483
	speed: 0.1971s/iter; left time: 915.6431s
	iters: 800, epoch: 6 | loss: 0.2324432
	speed: 0.1956s/iter; left time: 889.0194s
	iters: 900, epoch: 6 | loss: 0.2790076
	speed: 0.2006s/iter; left time: 891.7525s
	iters: 1000, epoch: 6 | loss: 0.3020062
	speed: 0.2118s/iter; left time: 920.5397s
Epoch: 6 cost time: 201.30782675743103
Epoch: 6, Steps: 1069 | Train Loss: 0.2533194 Vali Loss: 0.3924448 Test Loss: 0.2931413
Validation loss decreased (0.395174 --> 0.392445).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2144917
	speed: 1.6091s/iter; left time: 6721.4065s
	iters: 200, epoch: 7 | loss: 0.2089291
	speed: 0.1910s/iter; left time: 778.5934s
	iters: 300, epoch: 7 | loss: 0.2671975
	speed: 0.1917s/iter; left time: 762.2915s
	iters: 400, epoch: 7 | loss: 0.2938520
	speed: 0.1881s/iter; left time: 729.2121s
	iters: 500, epoch: 7 | loss: 0.2303945
	speed: 0.1881s/iter; left time: 710.3261s
	iters: 600, epoch: 7 | loss: 0.2634490
	speed: 0.1893s/iter; left time: 695.9872s
	iters: 700, epoch: 7 | loss: 0.2735712
	speed: 0.1894s/iter; left time: 677.3889s
	iters: 800, epoch: 7 | loss: 0.2068035
	speed: 0.1888s/iter; left time: 656.6109s
	iters: 900, epoch: 7 | loss: 0.2493008
	speed: 0.1880s/iter; left time: 634.9259s
	iters: 1000, epoch: 7 | loss: 0.2905278
	speed: 0.1886s/iter; left time: 617.8907s
Epoch: 7 cost time: 202.52541971206665
Epoch: 7, Steps: 1069 | Train Loss: 0.2515887 Vali Loss: 0.3920413 Test Loss: 0.2924546
Validation loss decreased (0.392445 --> 0.392041).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2708476
	speed: 1.5289s/iter; left time: 4751.9541s
	iters: 200, epoch: 8 | loss: 0.1815003
	speed: 0.1960s/iter; left time: 589.4856s
	iters: 300, epoch: 8 | loss: 0.2520931
	speed: 0.2117s/iter; left time: 615.5099s
	iters: 400, epoch: 8 | loss: 0.2220230
	speed: 0.2115s/iter; left time: 594.0265s
	iters: 500, epoch: 8 | loss: 0.2750142
	speed: 0.2126s/iter; left time: 575.7419s
	iters: 600, epoch: 8 | loss: 0.2504930
	speed: 0.2111s/iter; left time: 550.4937s
	iters: 700, epoch: 8 | loss: 0.2556492
	speed: 0.2114s/iter; left time: 530.2845s
	iters: 800, epoch: 8 | loss: 0.2404562
	speed: 0.2117s/iter; left time: 509.8701s
	iters: 900, epoch: 8 | loss: 0.2320319
	speed: 0.2117s/iter; left time: 488.5203s
	iters: 1000, epoch: 8 | loss: 0.2358546
	speed: 0.2118s/iter; left time: 467.7254s
Epoch: 8 cost time: 222.7230772972107
Epoch: 8, Steps: 1069 | Train Loss: 0.2508566 Vali Loss: 0.3914649 Test Loss: 0.2922510
Validation loss decreased (0.392041 --> 0.391465).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2391822
	speed: 1.6954s/iter; left time: 3456.8305s
	iters: 200, epoch: 9 | loss: 0.2739920
	speed: 0.2104s/iter; left time: 407.9895s
	iters: 300, epoch: 9 | loss: 0.2378205
	speed: 0.2113s/iter; left time: 388.5046s
	iters: 400, epoch: 9 | loss: 0.2482208
	speed: 0.2118s/iter; left time: 368.3904s
	iters: 500, epoch: 9 | loss: 0.2402991
	speed: 0.2122s/iter; left time: 347.8706s
	iters: 600, epoch: 9 | loss: 0.2966557
	speed: 0.2105s/iter; left time: 323.9777s
	iters: 700, epoch: 9 | loss: 0.2265304
	speed: 0.2113s/iter; left time: 304.0670s
	iters: 800, epoch: 9 | loss: 0.2398756
	speed: 0.2127s/iter; left time: 284.7950s
	iters: 900, epoch: 9 | loss: 0.2559393
	speed: 0.2123s/iter; left time: 263.0886s
	iters: 1000, epoch: 9 | loss: 0.2439250
	speed: 0.2132s/iter; left time: 242.8381s
Epoch: 9 cost time: 226.46492648124695
Epoch: 9, Steps: 1069 | Train Loss: 0.2508814 Vali Loss: 0.3896982 Test Loss: 0.2921115
Validation loss decreased (0.391465 --> 0.389698).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2480156
	speed: 1.7061s/iter; left time: 1654.9200s
	iters: 200, epoch: 10 | loss: 0.2367887
	speed: 0.2123s/iter; left time: 184.6736s
	iters: 300, epoch: 10 | loss: 0.3232728
	speed: 0.2123s/iter; left time: 163.4346s
	iters: 400, epoch: 10 | loss: 0.2500423
	speed: 0.2106s/iter; left time: 141.0778s
	iters: 500, epoch: 10 | loss: 0.2490130
	speed: 0.2118s/iter; left time: 120.7472s
	iters: 600, epoch: 10 | loss: 0.2503631
	speed: 0.2118s/iter; left time: 99.5343s
	iters: 700, epoch: 10 | loss: 0.2491799
	speed: 0.2115s/iter; left time: 78.2486s
	iters: 800, epoch: 10 | loss: 0.2185964
	speed: 0.2128s/iter; left time: 57.4612s
	iters: 900, epoch: 10 | loss: 0.2416113
	speed: 0.2135s/iter; left time: 36.2914s
	iters: 1000, epoch: 10 | loss: 0.2480705
	speed: 0.2134s/iter; left time: 14.9382s
Epoch: 10 cost time: 227.05715608596802
Epoch: 10, Steps: 1069 | Train Loss: 0.2503342 Vali Loss: 0.3914588 Test Loss: 0.2917699
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTm1_96_96_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.2912577688694, mae:0.34520187973976135
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_192        Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            288                 Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_192_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34081
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3603987
	speed: 0.4901s/iter; left time: 1260.0747s
	iters: 200, epoch: 1 | loss: 0.3465185
	speed: 0.4903s/iter; left time: 1211.6244s
Epoch: 1 cost time: 131.00816297531128
Epoch: 1, Steps: 267 | Train Loss: 0.3519557 Vali Loss: 0.5374684 Test Loss: 0.3484125
Validation loss decreased (inf --> 0.537468).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3186142
	speed: 1.3695s/iter; left time: 3155.3100s
	iters: 200, epoch: 2 | loss: 0.3172320
	speed: 0.5472s/iter; left time: 1205.9608s
Epoch: 2 cost time: 146.71389532089233
Epoch: 2, Steps: 267 | Train Loss: 0.3235375 Vali Loss: 0.5298111 Test Loss: 0.3466793
Validation loss decreased (0.537468 --> 0.529811).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2983874
	speed: 1.4856s/iter; left time: 3026.1078s
	iters: 200, epoch: 3 | loss: 0.2880636
	speed: 0.5676s/iter; left time: 1099.3820s
Epoch: 3 cost time: 151.96384954452515
Epoch: 3, Steps: 267 | Train Loss: 0.3072867 Vali Loss: 0.5308532 Test Loss: 0.3370135
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3025503
	speed: 1.4785s/iter; left time: 2617.0104s
	iters: 200, epoch: 4 | loss: 0.2977005
	speed: 0.5684s/iter; left time: 949.3103s
Epoch: 4 cost time: 152.24196434020996
Epoch: 4, Steps: 267 | Train Loss: 0.2994669 Vali Loss: 0.5127949 Test Loss: 0.3297013
Validation loss decreased (0.529811 --> 0.512795).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2931152
	speed: 1.4651s/iter; left time: 2201.9713s
	iters: 200, epoch: 5 | loss: 0.2759285
	speed: 0.5801s/iter; left time: 813.9362s
Epoch: 5 cost time: 153.35626745224
Epoch: 5, Steps: 267 | Train Loss: 0.2954181 Vali Loss: 0.5135969 Test Loss: 0.3288137
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2985851
	speed: 1.4677s/iter; left time: 1814.0812s
	iters: 200, epoch: 6 | loss: 0.3097072
	speed: 0.5552s/iter; left time: 630.6661s
Epoch: 6 cost time: 146.603933095932
Epoch: 6, Steps: 267 | Train Loss: 0.2928941 Vali Loss: 0.5121499 Test Loss: 0.3287972
Validation loss decreased (0.512795 --> 0.512150).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2947548
	speed: 1.3393s/iter; left time: 1297.7692s
	iters: 200, epoch: 7 | loss: 0.2744219
	speed: 0.5174s/iter; left time: 449.5865s
Epoch: 7 cost time: 138.37658524513245
Epoch: 7, Steps: 267 | Train Loss: 0.2919161 Vali Loss: 0.5117100 Test Loss: 0.3286213
Validation loss decreased (0.512150 --> 0.511710).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2589195
	speed: 1.3504s/iter; left time: 947.9578s
	iters: 200, epoch: 8 | loss: 0.2848470
	speed: 0.5164s/iter; left time: 310.8434s
Epoch: 8 cost time: 138.1934380531311
Epoch: 8, Steps: 267 | Train Loss: 0.2910310 Vali Loss: 0.5117534 Test Loss: 0.3283304
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2978625
	speed: 1.3709s/iter; left time: 596.3371s
	iters: 200, epoch: 9 | loss: 0.2732290
	speed: 0.5688s/iter; left time: 190.5371s
Epoch: 9 cost time: 149.4834599494934
Epoch: 9, Steps: 267 | Train Loss: 0.2907547 Vali Loss: 0.5109249 Test Loss: 0.3284096
Validation loss decreased (0.511710 --> 0.510925).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3193006
	speed: 1.4583s/iter; left time: 245.0011s
	iters: 200, epoch: 10 | loss: 0.2702097
	speed: 0.5689s/iter; left time: 38.6826s
Epoch: 10 cost time: 151.45991277694702
Epoch: 10, Steps: 267 | Train Loss: 0.2906522 Vali Loss: 0.5106894 Test Loss: 0.3281727
Validation loss decreased (0.510925 --> 0.510689).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTm1_96_192_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.3283994197845459, mae:0.37042540311813354
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_336        Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            288                 Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_336_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33937
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4097744
	speed: 0.3017s/iter; left time: 772.5347s
	iters: 200, epoch: 1 | loss: 0.3943127
	speed: 0.2895s/iter; left time: 712.5267s
Epoch: 1 cost time: 78.38599491119385
Epoch: 1, Steps: 266 | Train Loss: 0.4025428 Vali Loss: 0.6815415 Test Loss: 0.3891686
Validation loss decreased (inf --> 0.681542).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4021994
	speed: 0.8336s/iter; left time: 1913.1872s
	iters: 200, epoch: 2 | loss: 0.3963766
	speed: 0.2761s/iter; left time: 606.1248s
Epoch: 2 cost time: 73.65743851661682
Epoch: 2, Steps: 266 | Train Loss: 0.3756563 Vali Loss: 0.6689953 Test Loss: 0.3865259
Validation loss decreased (0.681542 --> 0.668995).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3722256
	speed: 0.8519s/iter; left time: 1728.5662s
	iters: 200, epoch: 3 | loss: 0.3716923
	speed: 0.2971s/iter; left time: 573.1353s
Epoch: 3 cost time: 79.73952007293701
Epoch: 3, Steps: 266 | Train Loss: 0.3621179 Vali Loss: 0.6628666 Test Loss: 0.3792395
Validation loss decreased (0.668995 --> 0.662867).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3641605
	speed: 0.8776s/iter; left time: 1547.2574s
	iters: 200, epoch: 4 | loss: 0.3302391
	speed: 0.3053s/iter; left time: 507.6478s
Epoch: 4 cost time: 81.58112716674805
Epoch: 4, Steps: 266 | Train Loss: 0.3558988 Vali Loss: 0.6631142 Test Loss: 0.3722168
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3536755
	speed: 0.9259s/iter; left time: 1386.0228s
	iters: 200, epoch: 5 | loss: 0.3328153
	speed: 0.3164s/iter; left time: 441.9492s
Epoch: 5 cost time: 84.52971315383911
Epoch: 5, Steps: 266 | Train Loss: 0.3525593 Vali Loss: 0.6559430 Test Loss: 0.3676707
Validation loss decreased (0.662867 --> 0.655943).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3467368
	speed: 0.9400s/iter; left time: 1157.1596s
	iters: 200, epoch: 6 | loss: 0.3779734
	speed: 0.3190s/iter; left time: 360.7873s
Epoch: 6 cost time: 85.6418707370758
Epoch: 6, Steps: 266 | Train Loss: 0.3506404 Vali Loss: 0.6554274 Test Loss: 0.3669313
Validation loss decreased (0.655943 --> 0.655427).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3612504
	speed: 0.9271s/iter; left time: 894.6580s
	iters: 200, epoch: 7 | loss: 0.3872682
	speed: 0.3184s/iter; left time: 275.4320s
Epoch: 7 cost time: 84.9059829711914
Epoch: 7, Steps: 266 | Train Loss: 0.3498823 Vali Loss: 0.6542620 Test Loss: 0.3663035
Validation loss decreased (0.655427 --> 0.654262).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3377514
	speed: 0.9315s/iter; left time: 651.1462s
	iters: 200, epoch: 8 | loss: 0.3394739
	speed: 0.3245s/iter; left time: 194.3486s
Epoch: 8 cost time: 85.85013580322266
Epoch: 8, Steps: 266 | Train Loss: 0.3493821 Vali Loss: 0.6500127 Test Loss: 0.3662710
Validation loss decreased (0.654262 --> 0.650013).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3297419
	speed: 0.9546s/iter; left time: 413.3528s
	iters: 200, epoch: 9 | loss: 0.3412509
	speed: 0.3200s/iter; left time: 106.5708s
Epoch: 9 cost time: 85.7419502735138
Epoch: 9, Steps: 266 | Train Loss: 0.3490771 Vali Loss: 0.6512223 Test Loss: 0.3663858
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3535993
	speed: 0.9342s/iter; left time: 156.0179s
	iters: 200, epoch: 10 | loss: 0.3693622
	speed: 0.3194s/iter; left time: 21.4020s
Epoch: 10 cost time: 85.06689476966858
Epoch: 10, Steps: 266 | Train Loss: 0.3489549 Vali Loss: 0.6522088 Test Loss: 0.3660970
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTm1_96_336_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.36566582322120667, mae:0.39116546511650085
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_720        Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            288                 Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_720_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33553
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4834844
	speed: 0.5890s/iter; left time: 1490.6606s
	iters: 200, epoch: 1 | loss: 0.4652111
	speed: 0.5878s/iter; left time: 1428.9100s
Epoch: 1 cost time: 154.43348741531372
Epoch: 1, Steps: 263 | Train Loss: 0.4593561 Vali Loss: 0.9963228 Test Loss: 0.4359135
Validation loss decreased (inf --> 0.996323).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4203812
	speed: 1.4642s/iter; left time: 3320.7624s
	iters: 200, epoch: 2 | loss: 0.4067470
	speed: 0.5866s/iter; left time: 1271.8070s
Epoch: 2 cost time: 154.23500967025757
Epoch: 2, Steps: 263 | Train Loss: 0.4304096 Vali Loss: 0.9941757 Test Loss: 0.4399770
Validation loss decreased (0.996323 --> 0.994176).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3994112
	speed: 1.4892s/iter; left time: 2985.7492s
	iters: 200, epoch: 3 | loss: 0.3823707
	speed: 0.5869s/iter; left time: 1117.9773s
Epoch: 3 cost time: 154.30292177200317
Epoch: 3, Steps: 263 | Train Loss: 0.4119320 Vali Loss: 0.9710844 Test Loss: 0.4348673
Validation loss decreased (0.994176 --> 0.971084).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3932244
	speed: 1.4308s/iter; left time: 2492.4394s
	iters: 200, epoch: 4 | loss: 0.4135070
	speed: 0.5368s/iter; left time: 881.3541s
Epoch: 4 cost time: 141.16959977149963
Epoch: 4, Steps: 263 | Train Loss: 0.3993620 Vali Loss: 0.9872786 Test Loss: 0.4360965
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3941033
	speed: 1.2712s/iter; left time: 1880.0565s
	iters: 200, epoch: 5 | loss: 0.3843917
	speed: 0.4862s/iter; left time: 670.4670s
Epoch: 5 cost time: 127.85225629806519
Epoch: 5, Steps: 263 | Train Loss: 0.3928812 Vali Loss: 0.9764282 Test Loss: 0.4341599
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3973137
	speed: 1.2175s/iter; left time: 1480.5182s
	iters: 200, epoch: 6 | loss: 0.3826548
	speed: 0.5087s/iter; left time: 567.7090s
Epoch: 6 cost time: 133.9254856109619
Epoch: 6, Steps: 263 | Train Loss: 0.3893482 Vali Loss: 0.9797572 Test Loss: 0.4316709
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_720_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.4338604509830475, mae:0.4351506233215332
