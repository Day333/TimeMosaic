Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_96         Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2297342
	speed: 0.2587s/iter; left time: 2755.8383s
	iters: 200, epoch: 1 | loss: 0.2457160
	speed: 0.2639s/iter; left time: 2784.4881s
	iters: 300, epoch: 1 | loss: 0.1905180
	speed: 0.2667s/iter; left time: 2786.9736s
	iters: 400, epoch: 1 | loss: 0.1656951
	speed: 0.2670s/iter; left time: 2764.0245s
	iters: 500, epoch: 1 | loss: 0.3005823
	speed: 0.2659s/iter; left time: 2725.6035s
	iters: 600, epoch: 1 | loss: 0.4769332
	speed: 0.2669s/iter; left time: 2709.4234s
	iters: 700, epoch: 1 | loss: 0.2275794
	speed: 0.2670s/iter; left time: 2684.1085s
	iters: 800, epoch: 1 | loss: 0.5030527
	speed: 0.2666s/iter; left time: 2652.9189s
	iters: 900, epoch: 1 | loss: 0.3164522
	speed: 0.2667s/iter; left time: 2627.3159s
	iters: 1000, epoch: 1 | loss: 0.2751556
	speed: 0.2672s/iter; left time: 2605.1517s
Epoch: 1 cost time: 285.69857692718506
Epoch: 1, Steps: 1075 | Train Loss: 0.2443541 Vali Loss: 0.1296893 Test Loss: 0.1811561
Validation loss decreased (inf --> 0.129689).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4038410
	speed: 1.2249s/iter; left time: 11729.2373s
	iters: 200, epoch: 2 | loss: 0.2857282
	speed: 0.2179s/iter; left time: 2065.0682s
	iters: 300, epoch: 2 | loss: 0.3921243
	speed: 0.2734s/iter; left time: 2563.4083s
	iters: 400, epoch: 2 | loss: 0.2684211
	speed: 0.2727s/iter; left time: 2529.5837s
	iters: 500, epoch: 2 | loss: 0.2244859
	speed: 0.2731s/iter; left time: 2506.2811s
	iters: 600, epoch: 2 | loss: 0.2627290
	speed: 0.2727s/iter; left time: 2475.4654s
	iters: 700, epoch: 2 | loss: 0.1846995
	speed: 0.2726s/iter; left time: 2446.5470s
	iters: 800, epoch: 2 | loss: 0.2903999
	speed: 0.2724s/iter; left time: 2417.5781s
	iters: 900, epoch: 2 | loss: 0.1220093
	speed: 0.2727s/iter; left time: 2393.5460s
	iters: 1000, epoch: 2 | loss: 0.1296754
	speed: 0.2731s/iter; left time: 2369.3713s
Epoch: 2 cost time: 285.7115943431854
Epoch: 2, Steps: 1075 | Train Loss: 0.2326958 Vali Loss: 0.1399672 Test Loss: 0.1905880
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1902871
	speed: 1.3184s/iter; left time: 11207.8466s
	iters: 200, epoch: 3 | loss: 0.2063970
	speed: 0.2726s/iter; left time: 2290.3632s
	iters: 300, epoch: 3 | loss: 0.1233073
	speed: 0.2710s/iter; left time: 2249.9222s
	iters: 400, epoch: 3 | loss: 0.1767153
	speed: 0.2586s/iter; left time: 2120.8416s
	iters: 500, epoch: 3 | loss: 0.3012141
	speed: 0.2576s/iter; left time: 2086.9499s
	iters: 600, epoch: 3 | loss: 0.4145709
	speed: 0.2601s/iter; left time: 2080.7029s
	iters: 700, epoch: 3 | loss: 0.2654997
	speed: 0.2595s/iter; left time: 2050.3366s
	iters: 800, epoch: 3 | loss: 0.0931517
	speed: 0.2584s/iter; left time: 2015.7094s
	iters: 900, epoch: 3 | loss: 0.1562101
	speed: 0.2692s/iter; left time: 2073.2654s
	iters: 1000, epoch: 3 | loss: 0.2309021
	speed: 0.2733s/iter; left time: 2077.2583s
Epoch: 3 cost time: 285.8167383670807
Epoch: 3, Steps: 1075 | Train Loss: 0.2234043 Vali Loss: 0.1282773 Test Loss: 0.1779548
Validation loss decreased (0.129689 --> 0.128277).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2144282
	speed: 1.3222s/iter; left time: 9818.7482s
	iters: 200, epoch: 4 | loss: 0.2691181
	speed: 0.2731s/iter; left time: 2000.5674s
	iters: 300, epoch: 4 | loss: 0.3636611
	speed: 0.2732s/iter; left time: 1973.9579s
	iters: 400, epoch: 4 | loss: 0.1434103
	speed: 0.2729s/iter; left time: 1944.4824s
	iters: 500, epoch: 4 | loss: 0.3592721
	speed: 0.2728s/iter; left time: 1916.7061s
	iters: 600, epoch: 4 | loss: 0.1434194
	speed: 0.2728s/iter; left time: 1889.6368s
	iters: 700, epoch: 4 | loss: 0.1600530
	speed: 0.2727s/iter; left time: 1861.6592s
	iters: 800, epoch: 4 | loss: 0.1902897
	speed: 0.2729s/iter; left time: 1835.3165s
	iters: 900, epoch: 4 | loss: 0.1814176
	speed: 0.2723s/iter; left time: 1804.3075s
	iters: 1000, epoch: 4 | loss: 0.1962427
	speed: 0.2730s/iter; left time: 1781.3964s
Epoch: 4 cost time: 293.4339904785156
Epoch: 4, Steps: 1075 | Train Loss: 0.2158115 Vali Loss: 0.1303102 Test Loss: 0.1807222
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2917584
	speed: 1.3215s/iter; left time: 8392.8723s
	iters: 200, epoch: 5 | loss: 0.1313859
	speed: 0.2733s/iter; left time: 1708.2574s
	iters: 300, epoch: 5 | loss: 0.1745504
	speed: 0.2727s/iter; left time: 1677.2798s
	iters: 400, epoch: 5 | loss: 0.1235948
	speed: 0.2699s/iter; left time: 1633.2797s
	iters: 500, epoch: 5 | loss: 0.1440208
	speed: 0.2669s/iter; left time: 1588.4513s
	iters: 600, epoch: 5 | loss: 0.1302748
	speed: 0.2670s/iter; left time: 1562.1495s
	iters: 700, epoch: 5 | loss: 0.1683764
	speed: 0.2667s/iter; left time: 1533.9898s
	iters: 800, epoch: 5 | loss: 0.1449208
	speed: 0.2661s/iter; left time: 1503.9388s
	iters: 900, epoch: 5 | loss: 0.2363264
	speed: 0.2673s/iter; left time: 1483.7532s
	iters: 1000, epoch: 5 | loss: 0.1668525
	speed: 0.2621s/iter; left time: 1428.8306s
Epoch: 5 cost time: 288.41202306747437
Epoch: 5, Steps: 1075 | Train Loss: 0.2113851 Vali Loss: 0.1295140 Test Loss: 0.1811486
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2321680
	speed: 1.2182s/iter; left time: 6427.1309s
	iters: 200, epoch: 6 | loss: 0.1693527
	speed: 0.2583s/iter; left time: 1336.7880s
	iters: 300, epoch: 6 | loss: 0.1622368
	speed: 0.2644s/iter; left time: 1342.2940s
	iters: 400, epoch: 6 | loss: 0.4631226
	speed: 0.2731s/iter; left time: 1359.1763s
	iters: 500, epoch: 6 | loss: 0.1774012
	speed: 0.2721s/iter; left time: 1326.7026s
	iters: 600, epoch: 6 | loss: 0.1199859
	speed: 0.2731s/iter; left time: 1304.3186s
	iters: 700, epoch: 6 | loss: 0.3618881
	speed: 0.2728s/iter; left time: 1275.5058s
	iters: 800, epoch: 6 | loss: 0.1620814
	speed: 0.2726s/iter; left time: 1247.3209s
	iters: 900, epoch: 6 | loss: 0.1346019
	speed: 0.2730s/iter; left time: 1222.0270s
	iters: 1000, epoch: 6 | loss: 0.1929341
	speed: 0.2729s/iter; left time: 1193.9952s
Epoch: 6 cost time: 288.8798232078552
Epoch: 6, Steps: 1075 | Train Loss: 0.2081502 Vali Loss: 0.1311042 Test Loss: 0.1829978
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_96_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.17815962433815002, mae:0.26012110710144043
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_192        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5137958
	speed: 1.9410s/iter; left time: 5009.7834s
	iters: 200, epoch: 1 | loss: 0.4526361
	speed: 1.9482s/iter; left time: 4833.4320s
Epoch: 1 cost time: 521.7478225231171
Epoch: 1, Steps: 268 | Train Loss: 0.3415657 Vali Loss: 0.1735712 Test Loss: 0.2424311
Validation loss decreased (inf --> 0.173571).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2938095
	speed: 4.0538s/iter; left time: 9376.5388s
	iters: 200, epoch: 2 | loss: 0.2904546
	speed: 1.9132s/iter; left time: 4233.9306s
Epoch: 2 cost time: 511.8176612854004
Epoch: 2, Steps: 268 | Train Loss: 0.3290544 Vali Loss: 0.1763177 Test Loss: 0.2483477
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2942631
	speed: 4.0903s/iter; left time: 8364.6327s
	iters: 200, epoch: 3 | loss: 0.4003419
	speed: 1.9491s/iter; left time: 3790.9141s
Epoch: 3 cost time: 516.8270115852356
Epoch: 3, Steps: 268 | Train Loss: 0.3226507 Vali Loss: 0.1744092 Test Loss: 0.2441585
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3111422
	speed: 3.9002s/iter; left time: 6930.6262s
	iters: 200, epoch: 4 | loss: 0.3014131
	speed: 1.8965s/iter; left time: 3180.3813s
Epoch: 4 cost time: 498.78541588783264
Epoch: 4, Steps: 268 | Train Loss: 0.3180141 Vali Loss: 0.1728250 Test Loss: 0.2421596
Validation loss decreased (0.173571 --> 0.172825).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3417219
	speed: 3.9013s/iter; left time: 5887.0588s
	iters: 200, epoch: 5 | loss: 0.2867619
	speed: 1.8491s/iter; left time: 2605.3741s
Epoch: 5 cost time: 494.6208610534668
Epoch: 5, Steps: 268 | Train Loss: 0.3150097 Vali Loss: 0.1728828 Test Loss: 0.2429652
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2818508
	speed: 3.9482s/iter; left time: 4899.6755s
	iters: 200, epoch: 6 | loss: 0.3856193
	speed: 1.8836s/iter; left time: 2149.1478s
Epoch: 6 cost time: 503.02351236343384
Epoch: 6, Steps: 268 | Train Loss: 0.3130372 Vali Loss: 0.1739738 Test Loss: 0.2452357
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2551348
	speed: 3.9488s/iter; left time: 3842.1718s
	iters: 200, epoch: 7 | loss: 0.1925106
	speed: 1.8865s/iter; left time: 1646.8791s
Epoch: 7 cost time: 499.5555593967438
Epoch: 7, Steps: 268 | Train Loss: 0.3119780 Vali Loss: 0.1741222 Test Loss: 0.2453315
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_192_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.24291935563087463, mae:0.3028023838996887
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_336        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.8103358
	speed: 0.2990s/iter; left time: 3160.4874s
	iters: 200, epoch: 1 | loss: 0.1991391
	speed: 0.2919s/iter; left time: 3056.5152s
	iters: 300, epoch: 1 | loss: 0.6301488
	speed: 0.2940s/iter; left time: 3048.6821s
	iters: 400, epoch: 1 | loss: 0.6665289
	speed: 0.3004s/iter; left time: 3085.4294s
	iters: 500, epoch: 1 | loss: 0.3252915
	speed: 0.3006s/iter; left time: 3056.9432s
	iters: 600, epoch: 1 | loss: 0.5418787
	speed: 0.3009s/iter; left time: 3030.8198s
	iters: 700, epoch: 1 | loss: 0.5442109
	speed: 0.3008s/iter; left time: 2999.1502s
	iters: 800, epoch: 1 | loss: 0.5960006
	speed: 0.3007s/iter; left time: 2967.8793s
	iters: 900, epoch: 1 | loss: 0.5390679
	speed: 0.3010s/iter; left time: 2941.4782s
	iters: 1000, epoch: 1 | loss: 0.3272846
	speed: 0.3007s/iter; left time: 2908.0709s
Epoch: 1 cost time: 319.287148475647
Epoch: 1, Steps: 1067 | Train Loss: 0.4499377 Vali Loss: 0.2254581 Test Loss: 0.3096146
Validation loss decreased (inf --> 0.225458).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6332281
	speed: 1.3614s/iter; left time: 12939.1223s
	iters: 200, epoch: 2 | loss: 0.4776204
	speed: 0.2955s/iter; left time: 2778.6335s
	iters: 300, epoch: 2 | loss: 0.4772240
	speed: 0.3010s/iter; left time: 2800.7208s
	iters: 400, epoch: 2 | loss: 0.6078225
	speed: 0.3007s/iter; left time: 2767.7682s
	iters: 500, epoch: 2 | loss: 0.4174618
	speed: 0.3008s/iter; left time: 2738.4728s
	iters: 600, epoch: 2 | loss: 0.3581988
	speed: 0.3009s/iter; left time: 2709.5623s
	iters: 700, epoch: 2 | loss: 0.3402952
	speed: 0.3002s/iter; left time: 2672.8194s
	iters: 800, epoch: 2 | loss: 0.3061478
	speed: 0.3005s/iter; left time: 2645.5017s
	iters: 900, epoch: 2 | loss: 0.2674579
	speed: 0.3017s/iter; left time: 2626.1237s
	iters: 1000, epoch: 2 | loss: 0.3541556
	speed: 0.3006s/iter; left time: 2586.2404s
Epoch: 2 cost time: 318.27453112602234
Epoch: 2, Steps: 1067 | Train Loss: 0.4364672 Vali Loss: 0.2212348 Test Loss: 0.3040924
Validation loss decreased (0.225458 --> 0.221235).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5156385
	speed: 1.4153s/iter; left time: 11941.1653s
	iters: 200, epoch: 3 | loss: 0.2891793
	speed: 0.3008s/iter; left time: 2507.4266s
	iters: 300, epoch: 3 | loss: 0.5871778
	speed: 0.2791s/iter; left time: 2299.1503s
	iters: 400, epoch: 3 | loss: 0.5321552
	speed: 0.2779s/iter; left time: 2261.1547s
	iters: 500, epoch: 3 | loss: 0.6528133
	speed: 0.2799s/iter; left time: 2249.8425s
	iters: 600, epoch: 3 | loss: 0.4119945
	speed: 0.3009s/iter; left time: 2388.1416s
	iters: 700, epoch: 3 | loss: 0.2368966
	speed: 0.3002s/iter; left time: 2352.3095s
	iters: 800, epoch: 3 | loss: 0.4179687
	speed: 0.3004s/iter; left time: 2323.8124s
	iters: 900, epoch: 3 | loss: 0.3541402
	speed: 0.2999s/iter; left time: 2290.5963s
	iters: 1000, epoch: 3 | loss: 0.5074712
	speed: 0.3010s/iter; left time: 2268.6443s
Epoch: 3 cost time: 314.33579754829407
Epoch: 3, Steps: 1067 | Train Loss: 0.4252397 Vali Loss: 0.2323281 Test Loss: 0.3133127
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3233562
	speed: 1.3999s/iter; left time: 10317.1670s
	iters: 200, epoch: 4 | loss: 0.3432398
	speed: 0.2926s/iter; left time: 2127.0642s
	iters: 300, epoch: 4 | loss: 0.2584321
	speed: 0.2945s/iter; left time: 2111.7761s
	iters: 400, epoch: 4 | loss: 0.1943391
	speed: 0.2927s/iter; left time: 2069.5945s
	iters: 500, epoch: 4 | loss: 0.3229903
	speed: 0.2913s/iter; left time: 2030.4120s
	iters: 600, epoch: 4 | loss: 0.3378178
	speed: 0.2871s/iter; left time: 1972.4887s
	iters: 700, epoch: 4 | loss: 0.2395327
	speed: 0.2663s/iter; left time: 1802.6378s
	iters: 800, epoch: 4 | loss: 0.6443769
	speed: 0.2656s/iter; left time: 1771.8257s
	iters: 900, epoch: 4 | loss: 0.5710009
	speed: 0.2722s/iter; left time: 1788.6536s
	iters: 1000, epoch: 4 | loss: 0.4639994
	speed: 0.2996s/iter; left time: 1938.3257s
Epoch: 4 cost time: 305.6914949417114
Epoch: 4, Steps: 1067 | Train Loss: 0.4198350 Vali Loss: 0.2186696 Test Loss: 0.3009263
Validation loss decreased (0.221235 --> 0.218670).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7214600
	speed: 1.4441s/iter; left time: 9102.0727s
	iters: 200, epoch: 5 | loss: 0.2510911
	speed: 0.3013s/iter; left time: 1869.2705s
	iters: 300, epoch: 5 | loss: 0.2064268
	speed: 0.3016s/iter; left time: 1840.5222s
	iters: 400, epoch: 5 | loss: 0.2666055
	speed: 0.3016s/iter; left time: 1810.6288s
	iters: 500, epoch: 5 | loss: 0.3845424
	speed: 0.3024s/iter; left time: 1784.7790s
	iters: 600, epoch: 5 | loss: 0.2578501
	speed: 0.3021s/iter; left time: 1753.1563s
	iters: 700, epoch: 5 | loss: 0.4633040
	speed: 0.3023s/iter; left time: 1723.9606s
	iters: 800, epoch: 5 | loss: 0.3595055
	speed: 0.3017s/iter; left time: 1690.4525s
	iters: 900, epoch: 5 | loss: 0.3326164
	speed: 0.3017s/iter; left time: 1660.3355s
	iters: 1000, epoch: 5 | loss: 0.3581738
	speed: 0.2938s/iter; left time: 1587.1726s
Epoch: 5 cost time: 319.5861623287201
Epoch: 5, Steps: 1067 | Train Loss: 0.4151797 Vali Loss: 0.2197137 Test Loss: 0.3025427
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4179783
	speed: 1.3873s/iter; left time: 7263.9958s
	iters: 200, epoch: 6 | loss: 0.6245541
	speed: 0.3005s/iter; left time: 1543.2105s
	iters: 300, epoch: 6 | loss: 0.6170305
	speed: 0.3022s/iter; left time: 1522.0360s
	iters: 400, epoch: 6 | loss: 0.2669734
	speed: 0.2998s/iter; left time: 1479.7971s
	iters: 500, epoch: 6 | loss: 1.1110847
	speed: 0.3010s/iter; left time: 1455.5227s
	iters: 600, epoch: 6 | loss: 0.8666927
	speed: 0.3018s/iter; left time: 1429.3558s
	iters: 700, epoch: 6 | loss: 0.5702164
	speed: 0.3010s/iter; left time: 1395.6491s
	iters: 800, epoch: 6 | loss: 0.4888832
	speed: 0.3009s/iter; left time: 1365.0226s
	iters: 900, epoch: 6 | loss: 0.4729362
	speed: 0.3016s/iter; left time: 1337.7977s
	iters: 1000, epoch: 6 | loss: 0.2284023
	speed: 0.3010s/iter; left time: 1305.0374s
Epoch: 6 cost time: 321.35847210884094
Epoch: 6, Steps: 1067 | Train Loss: 0.4121021 Vali Loss: 0.2189607 Test Loss: 0.3020604
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1671273
	speed: 1.3801s/iter; left time: 5753.5365s
	iters: 200, epoch: 7 | loss: 0.2049734
	speed: 0.2789s/iter; left time: 1134.8124s
	iters: 300, epoch: 7 | loss: 0.3813538
	speed: 0.2985s/iter; left time: 1184.6782s
	iters: 400, epoch: 7 | loss: 0.3175524
	speed: 0.3001s/iter; left time: 1161.1993s
	iters: 500, epoch: 7 | loss: 0.2270674
	speed: 0.3010s/iter; left time: 1134.6281s
	iters: 600, epoch: 7 | loss: 0.2219844
	speed: 0.3004s/iter; left time: 1102.2259s
	iters: 700, epoch: 7 | loss: 0.3278507
	speed: 0.2921s/iter; left time: 1042.5810s
	iters: 800, epoch: 7 | loss: 0.2730706
	speed: 0.2937s/iter; left time: 1018.9763s
	iters: 900, epoch: 7 | loss: 0.3025858
	speed: 0.2919s/iter; left time: 983.2571s
	iters: 1000, epoch: 7 | loss: 0.3577881
	speed: 0.2924s/iter; left time: 955.7210s
Epoch: 7 cost time: 312.3935270309448
Epoch: 7, Steps: 1067 | Train Loss: 0.4107353 Vali Loss: 0.2213500 Test Loss: 0.3039480
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_336_AGPT_PT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.3011631667613983, mae:0.34007999300956726
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_720        Model:              AGPT_PT             

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_720_AGPT_PT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
Traceback (most recent call last):
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/run.py", line 138, in <module>
    exp.train(setting)
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/exp/exp_AGPT.py", line 131, in train
    outputs, aux_loss = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/models/AGPT_PT.py", line 337, in forward
    dec_out, budget_loss = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/models/AGPT_PT.py", line 268, in forecast
    segment_out, _ = self.encoder(segment_input)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/layers/Transformer_EncDec.py", line 74, in forward
    x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/layers/Transformer_EncDec.py", line 40, in forward
    new_x, attn = self.attention(
                  ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/layers/SelfAttention_Family.py", line 200, in forward
    keys = self.key_projection(keys).view(B, S, H, -1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 26.56 MiB is free. Process 77168 has 36.44 GiB memory in use. Process 403712 has 5.19 GiB memory in use. Process 849614 has 37.48 GiB memory in use. Of the allocated memory 36.90 GiB is allocated by PyTorch, and 91.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
