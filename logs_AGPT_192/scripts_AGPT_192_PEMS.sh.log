Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS03              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS03.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             358                 Dec In:             358                 
  C Out:              358                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15617
val 5135
test 5135
	iters: 100, epoch: 1 | loss: 0.2410136
	speed: 0.3787s/iter; left time: 1814.1814s
	iters: 200, epoch: 1 | loss: 0.1961690
	speed: 0.3492s/iter; left time: 1638.0449s
	iters: 300, epoch: 1 | loss: 0.2548554
	speed: 0.3603s/iter; left time: 1654.2245s
	iters: 400, epoch: 1 | loss: 0.2221420
	speed: 0.3583s/iter; left time: 1609.0888s
Epoch: 1 cost time: 175.28859972953796
Epoch: 1, Steps: 489 | Train Loss: 0.2507309 Vali Loss: 0.1399979 Test Loss: 0.1382285
Validation loss decreased (inf --> 0.139998).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1822216
	speed: 1.1356s/iter; left time: 4885.4804s
	iters: 200, epoch: 2 | loss: 0.2154800
	speed: 0.3073s/iter; left time: 1291.0889s
	iters: 300, epoch: 2 | loss: 0.1995906
	speed: 0.3596s/iter; left time: 1474.9966s
	iters: 400, epoch: 2 | loss: 0.2202242
	speed: 0.3541s/iter; left time: 1416.9774s
Epoch: 2 cost time: 162.400075674057
Epoch: 2, Steps: 489 | Train Loss: 0.2077242 Vali Loss: 0.1619712 Test Loss: 0.1618009
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1974706
	speed: 1.1981s/iter; left time: 4568.2791s
	iters: 200, epoch: 3 | loss: 0.1860173
	speed: 0.3262s/iter; left time: 1211.0312s
	iters: 300, epoch: 3 | loss: 0.2161361
	speed: 0.2688s/iter; left time: 971.2264s
	iters: 400, epoch: 3 | loss: 0.2048576
	speed: 0.3268s/iter; left time: 1148.1416s
Epoch: 3 cost time: 154.0262794494629
Epoch: 3, Steps: 489 | Train Loss: 0.1975698 Vali Loss: 0.1117890 Test Loss: 0.1131776
Validation loss decreased (0.139998 --> 0.111789).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1924537
	speed: 1.1805s/iter; left time: 3924.0174s
	iters: 200, epoch: 4 | loss: 0.1810834
	speed: 0.3590s/iter; left time: 1157.2897s
	iters: 300, epoch: 4 | loss: 0.1907638
	speed: 0.3476s/iter; left time: 1085.9696s
	iters: 400, epoch: 4 | loss: 0.1884256
	speed: 0.2999s/iter; left time: 906.8981s
Epoch: 4 cost time: 158.84452509880066
Epoch: 4, Steps: 489 | Train Loss: 0.1927155 Vali Loss: 0.0932336 Test Loss: 0.0954658
Validation loss decreased (0.111789 --> 0.093234).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2106988
	speed: 1.1530s/iter; left time: 3268.7245s
	iters: 200, epoch: 5 | loss: 0.2008079
	speed: 0.3934s/iter; left time: 1075.9879s
	iters: 300, epoch: 5 | loss: 0.1710262
	speed: 0.3745s/iter; left time: 986.7605s
	iters: 400, epoch: 5 | loss: 0.1846374
	speed: 0.3570s/iter; left time: 905.0419s
Epoch: 5 cost time: 182.66976070404053
Epoch: 5, Steps: 489 | Train Loss: 0.1897999 Vali Loss: 0.0970676 Test Loss: 0.0986280
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1654888
	speed: 1.2412s/iter; left time: 2911.7399s
	iters: 200, epoch: 6 | loss: 0.1922899
	speed: 0.3529s/iter; left time: 792.5940s
	iters: 300, epoch: 6 | loss: 0.1925871
	speed: 0.3312s/iter; left time: 710.7436s
	iters: 400, epoch: 6 | loss: 0.1688269
	speed: 0.3064s/iter; left time: 626.9285s
Epoch: 6 cost time: 158.3341088294983
Epoch: 6, Steps: 489 | Train Loss: 0.1880862 Vali Loss: 0.0897025 Test Loss: 0.0916265
Validation loss decreased (0.093234 --> 0.089703).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1964912
	speed: 1.0104s/iter; left time: 1876.2922s
	iters: 200, epoch: 7 | loss: 0.1977374
	speed: 0.2726s/iter; left time: 478.9145s
	iters: 300, epoch: 7 | loss: 0.1852112
	speed: 0.2766s/iter; left time: 458.2445s
	iters: 400, epoch: 7 | loss: 0.1782118
	speed: 0.3030s/iter; left time: 471.6976s
Epoch: 7 cost time: 141.41385555267334
Epoch: 7, Steps: 489 | Train Loss: 0.1870265 Vali Loss: 0.0886058 Test Loss: 0.0903590
Validation loss decreased (0.089703 --> 0.088606).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2408367
	speed: 1.0620s/iter; left time: 1452.7612s
	iters: 200, epoch: 8 | loss: 0.2037961
	speed: 0.3098s/iter; left time: 392.8133s
	iters: 300, epoch: 8 | loss: 0.2110796
	speed: 0.2150s/iter; left time: 251.0749s
	iters: 400, epoch: 8 | loss: 0.1967881
	speed: 0.2536s/iter; left time: 270.8381s
Epoch: 8 cost time: 138.3167896270752
Epoch: 8, Steps: 489 | Train Loss: 0.1871879 Vali Loss: 0.0910371 Test Loss: 0.0929818
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1498783
	speed: 0.9954s/iter; left time: 874.9201s
	iters: 200, epoch: 9 | loss: 0.1678008
	speed: 0.2499s/iter; left time: 194.6766s
	iters: 300, epoch: 9 | loss: 0.1665897
	speed: 0.2534s/iter; left time: 172.0698s
	iters: 400, epoch: 9 | loss: 0.1852274
	speed: 0.2066s/iter; left time: 119.5928s
Epoch: 9 cost time: 112.53360223770142
Epoch: 9, Steps: 489 | Train Loss: 0.1873531 Vali Loss: 0.0926198 Test Loss: 0.0946303
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1827120
	speed: 0.8584s/iter; left time: 334.7708s
	iters: 200, epoch: 10 | loss: 0.1655590
	speed: 0.2523s/iter; left time: 73.1714s
	iters: 300, epoch: 10 | loss: 0.1942736
	speed: 0.2556s/iter; left time: 48.5558s
	iters: 400, epoch: 10 | loss: 0.2068917
	speed: 0.2548s/iter; left time: 22.9277s
Epoch: 10 cost time: 122.31993317604065
Epoch: 10, Steps: 489 | Train Loss: 0.1861643 Vali Loss: 0.0909664 Test Loss: 0.0929374
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5135
test shape: (5135, 12, 358) (5135, 12, 358)
test shape: (5135, 12, 358) (5135, 12, 358)
mse:0.09039562195539474, mae:0.20706748962402344
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS04              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS04.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             307                 Dec In:             307                 
  C Out:              307                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10088
val 3291
test 3292
	iters: 100, epoch: 1 | loss: 0.2431923
	speed: 0.2254s/iter; left time: 689.9134s
	iters: 200, epoch: 1 | loss: 0.2226894
	speed: 0.2197s/iter; left time: 650.4246s
	iters: 300, epoch: 1 | loss: 0.2545962
	speed: 0.2185s/iter; left time: 625.0513s
Epoch: 1 cost time: 69.79425048828125
Epoch: 1, Steps: 316 | Train Loss: 0.2729750 Vali Loss: 0.3710478 Test Loss: 0.3473413
Validation loss decreased (inf --> 0.371048).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2248006
	speed: 0.4639s/iter; left time: 1273.3793s
	iters: 200, epoch: 2 | loss: 0.2294411
	speed: 0.1812s/iter; left time: 479.1971s
	iters: 300, epoch: 2 | loss: 0.2121712
	speed: 0.1667s/iter; left time: 424.3235s
Epoch: 2 cost time: 58.005624294281006
Epoch: 2, Steps: 316 | Train Loss: 0.2260376 Vali Loss: 0.1383095 Test Loss: 0.1307945
Validation loss decreased (0.371048 --> 0.138309).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1922395
	speed: 0.3890s/iter; left time: 944.9282s
	iters: 200, epoch: 3 | loss: 0.2160404
	speed: 0.1625s/iter; left time: 378.4820s
	iters: 300, epoch: 3 | loss: 0.1853403
	speed: 0.2085s/iter; left time: 464.7383s
Epoch: 3 cost time: 57.62346053123474
Epoch: 3, Steps: 316 | Train Loss: 0.2087863 Vali Loss: 0.1217951 Test Loss: 0.1167731
Validation loss decreased (0.138309 --> 0.121795).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1764978
	speed: 0.4598s/iter; left time: 971.6228s
	iters: 200, epoch: 4 | loss: 0.1893514
	speed: 0.2185s/iter; left time: 439.8427s
	iters: 300, epoch: 4 | loss: 0.2012251
	speed: 0.2186s/iter; left time: 418.2640s
Epoch: 4 cost time: 68.25436067581177
Epoch: 4, Steps: 316 | Train Loss: 0.2049699 Vali Loss: 0.1185821 Test Loss: 0.1130193
Validation loss decreased (0.121795 --> 0.118582).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1916018
	speed: 0.4290s/iter; left time: 770.9856s
	iters: 200, epoch: 5 | loss: 0.2135909
	speed: 0.1521s/iter; left time: 258.1978s
	iters: 300, epoch: 5 | loss: 0.1970744
	speed: 0.1712s/iter; left time: 273.4060s
Epoch: 5 cost time: 52.521754026412964
Epoch: 5, Steps: 316 | Train Loss: 0.2029615 Vali Loss: 0.1161219 Test Loss: 0.1110636
Validation loss decreased (0.118582 --> 0.116122).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1952419
	speed: 0.4753s/iter; left time: 703.9239s
	iters: 200, epoch: 6 | loss: 0.1921706
	speed: 0.2182s/iter; left time: 301.3122s
	iters: 300, epoch: 6 | loss: 0.2184215
	speed: 0.2198s/iter; left time: 281.5752s
Epoch: 6 cost time: 69.25222110748291
Epoch: 6, Steps: 316 | Train Loss: 0.2019740 Vali Loss: 0.1140397 Test Loss: 0.1087336
Validation loss decreased (0.116122 --> 0.114040).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2068732
	speed: 0.4470s/iter; left time: 520.8105s
	iters: 200, epoch: 7 | loss: 0.1999271
	speed: 0.1526s/iter; left time: 162.4727s
	iters: 300, epoch: 7 | loss: 0.1872067
	speed: 0.1701s/iter; left time: 164.1826s
Epoch: 7 cost time: 54.556920528411865
Epoch: 7, Steps: 316 | Train Loss: 0.2016186 Vali Loss: 0.1159570 Test Loss: 0.1106328
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2017156
	speed: 0.4701s/iter; left time: 399.1061s
	iters: 200, epoch: 8 | loss: 0.2180715
	speed: 0.2189s/iter; left time: 163.9687s
	iters: 300, epoch: 8 | loss: 0.2281486
	speed: 0.2048s/iter; left time: 132.8830s
Epoch: 8 cost time: 67.39273262023926
Epoch: 8, Steps: 316 | Train Loss: 0.2011188 Vali Loss: 0.1165641 Test Loss: 0.1113355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1898648
	speed: 0.4602s/iter; left time: 245.2974s
	iters: 200, epoch: 9 | loss: 0.1802746
	speed: 0.1952s/iter; left time: 84.5114s
	iters: 300, epoch: 9 | loss: 0.2268580
	speed: 0.1719s/iter; left time: 57.2442s
Epoch: 9 cost time: 60.67373514175415
Epoch: 9, Steps: 316 | Train Loss: 0.2009588 Vali Loss: 0.1185488 Test Loss: 0.1130707
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1866792
	speed: 0.4653s/iter; left time: 100.9680s
	iters: 200, epoch: 10 | loss: 0.2218310
	speed: 0.2021s/iter; left time: 23.6422s
	iters: 300, epoch: 10 | loss: 0.2103059
	speed: 0.2008s/iter; left time: 3.4128s
Epoch: 10 cost time: 64.5155782699585
Epoch: 10, Steps: 316 | Train Loss: 0.2007842 Vali Loss: 0.1168146 Test Loss: 0.1115823
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3292
test shape: (3292, 12, 307) (3292, 12, 307)
test shape: (3292, 12, 307) (3292, 12, 307)
mse:0.10879100859165192, mae:0.22391283512115479
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS07              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS07.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             883                 Dec In:             883                 
  C Out:              883                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16827
val 5538
test 5538
	iters: 100, epoch: 1 | loss: 0.2687713
	speed: 0.6235s/iter; left time: 3218.0606s
	iters: 200, epoch: 1 | loss: 0.2418754
	speed: 0.6706s/iter; left time: 3393.8815s
	iters: 300, epoch: 1 | loss: 0.1796077
	speed: 0.6708s/iter; left time: 3328.0388s
	iters: 400, epoch: 1 | loss: 0.2149259
	speed: 0.7231s/iter; left time: 3515.0729s
	iters: 500, epoch: 1 | loss: 0.1928703
	speed: 0.5338s/iter; left time: 2541.3829s
Epoch: 1 cost time: 339.5379536151886
Epoch: 1, Steps: 526 | Train Loss: 0.2509287 Vali Loss: 0.1090066 Test Loss: 0.1111570
Validation loss decreased (inf --> 0.109007).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2156925
	speed: 1.5596s/iter; left time: 7228.9626s
	iters: 200, epoch: 2 | loss: 0.1867502
	speed: 0.3894s/iter; left time: 1765.7088s
	iters: 300, epoch: 2 | loss: 0.1746047
	speed: 0.3483s/iter; left time: 1544.8827s
	iters: 400, epoch: 2 | loss: 0.1948880
	speed: 0.5905s/iter; left time: 2559.9396s
	iters: 500, epoch: 2 | loss: 0.1836227
	speed: 0.5923s/iter; left time: 2508.3610s
Epoch: 2 cost time: 254.08265352249146
Epoch: 2, Steps: 526 | Train Loss: 0.2031027 Vali Loss: 0.0873297 Test Loss: 0.0881985
Validation loss decreased (0.109007 --> 0.087330).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1623894
	speed: 1.4781s/iter; left time: 6073.6572s
	iters: 200, epoch: 3 | loss: 0.1858961
	speed: 0.5782s/iter; left time: 2317.9243s
	iters: 300, epoch: 3 | loss: 0.2016902
	speed: 0.5834s/iter; left time: 2280.4736s
	iters: 400, epoch: 3 | loss: 0.1613850
	speed: 0.5103s/iter; left time: 1943.5636s
	iters: 500, epoch: 3 | loss: 0.1715037
	speed: 0.5845s/iter; left time: 2168.0832s
Epoch: 3 cost time: 290.79742765426636
Epoch: 3, Steps: 526 | Train Loss: 0.1932043 Vali Loss: 0.0869027 Test Loss: 0.0885900
Validation loss decreased (0.087330 --> 0.086903).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1620629
	speed: 1.5165s/iter; left time: 5433.7445s
	iters: 200, epoch: 4 | loss: 0.1845607
	speed: 0.5217s/iter; left time: 1816.9158s
	iters: 300, epoch: 4 | loss: 0.1847957
	speed: 0.5881s/iter; left time: 1989.4391s
	iters: 400, epoch: 4 | loss: 0.1997191
	speed: 0.5538s/iter; left time: 1818.0208s
	iters: 500, epoch: 4 | loss: 0.1464773
	speed: 0.5598s/iter; left time: 1781.7153s
Epoch: 4 cost time: 296.38972759246826
Epoch: 4, Steps: 526 | Train Loss: 0.1903790 Vali Loss: 0.0859761 Test Loss: 0.0879198
Validation loss decreased (0.086903 --> 0.085976).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2147566
	speed: 1.5508s/iter; left time: 4740.7100s
	iters: 200, epoch: 5 | loss: 0.1921887
	speed: 0.5566s/iter; left time: 1645.7848s
	iters: 300, epoch: 5 | loss: 0.1692157
	speed: 0.5547s/iter; left time: 1584.6855s
	iters: 400, epoch: 5 | loss: 0.1859658
	speed: 0.5885s/iter; left time: 1622.5245s
	iters: 500, epoch: 5 | loss: 0.2095999
	speed: 0.5215s/iter; left time: 1385.4932s
Epoch: 5 cost time: 296.311475276947
Epoch: 5, Steps: 526 | Train Loss: 0.1885274 Vali Loss: 0.0877057 Test Loss: 0.0893458
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1922089
	speed: 1.3736s/iter; left time: 3476.6234s
	iters: 200, epoch: 6 | loss: 0.1854592
	speed: 0.5904s/iter; left time: 1435.1990s
	iters: 300, epoch: 6 | loss: 0.1453982
	speed: 0.5896s/iter; left time: 1374.3462s
	iters: 400, epoch: 6 | loss: 0.2040458
	speed: 0.5246s/iter; left time: 1170.4786s
	iters: 500, epoch: 6 | loss: 0.1917074
	speed: 0.5874s/iter; left time: 1251.6633s
Epoch: 6 cost time: 284.1265616416931
Epoch: 6, Steps: 526 | Train Loss: 0.1874923 Vali Loss: 0.0842022 Test Loss: 0.0853484
Validation loss decreased (0.085976 --> 0.084202).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1772740
	speed: 1.5335s/iter; left time: 3074.6111s
	iters: 200, epoch: 7 | loss: 0.1782621
	speed: 0.5186s/iter; left time: 987.8870s
	iters: 300, epoch: 7 | loss: 0.1994679
	speed: 0.5861s/iter; left time: 1057.9470s
	iters: 400, epoch: 7 | loss: 0.1858078
	speed: 0.5259s/iter; left time: 896.6473s
	iters: 500, epoch: 7 | loss: 0.1891986
	speed: 0.5750s/iter; left time: 922.8847s
Epoch: 7 cost time: 294.89251804351807
Epoch: 7, Steps: 526 | Train Loss: 0.1869015 Vali Loss: 0.0841552 Test Loss: 0.0858074
Validation loss decreased (0.084202 --> 0.084155).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2026275
	speed: 1.5300s/iter; left time: 2262.9213s
	iters: 200, epoch: 8 | loss: 0.1677720
	speed: 0.5420s/iter; left time: 747.3517s
	iters: 300, epoch: 8 | loss: 0.2143132
	speed: 0.5467s/iter; left time: 699.1942s
	iters: 400, epoch: 8 | loss: 0.1932966
	speed: 0.5840s/iter; left time: 688.4817s
	iters: 500, epoch: 8 | loss: 0.2001934
	speed: 0.5128s/iter; left time: 553.2698s
Epoch: 8 cost time: 292.57914686203003
Epoch: 8, Steps: 526 | Train Loss: 0.1865620 Vali Loss: 0.0850433 Test Loss: 0.0867802
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1569129
	speed: 1.5280s/iter; left time: 1456.1564s
	iters: 200, epoch: 9 | loss: 0.2052869
	speed: 0.5837s/iter; left time: 497.9009s
	iters: 300, epoch: 9 | loss: 0.1866856
	speed: 0.5119s/iter; left time: 385.4352s
	iters: 400, epoch: 9 | loss: 0.2032503
	speed: 0.5866s/iter; left time: 383.0230s
	iters: 500, epoch: 9 | loss: 0.2011891
	speed: 0.5910s/iter; left time: 326.8493s
Epoch: 9 cost time: 291.5181267261505
Epoch: 9, Steps: 526 | Train Loss: 0.1863447 Vali Loss: 0.0834315 Test Loss: 0.0851200
Validation loss decreased (0.084155 --> 0.083431).  Saving model ...
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1909337
	speed: 0.8591s/iter; left time: 366.8306s
	iters: 200, epoch: 10 | loss: 0.1979046
	speed: 0.2761s/iter; left time: 90.2827s
	iters: 300, epoch: 10 | loss: 0.1967989
	speed: 0.2755s/iter; left time: 62.5399s
	iters: 400, epoch: 10 | loss: 0.1827991
	speed: 0.2766s/iter; left time: 35.1239s
	iters: 500, epoch: 10 | loss: 0.2109827
	speed: 0.2761s/iter; left time: 7.4537s
Epoch: 10 cost time: 145.46705150604248
Epoch: 10, Steps: 526 | Train Loss: 0.1862669 Vali Loss: 0.0840730 Test Loss: 0.0858436
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5538
test shape: (5538, 12, 883) (5538, 12, 883)
test shape: (5538, 12, 883) (5538, 12, 883)
mse:0.0848744735121727, mae:0.20228715240955353
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS08              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS08.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             170                 Dec In:             170                 
  C Out:              170                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10606
val 3464
test 3465
	iters: 100, epoch: 1 | loss: 0.2707019
	speed: 0.0641s/iter; left time: 206.5620s
	iters: 200, epoch: 1 | loss: 0.2701244
	speed: 0.0585s/iter; left time: 182.4561s
	iters: 300, epoch: 1 | loss: 0.1964667
	speed: 0.0588s/iter; left time: 177.5561s
Epoch: 1 cost time: 20.018868684768677
Epoch: 1, Steps: 332 | Train Loss: 0.2683295 Vali Loss: 0.1923863 Test Loss: 0.1862371
Validation loss decreased (inf --> 0.192386).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1851408
	speed: 0.1394s/iter; left time: 402.5903s
	iters: 200, epoch: 2 | loss: 0.2049273
	speed: 0.0585s/iter; left time: 163.1726s
	iters: 300, epoch: 2 | loss: 0.2137103
	speed: 0.0584s/iter; left time: 157.1614s
Epoch: 2 cost time: 19.602819681167603
Epoch: 2, Steps: 332 | Train Loss: 0.2138822 Vali Loss: 0.1362167 Test Loss: 0.1255488
Validation loss decreased (0.192386 --> 0.136217).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2024714
	speed: 0.1416s/iter; left time: 362.0118s
	iters: 200, epoch: 3 | loss: 0.2390240
	speed: 0.0584s/iter; left time: 143.5566s
	iters: 300, epoch: 3 | loss: 0.1756093
	speed: 0.0588s/iter; left time: 138.6742s
Epoch: 3 cost time: 19.59965968132019
Epoch: 3, Steps: 332 | Train Loss: 0.2024895 Vali Loss: 0.1150774 Test Loss: 0.1039882
Validation loss decreased (0.136217 --> 0.115077).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2157926
	speed: 0.1407s/iter; left time: 313.1368s
	iters: 200, epoch: 4 | loss: 0.2203835
	speed: 0.0586s/iter; left time: 124.5044s
	iters: 300, epoch: 4 | loss: 0.2097564
	speed: 0.0585s/iter; left time: 118.4049s
Epoch: 4 cost time: 19.557793855667114
Epoch: 4, Steps: 332 | Train Loss: 0.1988412 Vali Loss: 0.1117429 Test Loss: 0.1011072
Validation loss decreased (0.115077 --> 0.111743).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2104907
	speed: 0.1409s/iter; left time: 266.8051s
	iters: 200, epoch: 5 | loss: 0.2129013
	speed: 0.0584s/iter; left time: 104.7972s
	iters: 300, epoch: 5 | loss: 0.1923410
	speed: 0.0583s/iter; left time: 98.7815s
Epoch: 5 cost time: 19.52943444252014
Epoch: 5, Steps: 332 | Train Loss: 0.1964199 Vali Loss: 0.1110658 Test Loss: 0.1005016
Validation loss decreased (0.111743 --> 0.111066).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2090088
	speed: 0.1418s/iter; left time: 221.3501s
	iters: 200, epoch: 6 | loss: 0.1858834
	speed: 0.0587s/iter; left time: 85.7514s
	iters: 300, epoch: 6 | loss: 0.1886906
	speed: 0.0584s/iter; left time: 79.5135s
Epoch: 6 cost time: 19.600727319717407
Epoch: 6, Steps: 332 | Train Loss: 0.1952261 Vali Loss: 0.1172616 Test Loss: 0.1080635
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2099589
	speed: 0.1417s/iter; left time: 174.1683s
	iters: 200, epoch: 7 | loss: 0.2184460
	speed: 0.0583s/iter; left time: 65.8560s
	iters: 300, epoch: 7 | loss: 0.2032031
	speed: 0.0585s/iter; left time: 60.1792s
Epoch: 7 cost time: 19.590823888778687
Epoch: 7, Steps: 332 | Train Loss: 0.1943541 Vali Loss: 0.1125104 Test Loss: 0.1026484
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1840592
	speed: 0.1426s/iter; left time: 127.8808s
	iters: 200, epoch: 8 | loss: 0.2017835
	speed: 0.0586s/iter; left time: 46.6774s
	iters: 300, epoch: 8 | loss: 0.1745905
	speed: 0.0585s/iter; left time: 40.8070s
Epoch: 8 cost time: 19.548365831375122
Epoch: 8, Steps: 332 | Train Loss: 0.1939353 Vali Loss: 0.1149304 Test Loss: 0.1057245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1882353
	speed: 0.1413s/iter; left time: 79.8310s
	iters: 200, epoch: 9 | loss: 0.1919771
	speed: 0.0585s/iter; left time: 27.2072s
	iters: 300, epoch: 9 | loss: 0.2034369
	speed: 0.0585s/iter; left time: 21.3677s
Epoch: 9 cost time: 19.55985689163208
Epoch: 9, Steps: 332 | Train Loss: 0.1936127 Vali Loss: 0.1134123 Test Loss: 0.1036874
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1922941
	speed: 0.1419s/iter; left time: 33.0713s
	iters: 200, epoch: 10 | loss: 0.1735471
	speed: 0.0585s/iter; left time: 7.7789s
	iters: 300, epoch: 10 | loss: 0.2198660
	speed: 0.0584s/iter; left time: 1.9287s
Epoch: 10 cost time: 19.60949945449829
Epoch: 10, Steps: 332 | Train Loss: 0.1934892 Vali Loss: 0.1126194 Test Loss: 0.1030597
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3465
test shape: (3465, 12, 170) (3465, 12, 170)
test shape: (3465, 12, 170) (3465, 12, 170)
mse:0.10077567398548126, mae:0.21366310119628906
