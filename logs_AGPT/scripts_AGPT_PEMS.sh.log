Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS03              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS03.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             358                 Dec In:             358                 
  C Out:              358                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15617
val 5135
test 5135
	iters: 100, epoch: 1 | loss: 0.2410136
	speed: 0.3715s/iter; left time: 1780.0156s
	iters: 200, epoch: 1 | loss: 0.1961690
	speed: 0.3682s/iter; left time: 1727.2630s
	iters: 300, epoch: 1 | loss: 0.2548554
	speed: 0.3561s/iter; left time: 1635.0842s
	iters: 400, epoch: 1 | loss: 0.2221420
	speed: 0.3181s/iter; left time: 1428.7115s
Epoch: 1 cost time: 169.73685383796692
Epoch: 1, Steps: 489 | Train Loss: 0.2507309 Vali Loss: 0.1399979 Test Loss: 0.1382285
Validation loss decreased (inf --> 0.139998).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1822216
	speed: 1.1785s/iter; left time: 5070.0180s
	iters: 200, epoch: 2 | loss: 0.2154800
	speed: 0.3462s/iter; left time: 1454.5757s
	iters: 300, epoch: 2 | loss: 0.1995906
	speed: 0.2994s/iter; left time: 1227.9930s
	iters: 400, epoch: 2 | loss: 0.2202242
	speed: 0.2833s/iter; left time: 1133.8615s
Epoch: 2 cost time: 151.2219831943512
Epoch: 2, Steps: 489 | Train Loss: 0.2077242 Vali Loss: 0.1619712 Test Loss: 0.1618009
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1974706
	speed: 1.1931s/iter; left time: 4549.2530s
	iters: 200, epoch: 3 | loss: 0.1860173
	speed: 0.2764s/iter; left time: 1026.4072s
	iters: 300, epoch: 3 | loss: 0.2161361
	speed: 0.3538s/iter; left time: 1278.3562s
	iters: 400, epoch: 3 | loss: 0.2048576
	speed: 0.3377s/iter; left time: 1186.3571s
Epoch: 3 cost time: 148.4435441493988
Epoch: 3, Steps: 489 | Train Loss: 0.1975698 Vali Loss: 0.1117890 Test Loss: 0.1131776
Validation loss decreased (0.139998 --> 0.111789).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1924537
	speed: 1.1081s/iter; left time: 3683.2747s
	iters: 200, epoch: 4 | loss: 0.1810834
	speed: 0.2918s/iter; left time: 940.6687s
	iters: 300, epoch: 4 | loss: 0.1907638
	speed: 0.3790s/iter; left time: 1184.0520s
	iters: 400, epoch: 4 | loss: 0.1884256
	speed: 0.2591s/iter; left time: 783.6649s
Epoch: 4 cost time: 141.971941947937
Epoch: 4, Steps: 489 | Train Loss: 0.1927155 Vali Loss: 0.0932336 Test Loss: 0.0954658
Validation loss decreased (0.111789 --> 0.093234).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2106988
	speed: 1.1423s/iter; left time: 3238.5535s
	iters: 200, epoch: 5 | loss: 0.2008079
	speed: 0.2808s/iter; left time: 768.0371s
	iters: 300, epoch: 5 | loss: 0.1710262
	speed: 0.2630s/iter; left time: 692.9930s
	iters: 400, epoch: 5 | loss: 0.1846374
	speed: 0.3032s/iter; left time: 768.7296s
Epoch: 5 cost time: 132.34895062446594
Epoch: 5, Steps: 489 | Train Loss: 0.1897999 Vali Loss: 0.0970676 Test Loss: 0.0986280
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1654888
	speed: 1.1953s/iter; left time: 2804.1241s
	iters: 200, epoch: 6 | loss: 0.1922899
	speed: 0.2520s/iter; left time: 566.0534s
	iters: 300, epoch: 6 | loss: 0.1925871
	speed: 0.2451s/iter; left time: 526.0338s
	iters: 400, epoch: 6 | loss: 0.1688269
	speed: 0.2634s/iter; left time: 538.8274s
Epoch: 6 cost time: 119.4746482372284
Epoch: 6, Steps: 489 | Train Loss: 0.1880862 Vali Loss: 0.0897025 Test Loss: 0.0916265
Validation loss decreased (0.093234 --> 0.089703).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1964912
	speed: 0.8633s/iter; left time: 1603.0961s
	iters: 200, epoch: 7 | loss: 0.1977374
	speed: 0.2502s/iter; left time: 439.6411s
	iters: 300, epoch: 7 | loss: 0.1852112
	speed: 0.2442s/iter; left time: 404.6829s
	iters: 400, epoch: 7 | loss: 0.1782118
	speed: 0.2258s/iter; left time: 351.5000s
Epoch: 7 cost time: 109.28082942962646
Epoch: 7, Steps: 489 | Train Loss: 0.1870265 Vali Loss: 0.0886058 Test Loss: 0.0903590
Validation loss decreased (0.089703 --> 0.088606).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2408367
	speed: 0.8768s/iter; left time: 1199.4377s
	iters: 200, epoch: 8 | loss: 0.2037961
	speed: 0.2346s/iter; left time: 297.5027s
	iters: 300, epoch: 8 | loss: 0.2110796
	speed: 0.2408s/iter; left time: 281.2390s
	iters: 400, epoch: 8 | loss: 0.1967881
	speed: 0.1791s/iter; left time: 191.2703s
Epoch: 8 cost time: 102.9826455116272
Epoch: 8, Steps: 489 | Train Loss: 0.1871879 Vali Loss: 0.0910371 Test Loss: 0.0929818
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1498783
	speed: 0.8298s/iter; left time: 729.3748s
	iters: 200, epoch: 9 | loss: 0.1678008
	speed: 0.2160s/iter; left time: 168.2375s
	iters: 300, epoch: 9 | loss: 0.1665897
	speed: 0.1636s/iter; left time: 111.1053s
	iters: 400, epoch: 9 | loss: 0.1852274
	speed: 0.1540s/iter; left time: 89.1878s
Epoch: 9 cost time: 93.40508270263672
Epoch: 9, Steps: 489 | Train Loss: 0.1873531 Vali Loss: 0.0926198 Test Loss: 0.0946303
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1827120
	speed: 0.9119s/iter; left time: 355.6249s
	iters: 200, epoch: 10 | loss: 0.1655590
	speed: 0.1800s/iter; left time: 52.1855s
	iters: 300, epoch: 10 | loss: 0.1942736
	speed: 0.1744s/iter; left time: 33.1426s
	iters: 400, epoch: 10 | loss: 0.2068917
	speed: 0.2248s/iter; left time: 20.2278s
Epoch: 10 cost time: 100.313560962677
Epoch: 10, Steps: 489 | Train Loss: 0.1861643 Vali Loss: 0.0909664 Test Loss: 0.0929374
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5135
test shape: (5135, 12, 358) (5135, 12, 358)
test shape: (5135, 12, 358) (5135, 12, 358)
mse:0.09039562195539474, mae:0.20706748962402344
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS04              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS04.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             307                 Dec In:             307                 
  C Out:              307                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10088
val 3291
test 3292
	iters: 100, epoch: 1 | loss: 0.2431923
	speed: 0.2683s/iter; left time: 821.3337s
	iters: 200, epoch: 1 | loss: 0.2226894
	speed: 0.2303s/iter; left time: 681.8258s
	iters: 300, epoch: 1 | loss: 0.2545962
	speed: 0.2813s/iter; left time: 804.6968s
Epoch: 1 cost time: 82.42654347419739
Epoch: 1, Steps: 316 | Train Loss: 0.2729750 Vali Loss: 0.3710478 Test Loss: 0.3473413
Validation loss decreased (inf --> 0.371048).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2248006
	speed: 0.5416s/iter; left time: 1486.7848s
	iters: 200, epoch: 2 | loss: 0.2294411
	speed: 0.1814s/iter; left time: 479.8717s
	iters: 300, epoch: 2 | loss: 0.2121712
	speed: 0.1735s/iter; left time: 441.4779s
Epoch: 2 cost time: 62.12520933151245
Epoch: 2, Steps: 316 | Train Loss: 0.2260376 Vali Loss: 0.1383095 Test Loss: 0.1307945
Validation loss decreased (0.371048 --> 0.138309).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1922395
	speed: 0.5647s/iter; left time: 1371.5735s
	iters: 200, epoch: 3 | loss: 0.2160404
	speed: 0.1724s/iter; left time: 401.5803s
	iters: 300, epoch: 3 | loss: 0.1853403
	speed: 0.1273s/iter; left time: 283.6831s
Epoch: 3 cost time: 49.79730224609375
Epoch: 3, Steps: 316 | Train Loss: 0.2087863 Vali Loss: 0.1217951 Test Loss: 0.1167731
Validation loss decreased (0.138309 --> 0.121795).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1764978
	speed: 0.4706s/iter; left time: 994.2727s
	iters: 200, epoch: 4 | loss: 0.1893514
	speed: 0.1771s/iter; left time: 356.4132s
	iters: 300, epoch: 4 | loss: 0.2012251
	speed: 0.1800s/iter; left time: 344.3886s
Epoch: 4 cost time: 56.85063290596008
Epoch: 4, Steps: 316 | Train Loss: 0.2049699 Vali Loss: 0.1185821 Test Loss: 0.1130193
Validation loss decreased (0.121795 --> 0.118582).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1916018
	speed: 0.3960s/iter; left time: 711.6976s
	iters: 200, epoch: 5 | loss: 0.2135909
	speed: 0.1325s/iter; left time: 224.8331s
	iters: 300, epoch: 5 | loss: 0.1970744
	speed: 0.1686s/iter; left time: 269.2852s
Epoch: 5 cost time: 46.051793575286865
Epoch: 5, Steps: 316 | Train Loss: 0.2029615 Vali Loss: 0.1161219 Test Loss: 0.1110636
Validation loss decreased (0.118582 --> 0.116122).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1952419
	speed: 0.4143s/iter; left time: 613.5696s
	iters: 200, epoch: 6 | loss: 0.1921706
	speed: 0.1818s/iter; left time: 251.0345s
	iters: 300, epoch: 6 | loss: 0.2184215
	speed: 0.1430s/iter; left time: 183.1454s
Epoch: 6 cost time: 52.813982248306274
Epoch: 6, Steps: 316 | Train Loss: 0.2019740 Vali Loss: 0.1140397 Test Loss: 0.1087336
Validation loss decreased (0.116122 --> 0.114040).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2068732
	speed: 0.4275s/iter; left time: 498.0751s
	iters: 200, epoch: 7 | loss: 0.1999271
	speed: 0.1836s/iter; left time: 195.5616s
	iters: 300, epoch: 7 | loss: 0.1872067
	speed: 0.1843s/iter; left time: 177.8729s
Epoch: 7 cost time: 58.32916522026062
Epoch: 7, Steps: 316 | Train Loss: 0.2016186 Vali Loss: 0.1159570 Test Loss: 0.1106328
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2017156
	speed: 0.3836s/iter; left time: 325.7116s
	iters: 200, epoch: 8 | loss: 0.2180715
	speed: 0.1294s/iter; left time: 96.9510s
	iters: 300, epoch: 8 | loss: 0.2281486
	speed: 0.1343s/iter; left time: 87.1769s
Epoch: 8 cost time: 41.641133546829224
Epoch: 8, Steps: 316 | Train Loss: 0.2011188 Vali Loss: 0.1165641 Test Loss: 0.1113355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1898648
	speed: 0.3552s/iter; left time: 189.3178s
	iters: 200, epoch: 9 | loss: 0.1802746
	speed: 0.2216s/iter; left time: 95.9676s
	iters: 300, epoch: 9 | loss: 0.2268580
	speed: 0.2149s/iter; left time: 71.5647s
Epoch: 9 cost time: 67.82881951332092
Epoch: 9, Steps: 316 | Train Loss: 0.2009588 Vali Loss: 0.1185488 Test Loss: 0.1130707
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1866792
	speed: 0.4364s/iter; left time: 94.6958s
	iters: 200, epoch: 10 | loss: 0.2218310
	speed: 0.2212s/iter; left time: 25.8781s
	iters: 300, epoch: 10 | loss: 0.2103059
	speed: 0.1592s/iter; left time: 2.7065s
Epoch: 10 cost time: 63.93775391578674
Epoch: 10, Steps: 316 | Train Loss: 0.2007842 Vali Loss: 0.1168146 Test Loss: 0.1115823
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3292
test shape: (3292, 12, 307) (3292, 12, 307)
test shape: (3292, 12, 307) (3292, 12, 307)
mse:0.10879100859165192, mae:0.22391283512115479
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS07              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS07.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             883                 Dec In:             883                 
  C Out:              883                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16827
val 5538
test 5538
	iters: 100, epoch: 1 | loss: 0.2687713
	speed: 0.5401s/iter; left time: 2787.5642s
	iters: 200, epoch: 1 | loss: 0.2418754
	speed: 0.5235s/iter; left time: 2649.6503s
	iters: 300, epoch: 1 | loss: 0.1796077
	speed: 0.5462s/iter; left time: 2709.7178s
	iters: 400, epoch: 1 | loss: 0.2149259
	speed: 0.5600s/iter; left time: 2722.2453s
	iters: 500, epoch: 1 | loss: 0.1928703
	speed: 0.5236s/iter; left time: 2493.0231s
Epoch: 1 cost time: 284.4203431606293
Epoch: 1, Steps: 526 | Train Loss: 0.2509287 Vali Loss: 0.1090066 Test Loss: 0.1111570
Validation loss decreased (inf --> 0.109007).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2156925
	speed: 1.3484s/iter; left time: 6249.8944s
	iters: 200, epoch: 2 | loss: 0.1867502
	speed: 0.5408s/iter; left time: 2452.3371s
	iters: 300, epoch: 2 | loss: 0.1746047
	speed: 0.4810s/iter; left time: 2133.1473s
	iters: 400, epoch: 2 | loss: 0.1948880
	speed: 0.5591s/iter; left time: 2423.6370s
	iters: 500, epoch: 2 | loss: 0.1836227
	speed: 0.4640s/iter; left time: 1965.1231s
Epoch: 2 cost time: 274.54791355133057
Epoch: 2, Steps: 526 | Train Loss: 0.2031027 Vali Loss: 0.0873297 Test Loss: 0.0881985
Validation loss decreased (0.109007 --> 0.087330).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1623894
	speed: 1.4364s/iter; left time: 5902.1417s
	iters: 200, epoch: 3 | loss: 0.1858961
	speed: 0.5500s/iter; left time: 2204.9284s
	iters: 300, epoch: 3 | loss: 0.2016902
	speed: 0.5391s/iter; left time: 2107.3018s
	iters: 400, epoch: 3 | loss: 0.1613850
	speed: 0.5063s/iter; left time: 1928.5480s
	iters: 500, epoch: 3 | loss: 0.1715037
	speed: 0.5563s/iter; left time: 2063.3857s
Epoch: 3 cost time: 277.3347587585449
Epoch: 3, Steps: 526 | Train Loss: 0.1932043 Vali Loss: 0.0869027 Test Loss: 0.0885900
Validation loss decreased (0.087330 --> 0.086903).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1620629
	speed: 1.4580s/iter; left time: 5224.0267s
	iters: 200, epoch: 4 | loss: 0.1845607
	speed: 0.3360s/iter; left time: 1170.1727s
	iters: 300, epoch: 4 | loss: 0.1847957
	speed: 0.2750s/iter; left time: 930.4450s
	iters: 400, epoch: 4 | loss: 0.1997191
	speed: 0.2749s/iter; left time: 902.6083s
	iters: 500, epoch: 4 | loss: 0.1464773
	speed: 0.2753s/iter; left time: 876.4300s
Epoch: 4 cost time: 181.62584352493286
Epoch: 4, Steps: 526 | Train Loss: 0.1903790 Vali Loss: 0.0859761 Test Loss: 0.0879198
Validation loss decreased (0.086903 --> 0.085976).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2147566
	speed: 0.7556s/iter; left time: 2309.9099s
	iters: 200, epoch: 5 | loss: 0.1921887
	speed: 0.2782s/iter; left time: 822.7564s
	iters: 300, epoch: 5 | loss: 0.1692157
	speed: 0.2776s/iter; left time: 793.1554s
	iters: 400, epoch: 5 | loss: 0.1859658
	speed: 0.2781s/iter; left time: 766.7700s
	iters: 500, epoch: 5 | loss: 0.2095999
	speed: 0.2758s/iter; left time: 732.8127s
Epoch: 5 cost time: 145.98882746696472
Epoch: 5, Steps: 526 | Train Loss: 0.1885274 Vali Loss: 0.0877057 Test Loss: 0.0893458
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1922089
	speed: 0.7729s/iter; left time: 1956.1372s
	iters: 200, epoch: 6 | loss: 0.1854592
	speed: 0.2761s/iter; left time: 671.2679s
	iters: 300, epoch: 6 | loss: 0.1453982
	speed: 0.2748s/iter; left time: 640.6616s
	iters: 400, epoch: 6 | loss: 0.2040458
	speed: 0.2751s/iter; left time: 613.6767s
	iters: 500, epoch: 6 | loss: 0.1917074
	speed: 0.2749s/iter; left time: 585.9025s
Epoch: 6 cost time: 145.20039987564087
Epoch: 6, Steps: 526 | Train Loss: 0.1874923 Vali Loss: 0.0842022 Test Loss: 0.0853484
Validation loss decreased (0.085976 --> 0.084202).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1772740
	speed: 0.7550s/iter; left time: 1513.8344s
	iters: 200, epoch: 7 | loss: 0.1782621
	speed: 0.2761s/iter; left time: 525.9563s
	iters: 300, epoch: 7 | loss: 0.1994679
	speed: 0.2754s/iter; left time: 497.0627s
	iters: 400, epoch: 7 | loss: 0.1858078
	speed: 0.2758s/iter; left time: 470.2019s
	iters: 500, epoch: 7 | loss: 0.1891986
	speed: 0.2746s/iter; left time: 440.6560s
Epoch: 7 cost time: 145.11132502555847
Epoch: 7, Steps: 526 | Train Loss: 0.1869015 Vali Loss: 0.0841552 Test Loss: 0.0858074
Validation loss decreased (0.084202 --> 0.084155).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2026275
	speed: 0.7589s/iter; left time: 1122.4775s
	iters: 200, epoch: 8 | loss: 0.1677720
	speed: 0.2758s/iter; left time: 380.2851s
	iters: 300, epoch: 8 | loss: 0.2143132
	speed: 0.2759s/iter; left time: 352.8627s
	iters: 400, epoch: 8 | loss: 0.1932966
	speed: 0.2749s/iter; left time: 324.1352s
	iters: 500, epoch: 8 | loss: 0.2001934
	speed: 0.2753s/iter; left time: 297.0706s
Epoch: 8 cost time: 145.1523299217224
Epoch: 8, Steps: 526 | Train Loss: 0.1865620 Vali Loss: 0.0850433 Test Loss: 0.0867802
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1569129
	speed: 0.7491s/iter; left time: 713.9353s
	iters: 200, epoch: 9 | loss: 0.2052869
	speed: 0.2777s/iter; left time: 236.8371s
	iters: 300, epoch: 9 | loss: 0.1866856
	speed: 0.2773s/iter; left time: 208.8198s
	iters: 400, epoch: 9 | loss: 0.2032503
	speed: 0.2777s/iter; left time: 181.3519s
	iters: 500, epoch: 9 | loss: 0.2011891
	speed: 0.2762s/iter; left time: 152.7500s
Epoch: 9 cost time: 145.7995367050171
Epoch: 9, Steps: 526 | Train Loss: 0.1863447 Vali Loss: 0.0834315 Test Loss: 0.0851200
Validation loss decreased (0.084155 --> 0.083431).  Saving model ...
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1909337
	speed: 0.7742s/iter; left time: 330.5828s
	iters: 200, epoch: 10 | loss: 0.1979046
	speed: 0.2748s/iter; left time: 89.8541s
	iters: 300, epoch: 10 | loss: 0.1967989
	speed: 0.2764s/iter; left time: 62.7502s
	iters: 400, epoch: 10 | loss: 0.1827991
	speed: 0.2760s/iter; left time: 35.0534s
	iters: 500, epoch: 10 | loss: 0.2109827
	speed: 0.2752s/iter; left time: 7.4303s
Epoch: 10 cost time: 145.29050588607788
Epoch: 10, Steps: 526 | Train Loss: 0.1862669 Vali Loss: 0.0840730 Test Loss: 0.0858436
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5538
test shape: (5538, 12, 883) (5538, 12, 883)
test shape: (5538, 12, 883) (5538, 12, 883)
mse:0.0848744735121727, mae:0.20228715240955353
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS08              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS08.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             170                 Dec In:             170                 
  C Out:              170                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10606
val 3464
test 3465
	iters: 100, epoch: 1 | loss: 0.2707019
	speed: 0.0639s/iter; left time: 205.8981s
	iters: 200, epoch: 1 | loss: 0.2701244
	speed: 0.0585s/iter; left time: 182.4987s
	iters: 300, epoch: 1 | loss: 0.1964667
	speed: 0.0586s/iter; left time: 177.1265s
Epoch: 1 cost time: 19.98408031463623
Epoch: 1, Steps: 332 | Train Loss: 0.2683295 Vali Loss: 0.1923863 Test Loss: 0.1862371
Validation loss decreased (inf --> 0.192386).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1851408
	speed: 0.1387s/iter; left time: 400.6283s
	iters: 200, epoch: 2 | loss: 0.2049273
	speed: 0.0581s/iter; left time: 162.0567s
	iters: 300, epoch: 2 | loss: 0.2137103
	speed: 0.0586s/iter; left time: 157.6680s
Epoch: 2 cost time: 19.598711729049683
Epoch: 2, Steps: 332 | Train Loss: 0.2138822 Vali Loss: 0.1362167 Test Loss: 0.1255488
Validation loss decreased (0.192386 --> 0.136217).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2024714
	speed: 0.1439s/iter; left time: 367.8357s
	iters: 200, epoch: 3 | loss: 0.2390240
	speed: 0.0583s/iter; left time: 143.3289s
	iters: 300, epoch: 3 | loss: 0.1756093
	speed: 0.0583s/iter; left time: 137.3401s
Epoch: 3 cost time: 19.60003161430359
Epoch: 3, Steps: 332 | Train Loss: 0.2024895 Vali Loss: 0.1150774 Test Loss: 0.1039882
Validation loss decreased (0.136217 --> 0.115077).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2157926
	speed: 0.1433s/iter; left time: 318.9224s
	iters: 200, epoch: 4 | loss: 0.2203835
	speed: 0.0582s/iter; left time: 123.5760s
	iters: 300, epoch: 4 | loss: 0.2097564
	speed: 0.0582s/iter; left time: 117.8124s
Epoch: 4 cost time: 19.506659984588623
Epoch: 4, Steps: 332 | Train Loss: 0.1988412 Vali Loss: 0.1117429 Test Loss: 0.1011072
Validation loss decreased (0.115077 --> 0.111743).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2104907
	speed: 0.1434s/iter; left time: 271.3933s
	iters: 200, epoch: 5 | loss: 0.2129013
	speed: 0.0581s/iter; left time: 104.2582s
	iters: 300, epoch: 5 | loss: 0.1923410
	speed: 0.0585s/iter; left time: 98.9887s
Epoch: 5 cost time: 19.54708766937256
Epoch: 5, Steps: 332 | Train Loss: 0.1964199 Vali Loss: 0.1110658 Test Loss: 0.1005016
Validation loss decreased (0.111743 --> 0.111066).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2090088
	speed: 0.1442s/iter; left time: 225.0311s
	iters: 200, epoch: 6 | loss: 0.1858834
	speed: 0.0581s/iter; left time: 84.9169s
	iters: 300, epoch: 6 | loss: 0.1886906
	speed: 0.0582s/iter; left time: 79.1785s
Epoch: 6 cost time: 19.597068071365356
Epoch: 6, Steps: 332 | Train Loss: 0.1952261 Vali Loss: 0.1172616 Test Loss: 0.1080635
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2099589
	speed: 0.1410s/iter; left time: 173.3254s
	iters: 200, epoch: 7 | loss: 0.2184460
	speed: 0.0585s/iter; left time: 66.0462s
	iters: 300, epoch: 7 | loss: 0.2032031
	speed: 0.0580s/iter; left time: 59.7190s
Epoch: 7 cost time: 19.496392011642456
Epoch: 7, Steps: 332 | Train Loss: 0.1943541 Vali Loss: 0.1125104 Test Loss: 0.1026484
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1840592
	speed: 0.1429s/iter; left time: 128.1966s
	iters: 200, epoch: 8 | loss: 0.2017835
	speed: 0.0584s/iter; left time: 46.5683s
	iters: 300, epoch: 8 | loss: 0.1745905
	speed: 0.0585s/iter; left time: 40.8076s
Epoch: 8 cost time: 19.52396297454834
Epoch: 8, Steps: 332 | Train Loss: 0.1939353 Vali Loss: 0.1149304 Test Loss: 0.1057245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1882353
	speed: 0.1419s/iter; left time: 80.1836s
	iters: 200, epoch: 9 | loss: 0.1919771
	speed: 0.0583s/iter; left time: 27.1164s
	iters: 300, epoch: 9 | loss: 0.2034369
	speed: 0.0585s/iter; left time: 21.3371s
Epoch: 9 cost time: 19.558411359786987
Epoch: 9, Steps: 332 | Train Loss: 0.1936127 Vali Loss: 0.1134123 Test Loss: 0.1036874
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1922941
	speed: 0.1427s/iter; left time: 33.2607s
	iters: 200, epoch: 10 | loss: 0.1735471
	speed: 0.0582s/iter; left time: 7.7369s
	iters: 300, epoch: 10 | loss: 0.2198660
	speed: 0.0583s/iter; left time: 1.9245s
Epoch: 10 cost time: 19.525882244110107
Epoch: 10, Steps: 332 | Train Loss: 0.1934892 Vali Loss: 0.1126194 Test Loss: 0.1030597
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3465
test shape: (3465, 12, 170) (3465, 12, 170)
test shape: (3465, 12, 170) (3465, 12, 170)
mse:0.10077567398548126, mae:0.21366310119628906
