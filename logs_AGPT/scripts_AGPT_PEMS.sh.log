Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS03              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS03.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             358                 Dec In:             358                 
  C Out:              358                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15617
val 5135
test 5135
	iters: 100, epoch: 1 | loss: 0.2410136
	speed: 0.3725s/iter; left time: 1784.4531s
	iters: 200, epoch: 1 | loss: 0.1961690
	speed: 0.3693s/iter; left time: 1732.5548s
	iters: 300, epoch: 1 | loss: 0.2548554
	speed: 0.3534s/iter; left time: 1622.5189s
	iters: 400, epoch: 1 | loss: 0.2221420
	speed: 0.3208s/iter; left time: 1440.6285s
Epoch: 1 cost time: 170.4058837890625
Epoch: 1, Steps: 489 | Train Loss: 0.2507309 Vali Loss: 0.1399979 Test Loss: 0.1382285
Validation loss decreased (inf --> 0.139998).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1822216
	speed: 1.1431s/iter; left time: 4917.4208s
	iters: 200, epoch: 2 | loss: 0.2154800
	speed: 0.3505s/iter; left time: 1472.7715s
	iters: 300, epoch: 2 | loss: 0.1995906
	speed: 0.2955s/iter; left time: 1212.2243s
	iters: 400, epoch: 2 | loss: 0.2202242
	speed: 0.3054s/iter; left time: 1222.0463s
Epoch: 2 cost time: 152.46776151657104
Epoch: 2, Steps: 489 | Train Loss: 0.2077242 Vali Loss: 0.1619712 Test Loss: 0.1618009
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1974706
	speed: 1.1745s/iter; left time: 4478.5172s
	iters: 200, epoch: 3 | loss: 0.1860173
	speed: 0.2532s/iter; left time: 940.1372s
	iters: 300, epoch: 3 | loss: 0.2161361
	speed: 0.3501s/iter; left time: 1265.0191s
	iters: 400, epoch: 3 | loss: 0.2048576
	speed: 0.3425s/iter; left time: 1203.1509s
Epoch: 3 cost time: 156.01775407791138
Epoch: 3, Steps: 489 | Train Loss: 0.1975698 Vali Loss: 0.1117890 Test Loss: 0.1131776
Validation loss decreased (0.139998 --> 0.111789).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1924537
	speed: 1.1775s/iter; left time: 3913.8516s
	iters: 200, epoch: 4 | loss: 0.1810834
	speed: 0.3304s/iter; left time: 1065.1247s
	iters: 300, epoch: 4 | loss: 0.1907638
	speed: 0.3440s/iter; left time: 1074.6140s
	iters: 400, epoch: 4 | loss: 0.1884256
	speed: 0.2866s/iter; left time: 866.8005s
Epoch: 4 cost time: 153.4856207370758
Epoch: 4, Steps: 489 | Train Loss: 0.1927155 Vali Loss: 0.0932336 Test Loss: 0.0954658
Validation loss decreased (0.111789 --> 0.093234).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2106988
	speed: 1.1809s/iter; left time: 3347.9811s
	iters: 200, epoch: 5 | loss: 0.2008079
	speed: 0.2822s/iter; left time: 771.9162s
	iters: 300, epoch: 5 | loss: 0.1710262
	speed: 0.3206s/iter; left time: 844.7321s
	iters: 400, epoch: 5 | loss: 0.1846374
	speed: 0.2418s/iter; left time: 612.8853s
Epoch: 5 cost time: 131.04967999458313
Epoch: 5, Steps: 489 | Train Loss: 0.1897999 Vali Loss: 0.0970676 Test Loss: 0.0986280
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1654888
	speed: 1.0315s/iter; left time: 2419.9572s
	iters: 200, epoch: 6 | loss: 0.1922899
	speed: 0.2427s/iter; left time: 545.2123s
	iters: 300, epoch: 6 | loss: 0.1925871
	speed: 0.2628s/iter; left time: 563.8843s
	iters: 400, epoch: 6 | loss: 0.1688269
	speed: 0.2675s/iter; left time: 547.3092s
Epoch: 6 cost time: 117.58548998832703
Epoch: 6, Steps: 489 | Train Loss: 0.1880862 Vali Loss: 0.0897025 Test Loss: 0.0916265
Validation loss decreased (0.093234 --> 0.089703).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1964912
	speed: 0.7816s/iter; left time: 1451.4511s
	iters: 200, epoch: 7 | loss: 0.1977374
	speed: 0.2412s/iter; left time: 423.8130s
	iters: 300, epoch: 7 | loss: 0.1852112
	speed: 0.2278s/iter; left time: 377.4840s
	iters: 400, epoch: 7 | loss: 0.1782118
	speed: 0.2367s/iter; left time: 368.5643s
Epoch: 7 cost time: 112.56725358963013
Epoch: 7, Steps: 489 | Train Loss: 0.1870265 Vali Loss: 0.0886058 Test Loss: 0.0903590
Validation loss decreased (0.089703 --> 0.088606).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2408367
	speed: 0.8095s/iter; left time: 1107.3593s
	iters: 200, epoch: 8 | loss: 0.2037961
	speed: 0.2393s/iter; left time: 303.4351s
	iters: 300, epoch: 8 | loss: 0.2110796
	speed: 0.1827s/iter; left time: 213.3387s
	iters: 400, epoch: 8 | loss: 0.1967881
	speed: 0.1888s/iter; left time: 201.6465s
Epoch: 8 cost time: 104.83537578582764
Epoch: 8, Steps: 489 | Train Loss: 0.1871879 Vali Loss: 0.0910371 Test Loss: 0.0929818
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1498783
	speed: 0.7998s/iter; left time: 703.0120s
	iters: 200, epoch: 9 | loss: 0.1678008
	speed: 0.1600s/iter; left time: 124.6443s
	iters: 300, epoch: 9 | loss: 0.1665897
	speed: 0.1732s/iter; left time: 117.5837s
	iters: 400, epoch: 9 | loss: 0.1852274
	speed: 0.2401s/iter; left time: 138.9955s
Epoch: 9 cost time: 99.2234787940979
Epoch: 9, Steps: 489 | Train Loss: 0.1873531 Vali Loss: 0.0926198 Test Loss: 0.0946303
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1827120
	speed: 0.8886s/iter; left time: 346.5599s
	iters: 200, epoch: 10 | loss: 0.1655590
	speed: 0.1558s/iter; left time: 45.1705s
	iters: 300, epoch: 10 | loss: 0.1942736
	speed: 0.2163s/iter; left time: 41.0948s
	iters: 400, epoch: 10 | loss: 0.2068917
	speed: 0.2889s/iter; left time: 25.9981s
Epoch: 10 cost time: 107.38775563240051
Epoch: 10, Steps: 489 | Train Loss: 0.1861643 Vali Loss: 0.0909664 Test Loss: 0.0929374
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5135
test shape: (5135, 12, 358) (5135, 12, 358)
test shape: (5135, 12, 358) (5135, 12, 358)
mse:0.09039562195539474, mae:0.20706748962402344
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS04              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS04.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             307                 Dec In:             307                 
  C Out:              307                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10088
val 3291
test 3292
	iters: 100, epoch: 1 | loss: 0.2431923
	speed: 0.2832s/iter; left time: 866.8880s
	iters: 200, epoch: 1 | loss: 0.2226894
	speed: 0.2326s/iter; left time: 688.8088s
	iters: 300, epoch: 1 | loss: 0.2545962
	speed: 0.2762s/iter; left time: 790.1343s
Epoch: 1 cost time: 83.57106566429138
Epoch: 1, Steps: 316 | Train Loss: 0.2729750 Vali Loss: 0.3710478 Test Loss: 0.3473413
Validation loss decreased (inf --> 0.371048).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2248006
	speed: 0.4780s/iter; left time: 1312.0012s
	iters: 200, epoch: 2 | loss: 0.2294411
	speed: 0.1378s/iter; left time: 364.5607s
	iters: 300, epoch: 2 | loss: 0.2121712
	speed: 0.1812s/iter; left time: 461.2490s
Epoch: 2 cost time: 49.316245317459106
Epoch: 2, Steps: 316 | Train Loss: 0.2260376 Vali Loss: 0.1383095 Test Loss: 0.1307945
Validation loss decreased (0.371048 --> 0.138309).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1922395
	speed: 0.4985s/iter; left time: 1210.8009s
	iters: 200, epoch: 3 | loss: 0.2160404
	speed: 0.1389s/iter; left time: 323.5954s
	iters: 300, epoch: 3 | loss: 0.1853403
	speed: 0.1279s/iter; left time: 285.0213s
Epoch: 3 cost time: 46.933926820755005
Epoch: 3, Steps: 316 | Train Loss: 0.2087863 Vali Loss: 0.1217951 Test Loss: 0.1167731
Validation loss decreased (0.138309 --> 0.121795).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1764978
	speed: 0.4376s/iter; left time: 924.6260s
	iters: 200, epoch: 4 | loss: 0.1893514
	speed: 0.1801s/iter; left time: 362.5945s
	iters: 300, epoch: 4 | loss: 0.2012251
	speed: 0.1791s/iter; left time: 342.5763s
Epoch: 4 cost time: 57.00699496269226
Epoch: 4, Steps: 316 | Train Loss: 0.2049699 Vali Loss: 0.1185821 Test Loss: 0.1130193
Validation loss decreased (0.121795 --> 0.118582).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1916018
	speed: 0.3821s/iter; left time: 686.5862s
	iters: 200, epoch: 5 | loss: 0.2135909
	speed: 0.1842s/iter; left time: 312.5179s
	iters: 300, epoch: 5 | loss: 0.1970744
	speed: 0.1829s/iter; left time: 292.1641s
Epoch: 5 cost time: 54.38359522819519
Epoch: 5, Steps: 316 | Train Loss: 0.2029615 Vali Loss: 0.1161219 Test Loss: 0.1110636
Validation loss decreased (0.118582 --> 0.116122).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1952419
	speed: 0.3957s/iter; left time: 585.9781s
	iters: 200, epoch: 6 | loss: 0.1921706
	speed: 0.1350s/iter; left time: 186.4510s
	iters: 300, epoch: 6 | loss: 0.2184215
	speed: 0.1697s/iter; left time: 217.3884s
Epoch: 6 cost time: 49.51246380805969
Epoch: 6, Steps: 316 | Train Loss: 0.2019740 Vali Loss: 0.1140397 Test Loss: 0.1087336
Validation loss decreased (0.116122 --> 0.114040).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2068732
	speed: 0.4061s/iter; left time: 473.0996s
	iters: 200, epoch: 7 | loss: 0.1999271
	speed: 0.1845s/iter; left time: 196.5091s
	iters: 300, epoch: 7 | loss: 0.1872067
	speed: 0.1373s/iter; left time: 132.5367s
Epoch: 7 cost time: 53.06172513961792
Epoch: 7, Steps: 316 | Train Loss: 0.2016186 Vali Loss: 0.1159570 Test Loss: 0.1106328
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2017156
	speed: 0.2923s/iter; left time: 248.1922s
	iters: 200, epoch: 8 | loss: 0.2180715
	speed: 0.1943s/iter; left time: 145.5306s
	iters: 300, epoch: 8 | loss: 0.2281486
	speed: 0.2207s/iter; left time: 143.2070s
Epoch: 8 cost time: 56.78113412857056
Epoch: 8, Steps: 316 | Train Loss: 0.2011188 Vali Loss: 0.1165641 Test Loss: 0.1113355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1898648
	speed: 0.4306s/iter; left time: 229.5202s
	iters: 200, epoch: 9 | loss: 0.1802746
	speed: 0.2194s/iter; left time: 95.0128s
	iters: 300, epoch: 9 | loss: 0.2268580
	speed: 0.2184s/iter; left time: 72.7363s
Epoch: 9 cost time: 64.57643127441406
Epoch: 9, Steps: 316 | Train Loss: 0.2009588 Vali Loss: 0.1185488 Test Loss: 0.1130707
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1866792
	speed: 0.4085s/iter; left time: 88.6398s
	iters: 200, epoch: 10 | loss: 0.2218310
	speed: 0.2178s/iter; left time: 25.4828s
	iters: 300, epoch: 10 | loss: 0.2103059
	speed: 0.2174s/iter; left time: 3.6951s
Epoch: 10 cost time: 66.84226322174072
Epoch: 10, Steps: 316 | Train Loss: 0.2007842 Vali Loss: 0.1168146 Test Loss: 0.1115823
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3292
test shape: (3292, 12, 307) (3292, 12, 307)
test shape: (3292, 12, 307) (3292, 12, 307)
mse:0.10879100859165192, mae:0.22391283512115479
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS07              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS07.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             883                 Dec In:             883                 
  C Out:              883                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16827
val 5538
test 5538
	iters: 100, epoch: 1 | loss: 0.2687713
	speed: 0.5179s/iter; left time: 2672.7912s
	iters: 200, epoch: 1 | loss: 0.2418754
	speed: 0.5519s/iter; left time: 2793.2960s
	iters: 300, epoch: 1 | loss: 0.1796077
	speed: 0.5479s/iter; left time: 2718.3480s
	iters: 400, epoch: 1 | loss: 0.2149259
	speed: 0.5249s/iter; left time: 2551.3356s
	iters: 500, epoch: 1 | loss: 0.1928703
	speed: 0.5294s/iter; left time: 2520.6783s
Epoch: 1 cost time: 277.36468744277954
Epoch: 1, Steps: 526 | Train Loss: 0.2509287 Vali Loss: 0.1090066 Test Loss: 0.1111570
Validation loss decreased (inf --> 0.109007).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2156925
	speed: 1.3474s/iter; left time: 6245.2497s
	iters: 200, epoch: 2 | loss: 0.1867502
	speed: 0.4586s/iter; left time: 2079.9739s
	iters: 300, epoch: 2 | loss: 0.1746047
	speed: 0.5562s/iter; left time: 2466.7063s
	iters: 400, epoch: 2 | loss: 0.1948880
	speed: 0.5043s/iter; left time: 2186.1498s
	iters: 500, epoch: 2 | loss: 0.1836227
	speed: 0.5234s/iter; left time: 2216.5864s
Epoch: 2 cost time: 270.6385221481323
Epoch: 2, Steps: 526 | Train Loss: 0.2031027 Vali Loss: 0.0873297 Test Loss: 0.0881985
Validation loss decreased (0.109007 --> 0.087330).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1623894
	speed: 1.4575s/iter; left time: 5988.9776s
	iters: 200, epoch: 3 | loss: 0.1858961
	speed: 0.5557s/iter; left time: 2227.8211s
	iters: 300, epoch: 3 | loss: 0.2016902
	speed: 0.5204s/iter; left time: 2034.0558s
	iters: 400, epoch: 3 | loss: 0.1613850
	speed: 0.5338s/iter; left time: 2033.2310s
	iters: 500, epoch: 3 | loss: 0.1715037
	speed: 0.5684s/iter; left time: 2108.1520s
Epoch: 3 cost time: 285.94453835487366
Epoch: 3, Steps: 526 | Train Loss: 0.1932043 Vali Loss: 0.0869027 Test Loss: 0.0885900
Validation loss decreased (0.087330 --> 0.086903).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1620629
	speed: 1.2027s/iter; left time: 4309.3637s
	iters: 200, epoch: 4 | loss: 0.1845607
	speed: 0.2758s/iter; left time: 960.6629s
	iters: 300, epoch: 4 | loss: 0.1847957
	speed: 0.2749s/iter; left time: 929.9497s
	iters: 400, epoch: 4 | loss: 0.1997191
	speed: 0.2748s/iter; left time: 902.3266s
	iters: 500, epoch: 4 | loss: 0.1464773
	speed: 0.2755s/iter; left time: 876.7606s
Epoch: 4 cost time: 147.9376094341278
Epoch: 4, Steps: 526 | Train Loss: 0.1903790 Vali Loss: 0.0859761 Test Loss: 0.0879198
Validation loss decreased (0.086903 --> 0.085976).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2147566
	speed: 0.7610s/iter; left time: 2326.3678s
	iters: 200, epoch: 5 | loss: 0.1921887
	speed: 0.2755s/iter; left time: 814.5522s
	iters: 300, epoch: 5 | loss: 0.1692157
	speed: 0.2748s/iter; left time: 785.1668s
	iters: 400, epoch: 5 | loss: 0.1859658
	speed: 0.2796s/iter; left time: 770.9860s
	iters: 500, epoch: 5 | loss: 0.2095999
	speed: 0.2779s/iter; left time: 738.2617s
Epoch: 5 cost time: 145.696227312088
Epoch: 5, Steps: 526 | Train Loss: 0.1885274 Vali Loss: 0.0877057 Test Loss: 0.0893458
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1922089
	speed: 0.7655s/iter; left time: 1937.4726s
	iters: 200, epoch: 6 | loss: 0.1854592
	speed: 0.2766s/iter; left time: 672.3645s
	iters: 300, epoch: 6 | loss: 0.1453982
	speed: 0.2754s/iter; left time: 641.9619s
	iters: 400, epoch: 6 | loss: 0.2040458
	speed: 0.2744s/iter; left time: 612.1702s
	iters: 500, epoch: 6 | loss: 0.1917074
	speed: 0.2747s/iter; left time: 585.4341s
Epoch: 6 cost time: 145.04635071754456
Epoch: 6, Steps: 526 | Train Loss: 0.1874923 Vali Loss: 0.0842022 Test Loss: 0.0853484
Validation loss decreased (0.085976 --> 0.084202).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1772740
	speed: 0.7516s/iter; left time: 1506.9529s
	iters: 200, epoch: 7 | loss: 0.1782621
	speed: 0.2751s/iter; left time: 524.0012s
	iters: 300, epoch: 7 | loss: 0.1994679
	speed: 0.2753s/iter; left time: 496.8782s
	iters: 400, epoch: 7 | loss: 0.1858078
	speed: 0.2760s/iter; left time: 470.6298s
	iters: 500, epoch: 7 | loss: 0.1891986
	speed: 0.2750s/iter; left time: 441.4540s
Epoch: 7 cost time: 144.9590563774109
Epoch: 7, Steps: 526 | Train Loss: 0.1869015 Vali Loss: 0.0841552 Test Loss: 0.0858074
Validation loss decreased (0.084202 --> 0.084155).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2026275
	speed: 0.7468s/iter; left time: 1104.5792s
	iters: 200, epoch: 8 | loss: 0.1677720
	speed: 0.2748s/iter; left time: 378.9993s
	iters: 300, epoch: 8 | loss: 0.2143132
	speed: 0.2753s/iter; left time: 352.1618s
	iters: 400, epoch: 8 | loss: 0.1932966
	speed: 0.2754s/iter; left time: 324.7437s
	iters: 500, epoch: 8 | loss: 0.2001934
	speed: 0.2751s/iter; left time: 296.8108s
Epoch: 8 cost time: 144.86734318733215
Epoch: 8, Steps: 526 | Train Loss: 0.1865620 Vali Loss: 0.0850433 Test Loss: 0.0867802
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1569129
	speed: 0.7523s/iter; left time: 716.9512s
	iters: 200, epoch: 9 | loss: 0.2052869
	speed: 0.2765s/iter; left time: 235.8802s
	iters: 300, epoch: 9 | loss: 0.1866856
	speed: 0.2762s/iter; left time: 207.9457s
	iters: 400, epoch: 9 | loss: 0.2032503
	speed: 0.2762s/iter; left time: 180.3284s
	iters: 500, epoch: 9 | loss: 0.2011891
	speed: 0.2772s/iter; left time: 153.2788s
Epoch: 9 cost time: 145.49647998809814
Epoch: 9, Steps: 526 | Train Loss: 0.1863447 Vali Loss: 0.0834315 Test Loss: 0.0851200
Validation loss decreased (0.084155 --> 0.083431).  Saving model ...
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1909337
	speed: 0.7617s/iter; left time: 325.2614s
	iters: 200, epoch: 10 | loss: 0.1979046
	speed: 0.2758s/iter; left time: 90.1990s
	iters: 300, epoch: 10 | loss: 0.1967989
	speed: 0.2764s/iter; left time: 62.7541s
	iters: 400, epoch: 10 | loss: 0.1827991
	speed: 0.2767s/iter; left time: 35.1410s
	iters: 500, epoch: 10 | loss: 0.2109827
	speed: 0.2773s/iter; left time: 7.4868s
Epoch: 10 cost time: 145.47389435768127
Epoch: 10, Steps: 526 | Train Loss: 0.1862669 Vali Loss: 0.0840730 Test Loss: 0.0858436
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5538
test shape: (5538, 12, 883) (5538, 12, 883)
test shape: (5538, 12, 883) (5538, 12, 883)
mse:0.0848744735121727, mae:0.20228715240955353
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS08              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS08.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             170                 Dec In:             170                 
  C Out:              170                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10606
val 3464
test 3465
	iters: 100, epoch: 1 | loss: 0.2707019
	speed: 0.0646s/iter; left time: 208.1732s
	iters: 200, epoch: 1 | loss: 0.2701244
	speed: 0.0589s/iter; left time: 183.7503s
	iters: 300, epoch: 1 | loss: 0.1964667
	speed: 0.0586s/iter; left time: 177.0419s
Epoch: 1 cost time: 20.125021934509277
Epoch: 1, Steps: 332 | Train Loss: 0.2683295 Vali Loss: 0.1923863 Test Loss: 0.1862371
Validation loss decreased (inf --> 0.192386).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1851408
	speed: 0.1394s/iter; left time: 402.8314s
	iters: 200, epoch: 2 | loss: 0.2049273
	speed: 0.0583s/iter; left time: 162.6965s
	iters: 300, epoch: 2 | loss: 0.2137103
	speed: 0.0586s/iter; left time: 157.4733s
Epoch: 2 cost time: 19.71531105041504
Epoch: 2, Steps: 332 | Train Loss: 0.2138822 Vali Loss: 0.1362167 Test Loss: 0.1255488
Validation loss decreased (0.192386 --> 0.136217).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2024714
	speed: 0.1425s/iter; left time: 364.4999s
	iters: 200, epoch: 3 | loss: 0.2390240
	speed: 0.0587s/iter; left time: 144.1824s
	iters: 300, epoch: 3 | loss: 0.1756093
	speed: 0.0584s/iter; left time: 137.5951s
Epoch: 3 cost time: 19.59273934364319
Epoch: 3, Steps: 332 | Train Loss: 0.2024895 Vali Loss: 0.1150774 Test Loss: 0.1039882
Validation loss decreased (0.136217 --> 0.115077).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2157926
	speed: 0.1415s/iter; left time: 314.8219s
	iters: 200, epoch: 4 | loss: 0.2203835
	speed: 0.0585s/iter; left time: 124.3330s
	iters: 300, epoch: 4 | loss: 0.2097564
	speed: 0.0586s/iter; left time: 118.6868s
Epoch: 4 cost time: 19.588785409927368
Epoch: 4, Steps: 332 | Train Loss: 0.1988412 Vali Loss: 0.1117429 Test Loss: 0.1011072
Validation loss decreased (0.115077 --> 0.111743).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2104907
	speed: 0.1430s/iter; left time: 270.6528s
	iters: 200, epoch: 5 | loss: 0.2129013
	speed: 0.0591s/iter; left time: 105.9781s
	iters: 300, epoch: 5 | loss: 0.1923410
	speed: 0.0592s/iter; left time: 100.2141s
Epoch: 5 cost time: 19.841754913330078
Epoch: 5, Steps: 332 | Train Loss: 0.1964199 Vali Loss: 0.1110658 Test Loss: 0.1005016
Validation loss decreased (0.111743 --> 0.111066).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2090088
	speed: 0.1425s/iter; left time: 222.4466s
	iters: 200, epoch: 6 | loss: 0.1858834
	speed: 0.0589s/iter; left time: 86.0526s
	iters: 300, epoch: 6 | loss: 0.1886906
	speed: 0.0588s/iter; left time: 79.9864s
Epoch: 6 cost time: 19.663735151290894
Epoch: 6, Steps: 332 | Train Loss: 0.1952261 Vali Loss: 0.1172616 Test Loss: 0.1080635
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2099589
	speed: 0.1426s/iter; left time: 175.2737s
	iters: 200, epoch: 7 | loss: 0.2184460
	speed: 0.0584s/iter; left time: 65.9018s
	iters: 300, epoch: 7 | loss: 0.2032031
	speed: 0.0584s/iter; left time: 60.1371s
Epoch: 7 cost time: 19.588334321975708
Epoch: 7, Steps: 332 | Train Loss: 0.1943541 Vali Loss: 0.1125104 Test Loss: 0.1026484
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1840592
	speed: 0.1430s/iter; left time: 128.2463s
	iters: 200, epoch: 8 | loss: 0.2017835
	speed: 0.0586s/iter; left time: 46.7221s
	iters: 300, epoch: 8 | loss: 0.1745905
	speed: 0.0585s/iter; left time: 40.8078s
Epoch: 8 cost time: 19.696571826934814
Epoch: 8, Steps: 332 | Train Loss: 0.1939353 Vali Loss: 0.1149304 Test Loss: 0.1057245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1882353
	speed: 0.1458s/iter; left time: 82.3616s
	iters: 200, epoch: 9 | loss: 0.1919771
	speed: 0.0586s/iter; left time: 27.2517s
	iters: 300, epoch: 9 | loss: 0.2034369
	speed: 0.0585s/iter; left time: 21.3349s
Epoch: 9 cost time: 19.791359663009644
Epoch: 9, Steps: 332 | Train Loss: 0.1936127 Vali Loss: 0.1134123 Test Loss: 0.1036874
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1922941
	speed: 0.1436s/iter; left time: 33.4603s
	iters: 200, epoch: 10 | loss: 0.1735471
	speed: 0.0588s/iter; left time: 7.8262s
	iters: 300, epoch: 10 | loss: 0.2198660
	speed: 0.0589s/iter; left time: 1.9426s
Epoch: 10 cost time: 19.7111337184906
Epoch: 10, Steps: 332 | Train Loss: 0.1934892 Vali Loss: 0.1126194 Test Loss: 0.1030597
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3465
test shape: (3465, 12, 170) (3465, 12, 170)
test shape: (3465, 12, 170) (3465, 12, 170)
mse:0.10077567398548126, mae:0.21366310119628906
