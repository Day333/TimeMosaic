Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_96         Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_96_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.3966810
	speed: 0.0261s/iter; left time: 277.8477s
	iters: 200, epoch: 1 | loss: 0.3390217
	speed: 0.0449s/iter; left time: 473.2566s
	iters: 300, epoch: 1 | loss: 0.3364055
	speed: 0.0623s/iter; left time: 651.0239s
	iters: 400, epoch: 1 | loss: 0.3283435
	speed: 0.0709s/iter; left time: 734.3724s
	iters: 500, epoch: 1 | loss: 0.3443033
	speed: 0.0935s/iter; left time: 958.0755s
	iters: 600, epoch: 1 | loss: 0.3761036
	speed: 0.0900s/iter; left time: 913.5244s
	iters: 700, epoch: 1 | loss: 0.3226252
	speed: 0.0947s/iter; left time: 951.7667s
	iters: 800, epoch: 1 | loss: 0.3262598
	speed: 0.0917s/iter; left time: 912.9998s
	iters: 900, epoch: 1 | loss: 0.3417181
	speed: 0.0922s/iter; left time: 908.2240s
	iters: 1000, epoch: 1 | loss: 0.4234422
	speed: 0.0944s/iter; left time: 920.5449s
Epoch: 1 cost time: 82.99392032623291
Epoch: 1, Steps: 1075 | Train Loss: 0.3496315 Vali Loss: 0.4416648 Test Loss: 0.3560081
Validation loss decreased (inf --> 0.441665).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2518544
	speed: 0.6981s/iter; left time: 6685.2034s
	iters: 200, epoch: 2 | loss: 0.2780032
	speed: 0.0945s/iter; left time: 895.8333s
	iters: 300, epoch: 2 | loss: 0.3573280
	speed: 0.0922s/iter; left time: 864.6058s
	iters: 400, epoch: 2 | loss: 0.3709032
	speed: 0.0862s/iter; left time: 799.2857s
	iters: 500, epoch: 2 | loss: 0.3294456
	speed: 0.0942s/iter; left time: 864.7605s
	iters: 600, epoch: 2 | loss: 0.3118449
	speed: 0.0921s/iter; left time: 835.9725s
	iters: 700, epoch: 2 | loss: 0.3799846
	speed: 0.0897s/iter; left time: 805.1282s
	iters: 800, epoch: 2 | loss: 0.2869999
	speed: 0.0938s/iter; left time: 832.9953s
	iters: 900, epoch: 2 | loss: 0.3435432
	speed: 0.0884s/iter; left time: 776.1570s
	iters: 1000, epoch: 2 | loss: 0.2637881
	speed: 0.0867s/iter; left time: 751.8928s
Epoch: 2 cost time: 97.17098641395569
Epoch: 2, Steps: 1075 | Train Loss: 0.3258439 Vali Loss: 0.4452560 Test Loss: 0.3571510
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3208839
	speed: 0.6884s/iter; left time: 5851.8251s
	iters: 200, epoch: 3 | loss: 0.2833636
	speed: 0.0940s/iter; left time: 789.7258s
	iters: 300, epoch: 3 | loss: 0.3327597
	speed: 0.0878s/iter; left time: 728.6857s
	iters: 400, epoch: 3 | loss: 0.2793123
	speed: 0.0911s/iter; left time: 747.0547s
	iters: 500, epoch: 3 | loss: 0.3484043
	speed: 0.0904s/iter; left time: 732.1770s
	iters: 600, epoch: 3 | loss: 0.3133297
	speed: 0.0851s/iter; left time: 681.1312s
	iters: 700, epoch: 3 | loss: 0.2458419
	speed: 0.0935s/iter; left time: 738.7025s
	iters: 800, epoch: 3 | loss: 0.4214879
	speed: 0.0891s/iter; left time: 695.0172s
	iters: 900, epoch: 3 | loss: 0.3008303
	speed: 0.0922s/iter; left time: 709.7679s
	iters: 1000, epoch: 3 | loss: 0.3657859
	speed: 0.0933s/iter; left time: 709.3113s
Epoch: 3 cost time: 97.39502286911011
Epoch: 3, Steps: 1075 | Train Loss: 0.3111710 Vali Loss: 0.4198208 Test Loss: 0.3310600
Validation loss decreased (0.441665 --> 0.419821).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3496503
	speed: 0.6583s/iter; left time: 4888.4830s
	iters: 200, epoch: 4 | loss: 0.3897918
	speed: 0.0823s/iter; left time: 602.8811s
	iters: 300, epoch: 4 | loss: 0.3496860
	speed: 0.0811s/iter; left time: 586.3786s
	iters: 400, epoch: 4 | loss: 0.3159809
	speed: 0.0829s/iter; left time: 590.9202s
	iters: 500, epoch: 4 | loss: 0.3214099
	speed: 0.0812s/iter; left time: 570.5294s
	iters: 600, epoch: 4 | loss: 0.2993087
	speed: 0.0824s/iter; left time: 570.8023s
	iters: 700, epoch: 4 | loss: 0.3454137
	speed: 0.0811s/iter; left time: 553.9251s
	iters: 800, epoch: 4 | loss: 0.2835697
	speed: 0.0826s/iter; left time: 555.8805s
	iters: 900, epoch: 4 | loss: 0.3330245
	speed: 0.0828s/iter; left time: 548.7236s
	iters: 1000, epoch: 4 | loss: 0.3083572
	speed: 0.0831s/iter; left time: 542.1334s
Epoch: 4 cost time: 88.76012659072876
Epoch: 4, Steps: 1075 | Train Loss: 0.3040634 Vali Loss: 0.4136503 Test Loss: 0.3272433
Validation loss decreased (0.419821 --> 0.413650).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2483498
	speed: 0.6355s/iter; left time: 4036.1511s
	iters: 200, epoch: 5 | loss: 0.3051391
	speed: 0.0829s/iter; left time: 518.3876s
	iters: 300, epoch: 5 | loss: 0.2629595
	speed: 0.0831s/iter; left time: 511.0092s
	iters: 400, epoch: 5 | loss: 0.2881477
	speed: 0.0813s/iter; left time: 492.0315s
	iters: 500, epoch: 5 | loss: 0.3827766
	speed: 0.0811s/iter; left time: 482.7877s
	iters: 600, epoch: 5 | loss: 0.2320162
	speed: 0.0776s/iter; left time: 453.9734s
	iters: 700, epoch: 5 | loss: 0.3523086
	speed: 0.0800s/iter; left time: 460.0790s
	iters: 800, epoch: 5 | loss: 0.3209051
	speed: 0.0804s/iter; left time: 454.0841s
	iters: 900, epoch: 5 | loss: 0.2443499
	speed: 0.0808s/iter; left time: 448.3278s
	iters: 1000, epoch: 5 | loss: 0.2978060
	speed: 0.0798s/iter; left time: 434.8061s
Epoch: 5 cost time: 87.1978075504303
Epoch: 5, Steps: 1075 | Train Loss: 0.3002098 Vali Loss: 0.4120160 Test Loss: 0.3245672
Validation loss decreased (0.413650 --> 0.412016).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3110267
	speed: 0.6276s/iter; left time: 3311.0614s
	iters: 200, epoch: 6 | loss: 0.2956408
	speed: 0.0831s/iter; left time: 430.1267s
	iters: 300, epoch: 6 | loss: 0.3060493
	speed: 0.0830s/iter; left time: 421.1392s
	iters: 400, epoch: 6 | loss: 0.2521870
	speed: 0.0825s/iter; left time: 410.6390s
	iters: 500, epoch: 6 | loss: 0.2984923
	speed: 0.0809s/iter; left time: 394.3176s
	iters: 600, epoch: 6 | loss: 0.3312888
	speed: 0.0805s/iter; left time: 384.5427s
	iters: 700, epoch: 6 | loss: 0.3282605
	speed: 0.0785s/iter; left time: 366.8792s
	iters: 800, epoch: 6 | loss: 0.2883643
	speed: 0.0679s/iter; left time: 310.7079s
	iters: 900, epoch: 6 | loss: 0.3133087
	speed: 0.0712s/iter; left time: 318.4885s
	iters: 1000, epoch: 6 | loss: 0.3181188
	speed: 0.0713s/iter; left time: 312.1817s
Epoch: 6 cost time: 83.77653789520264
Epoch: 6, Steps: 1075 | Train Loss: 0.2986801 Vali Loss: 0.4109578 Test Loss: 0.3244792
Validation loss decreased (0.412016 --> 0.410958).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2671781
	speed: 0.4890s/iter; left time: 2054.4855s
	iters: 200, epoch: 7 | loss: 0.2572559
	speed: 0.0598s/iter; left time: 245.3848s
	iters: 300, epoch: 7 | loss: 0.3675774
	speed: 0.0587s/iter; left time: 234.7962s
	iters: 400, epoch: 7 | loss: 0.2425196
	speed: 0.0603s/iter; left time: 235.1375s
	iters: 500, epoch: 7 | loss: 0.2630443
	speed: 0.0628s/iter; left time: 238.5559s
	iters: 600, epoch: 7 | loss: 0.3764382
	speed: 0.0572s/iter; left time: 211.7323s
	iters: 700, epoch: 7 | loss: 0.3040854
	speed: 0.0471s/iter; left time: 169.5730s
	iters: 800, epoch: 7 | loss: 0.2334325
	speed: 0.0459s/iter; left time: 160.7900s
	iters: 900, epoch: 7 | loss: 0.2775450
	speed: 0.0478s/iter; left time: 162.5209s
	iters: 1000, epoch: 7 | loss: 0.3470244
	speed: 0.0479s/iter; left time: 158.1519s
Epoch: 7 cost time: 60.50514316558838
Epoch: 7, Steps: 1075 | Train Loss: 0.2976801 Vali Loss: 0.4145033 Test Loss: 0.3246432
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3156922
	speed: 0.4524s/iter; left time: 1414.2938s
	iters: 200, epoch: 8 | loss: 0.2754513
	speed: 0.0498s/iter; left time: 150.6444s
	iters: 300, epoch: 8 | loss: 0.3504154
	speed: 0.0518s/iter; left time: 151.4611s
	iters: 400, epoch: 8 | loss: 0.2775197
	speed: 0.0539s/iter; left time: 152.2359s
	iters: 500, epoch: 8 | loss: 0.3038251
	speed: 0.0537s/iter; left time: 146.5079s
	iters: 600, epoch: 8 | loss: 0.3712381
	speed: 0.0522s/iter; left time: 136.9931s
	iters: 700, epoch: 8 | loss: 0.3347474
	speed: 0.0467s/iter; left time: 117.9837s
	iters: 800, epoch: 8 | loss: 0.2899098
	speed: 0.0481s/iter; left time: 116.6224s
	iters: 900, epoch: 8 | loss: 0.2987393
	speed: 0.0516s/iter; left time: 120.0736s
	iters: 1000, epoch: 8 | loss: 0.2535894
	speed: 0.0542s/iter; left time: 120.5645s
Epoch: 8 cost time: 55.08802366256714
Epoch: 8, Steps: 1075 | Train Loss: 0.2969676 Vali Loss: 0.4091184 Test Loss: 0.3236816
Validation loss decreased (0.410958 --> 0.409118).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2722253
	speed: 0.3310s/iter; left time: 678.9182s
	iters: 200, epoch: 9 | loss: 0.3603943
	speed: 0.0462s/iter; left time: 90.1808s
	iters: 300, epoch: 9 | loss: 0.2993728
	speed: 0.0426s/iter; left time: 78.7665s
	iters: 400, epoch: 9 | loss: 0.2567928
	speed: 0.0477s/iter; left time: 83.4735s
	iters: 500, epoch: 9 | loss: 0.2440965
	speed: 0.0432s/iter; left time: 71.3201s
	iters: 600, epoch: 9 | loss: 0.3039851
	speed: 0.0414s/iter; left time: 64.2650s
	iters: 700, epoch: 9 | loss: 0.3481205
	speed: 0.0475s/iter; left time: 68.9574s
	iters: 800, epoch: 9 | loss: 0.2920127
	speed: 0.0451s/iter; left time: 60.9579s
	iters: 900, epoch: 9 | loss: 0.2801326
	speed: 0.0499s/iter; left time: 62.4370s
	iters: 1000, epoch: 9 | loss: 0.2683901
	speed: 0.0640s/iter; left time: 73.6744s
Epoch: 9 cost time: 52.91745471954346
Epoch: 9, Steps: 1075 | Train Loss: 0.2970286 Vali Loss: 0.4086368 Test Loss: 0.3227916
Validation loss decreased (0.409118 --> 0.408637).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2602858
	speed: 0.5354s/iter; left time: 522.5482s
	iters: 200, epoch: 10 | loss: 0.2670753
	speed: 0.0734s/iter; left time: 64.2559s
	iters: 300, epoch: 10 | loss: 0.3328178
	speed: 0.0826s/iter; left time: 64.1218s
	iters: 400, epoch: 10 | loss: 0.3354078
	speed: 0.0826s/iter; left time: 55.8454s
	iters: 500, epoch: 10 | loss: 0.3034244
	speed: 0.0822s/iter; left time: 47.3751s
	iters: 600, epoch: 10 | loss: 0.2898532
	speed: 0.0832s/iter; left time: 39.5896s
	iters: 700, epoch: 10 | loss: 0.2609306
	speed: 0.0826s/iter; left time: 31.0674s
	iters: 800, epoch: 10 | loss: 0.3187770
	speed: 0.0830s/iter; left time: 22.9112s
	iters: 900, epoch: 10 | loss: 0.2842723
	speed: 0.0830s/iter; left time: 14.6025s
	iters: 1000, epoch: 10 | loss: 0.3747277
	speed: 0.0830s/iter; left time: 6.3088s
Epoch: 10 cost time: 87.04437708854675
Epoch: 10, Steps: 1075 | Train Loss: 0.2966206 Vali Loss: 0.4100335 Test Loss: 0.3236328
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_ETTm1_96_96_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.3234541714191437, mae:0.363944947719574
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_192        Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_192_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.4041884
	speed: 0.2447s/iter; left time: 631.5492s
	iters: 200, epoch: 1 | loss: 0.3630421
	speed: 0.2525s/iter; left time: 626.3394s
Epoch: 1 cost time: 67.36255073547363
Epoch: 1, Steps: 268 | Train Loss: 0.3842866 Vali Loss: 0.5392883 Test Loss: 0.3787265
Validation loss decreased (inf --> 0.539288).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3216705
	speed: 0.8034s/iter; left time: 1858.2071s
	iters: 200, epoch: 2 | loss: 0.3726090
	speed: 0.2499s/iter; left time: 553.1364s
Epoch: 2 cost time: 66.80589771270752
Epoch: 2, Steps: 268 | Train Loss: 0.3606025 Vali Loss: 0.5479944 Test Loss: 0.3789908
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3859929
	speed: 0.6574s/iter; left time: 1344.4434s
	iters: 200, epoch: 3 | loss: 0.3414598
	speed: 0.2699s/iter; left time: 524.9180s
Epoch: 3 cost time: 70.96494030952454
Epoch: 3, Steps: 268 | Train Loss: 0.3505619 Vali Loss: 0.5351341 Test Loss: 0.3731770
Validation loss decreased (0.539288 --> 0.535134).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3480902
	speed: 0.6334s/iter; left time: 1125.5765s
	iters: 200, epoch: 4 | loss: 0.3092310
	speed: 0.2390s/iter; left time: 400.8838s
Epoch: 4 cost time: 62.8804292678833
Epoch: 4, Steps: 268 | Train Loss: 0.3454294 Vali Loss: 0.5314435 Test Loss: 0.3718888
Validation loss decreased (0.535134 --> 0.531444).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3336011
	speed: 0.8142s/iter; left time: 1228.6446s
	iters: 200, epoch: 5 | loss: 0.3087135
	speed: 0.2520s/iter; left time: 355.0703s
Epoch: 5 cost time: 67.15502524375916
Epoch: 5, Steps: 268 | Train Loss: 0.3425813 Vali Loss: 0.5290318 Test Loss: 0.3700501
Validation loss decreased (0.531444 --> 0.529032).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3250423
	speed: 0.6748s/iter; left time: 837.4055s
	iters: 200, epoch: 6 | loss: 0.3626738
	speed: 0.2426s/iter; left time: 276.8603s
Epoch: 6 cost time: 65.13011074066162
Epoch: 6, Steps: 268 | Train Loss: 0.3410048 Vali Loss: 0.5321048 Test Loss: 0.3706544
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3295347
	speed: 0.7798s/iter; left time: 758.7119s
	iters: 200, epoch: 7 | loss: 0.3592676
	speed: 0.2467s/iter; left time: 215.3393s
Epoch: 7 cost time: 66.11223673820496
Epoch: 7, Steps: 268 | Train Loss: 0.3403205 Vali Loss: 0.5322818 Test Loss: 0.3693386
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3680574
	speed: 0.6424s/iter; left time: 452.9095s
	iters: 200, epoch: 8 | loss: 0.3285458
	speed: 0.2402s/iter; left time: 145.3004s
Epoch: 8 cost time: 65.16010737419128
Epoch: 8, Steps: 268 | Train Loss: 0.3399562 Vali Loss: 0.5323526 Test Loss: 0.3685999
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_192_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.3706413507461548, mae:0.3886215388774872
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_336        Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_336_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4394893
	speed: 0.1116s/iter; left time: 286.7964s
	iters: 200, epoch: 1 | loss: 0.4213192
	speed: 0.1048s/iter; left time: 259.0382s
Epoch: 1 cost time: 28.61935806274414
Epoch: 1, Steps: 267 | Train Loss: 0.4421851 Vali Loss: 0.7106085 Test Loss: 0.4327690
Validation loss decreased (inf --> 0.710609).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4130283
	speed: 0.5159s/iter; left time: 1188.6712s
	iters: 200, epoch: 2 | loss: 0.4009879
	speed: 0.1149s/iter; left time: 253.2309s
Epoch: 2 cost time: 33.64780592918396
Epoch: 2, Steps: 267 | Train Loss: 0.4194303 Vali Loss: 0.6789536 Test Loss: 0.4115412
Validation loss decreased (0.710609 --> 0.678954).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4157345
	speed: 0.3709s/iter; left time: 755.6174s
	iters: 200, epoch: 3 | loss: 0.4310833
	speed: 0.1230s/iter; left time: 238.2711s
Epoch: 3 cost time: 33.05576705932617
Epoch: 3, Steps: 267 | Train Loss: 0.4111624 Vali Loss: 0.6833942 Test Loss: 0.4057148
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4375414
	speed: 0.4875s/iter; left time: 862.8299s
	iters: 200, epoch: 4 | loss: 0.3779261
	speed: 0.1286s/iter; left time: 214.7519s
Epoch: 4 cost time: 35.85379695892334
Epoch: 4, Steps: 267 | Train Loss: 0.4074921 Vali Loss: 0.6828938 Test Loss: 0.4045461
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4521350
	speed: 0.4204s/iter; left time: 631.8766s
	iters: 200, epoch: 5 | loss: 0.4027671
	speed: 0.1297s/iter; left time: 181.9261s
Epoch: 5 cost time: 34.71493339538574
Epoch: 5, Steps: 267 | Train Loss: 0.4055280 Vali Loss: 0.6800079 Test Loss: 0.4053126
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_336_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.41094252467155457, mae:0.41323402523994446
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTm1_96_720        Model:              AGPT                

[1mData Loader[0m
  Data:               ETTm1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTm1_96_720_AGPT_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5144638
	speed: 0.2247s/iter; left time: 570.8974s
	iters: 200, epoch: 1 | loss: 0.4778976
	speed: 0.2266s/iter; left time: 553.2254s
Epoch: 1 cost time: 60.270469665527344
Epoch: 1, Steps: 264 | Train Loss: 0.5019492 Vali Loss: 0.9981534 Test Loss: 0.4767197
Validation loss decreased (inf --> 0.998153).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4890326
	speed: 0.7228s/iter; left time: 1645.8544s
	iters: 200, epoch: 2 | loss: 0.4477094
	speed: 0.2471s/iter; left time: 538.0054s
Epoch: 2 cost time: 66.38144278526306
Epoch: 2, Steps: 264 | Train Loss: 0.4797218 Vali Loss: 0.9977712 Test Loss: 0.4684337
Validation loss decreased (0.998153 --> 0.997771).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5141789
	speed: 0.6266s/iter; left time: 1261.2723s
	iters: 200, epoch: 3 | loss: 0.4085638
	speed: 0.2457s/iter; left time: 470.0799s
Epoch: 3 cost time: 65.12381172180176
Epoch: 3, Steps: 264 | Train Loss: 0.4685403 Vali Loss: 0.9832467 Test Loss: 0.4673527
Validation loss decreased (0.997771 --> 0.983247).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4705906
	speed: 0.6399s/iter; left time: 1119.2725s
	iters: 200, epoch: 4 | loss: 0.4953117
	speed: 0.2461s/iter; left time: 405.8299s
Epoch: 4 cost time: 65.49683594703674
Epoch: 4, Steps: 264 | Train Loss: 0.4625732 Vali Loss: 0.9845593 Test Loss: 0.4667211
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4238991
	speed: 0.6188s/iter; left time: 918.9505s
	iters: 200, epoch: 5 | loss: 0.4571370
	speed: 0.2456s/iter; left time: 340.1903s
Epoch: 5 cost time: 64.90648174285889
Epoch: 5, Steps: 264 | Train Loss: 0.4592278 Vali Loss: 0.9810365 Test Loss: 0.4610944
Validation loss decreased (0.983247 --> 0.981036).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4490005
	speed: 0.6163s/iter; left time: 752.4979s
	iters: 200, epoch: 6 | loss: 0.4389026
	speed: 0.2472s/iter; left time: 277.0717s
Epoch: 6 cost time: 65.10389447212219
Epoch: 6, Steps: 264 | Train Loss: 0.4571658 Vali Loss: 0.9768013 Test Loss: 0.4611340
Validation loss decreased (0.981036 --> 0.976801).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4564357
	speed: 0.6163s/iter; left time: 589.8399s
	iters: 200, epoch: 7 | loss: 0.4467731
	speed: 0.2436s/iter; left time: 208.7369s
Epoch: 7 cost time: 64.44980049133301
Epoch: 7, Steps: 264 | Train Loss: 0.4563873 Vali Loss: 0.9790450 Test Loss: 0.4620609
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4642271
	speed: 0.6227s/iter; left time: 431.5339s
	iters: 200, epoch: 8 | loss: 0.4658734
	speed: 0.2443s/iter; left time: 144.8938s
Epoch: 8 cost time: 64.83758997917175
Epoch: 8, Steps: 264 | Train Loss: 0.4557789 Vali Loss: 0.9796900 Test Loss: 0.4610670
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.4560997
	speed: 0.5967s/iter; left time: 255.9908s
	iters: 200, epoch: 9 | loss: 0.4354556
	speed: 0.2323s/iter; left time: 76.4110s
Epoch: 9 cost time: 61.22866702079773
Epoch: 9, Steps: 264 | Train Loss: 0.4556304 Vali Loss: 0.9773824 Test Loss: 0.4605034
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_ETTm1_96_720_AGPT_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.4600889980792999, mae:0.44536665081977844
