Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS03              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS03.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             358                 Dec In:             358                 
  C Out:              358                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15617
val 5135
test 5135
	iters: 100, epoch: 1 | loss: 0.2410136
	speed: 0.3527s/iter; left time: 1690.0127s
	iters: 200, epoch: 1 | loss: 0.1961690
	speed: 0.3506s/iter; left time: 1644.5383s
	iters: 300, epoch: 1 | loss: 0.2548554
	speed: 0.3201s/iter; left time: 1469.7145s
	iters: 400, epoch: 1 | loss: 0.2221420
	speed: 0.3198s/iter; left time: 1436.4254s
Epoch: 1 cost time: 165.20350408554077
Epoch: 1, Steps: 489 | Train Loss: 0.2507309 Vali Loss: 0.1399979 Test Loss: 0.1382285
Validation loss decreased (inf --> 0.139998).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1822216
	speed: 1.1527s/iter; left time: 4959.0894s
	iters: 200, epoch: 2 | loss: 0.2154800
	speed: 0.3466s/iter; left time: 1456.4949s
	iters: 300, epoch: 2 | loss: 0.1995906
	speed: 0.3411s/iter; left time: 1399.0176s
	iters: 400, epoch: 2 | loss: 0.2202242
	speed: 0.3293s/iter; left time: 1318.0167s
Epoch: 2 cost time: 160.20552968978882
Epoch: 2, Steps: 489 | Train Loss: 0.2077242 Vali Loss: 0.1619712 Test Loss: 0.1618009
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1974706
	speed: 1.0777s/iter; left time: 4109.3112s
	iters: 200, epoch: 3 | loss: 0.1860173
	speed: 0.2539s/iter; left time: 942.8331s
	iters: 300, epoch: 3 | loss: 0.2161361
	speed: 0.2712s/iter; left time: 979.8415s
	iters: 400, epoch: 3 | loss: 0.2048576
	speed: 0.2920s/iter; left time: 1025.7095s
Epoch: 3 cost time: 138.4274024963379
Epoch: 3, Steps: 489 | Train Loss: 0.1975698 Vali Loss: 0.1117890 Test Loss: 0.1131776
Validation loss decreased (0.139998 --> 0.111789).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1924537
	speed: 1.1148s/iter; left time: 3705.6371s
	iters: 200, epoch: 4 | loss: 0.1810834
	speed: 0.3450s/iter; left time: 1112.2671s
	iters: 300, epoch: 4 | loss: 0.1907638
	speed: 0.3194s/iter; left time: 997.7854s
	iters: 400, epoch: 4 | loss: 0.1884256
	speed: 0.3265s/iter; left time: 987.3652s
Epoch: 4 cost time: 164.17016696929932
Epoch: 4, Steps: 489 | Train Loss: 0.1927155 Vali Loss: 0.0932336 Test Loss: 0.0954658
Validation loss decreased (0.111789 --> 0.093234).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2106988
	speed: 1.1510s/iter; left time: 3263.2024s
	iters: 200, epoch: 5 | loss: 0.2008079
	speed: 0.3173s/iter; left time: 867.8670s
	iters: 300, epoch: 5 | loss: 0.1710262
	speed: 0.3211s/iter; left time: 846.1051s
	iters: 400, epoch: 5 | loss: 0.1846374
	speed: 0.2786s/iter; left time: 706.2975s
Epoch: 5 cost time: 148.25665855407715
Epoch: 5, Steps: 489 | Train Loss: 0.1897999 Vali Loss: 0.0970676 Test Loss: 0.0986280
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1654888
	speed: 1.0289s/iter; left time: 2413.6985s
	iters: 200, epoch: 6 | loss: 0.1922899
	speed: 0.2752s/iter; left time: 618.1665s
	iters: 300, epoch: 6 | loss: 0.1925871
	speed: 0.3126s/iter; left time: 670.8237s
	iters: 400, epoch: 6 | loss: 0.1688269
	speed: 0.3118s/iter; left time: 637.9061s
Epoch: 6 cost time: 146.29390382766724
Epoch: 6, Steps: 489 | Train Loss: 0.1880862 Vali Loss: 0.0897025 Test Loss: 0.0916265
Validation loss decreased (0.093234 --> 0.089703).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1964912
	speed: 1.1274s/iter; left time: 2093.4954s
	iters: 200, epoch: 7 | loss: 0.1977374
	speed: 0.3388s/iter; left time: 595.3174s
	iters: 300, epoch: 7 | loss: 0.1852112
	speed: 0.3317s/iter; left time: 549.6868s
	iters: 400, epoch: 7 | loss: 0.1782118
	speed: 0.3204s/iter; left time: 498.8106s
Epoch: 7 cost time: 161.25451231002808
Epoch: 7, Steps: 489 | Train Loss: 0.1870265 Vali Loss: 0.0886058 Test Loss: 0.0903590
Validation loss decreased (0.089703 --> 0.088606).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2408367
	speed: 1.0545s/iter; left time: 1442.5707s
	iters: 200, epoch: 8 | loss: 0.2037961
	speed: 0.3171s/iter; left time: 402.0311s
	iters: 300, epoch: 8 | loss: 0.2110796
	speed: 0.3103s/iter; left time: 362.4561s
	iters: 400, epoch: 8 | loss: 0.1967881
	speed: 0.3339s/iter; left time: 356.5640s
Epoch: 8 cost time: 153.52536344528198
Epoch: 8, Steps: 489 | Train Loss: 0.1871879 Vali Loss: 0.0910371 Test Loss: 0.0929818
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1498783
	speed: 1.0864s/iter; left time: 954.9285s
	iters: 200, epoch: 9 | loss: 0.1678008
	speed: 0.2805s/iter; left time: 218.5244s
	iters: 300, epoch: 9 | loss: 0.1665897
	speed: 0.3192s/iter; left time: 216.7574s
	iters: 400, epoch: 9 | loss: 0.1852274
	speed: 0.3508s/iter; left time: 203.1198s
Epoch: 9 cost time: 155.225013256073
Epoch: 9, Steps: 489 | Train Loss: 0.1873531 Vali Loss: 0.0926198 Test Loss: 0.0946303
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1827120
	speed: 1.1770s/iter; left time: 459.0245s
	iters: 200, epoch: 10 | loss: 0.1655590
	speed: 0.3034s/iter; left time: 87.9901s
	iters: 300, epoch: 10 | loss: 0.1942736
	speed: 0.2734s/iter; left time: 51.9383s
	iters: 400, epoch: 10 | loss: 0.2068917
	speed: 0.2948s/iter; left time: 26.5279s
Epoch: 10 cost time: 147.64373683929443
Epoch: 10, Steps: 489 | Train Loss: 0.1861643 Vali Loss: 0.0909664 Test Loss: 0.0929374
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS03_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5135
test shape: (5135, 12, 358) (5135, 12, 358)
test shape: (5135, 12, 358) (5135, 12, 358)
mse:0.09039562195539474, mae:0.20706748962402344
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS04              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS04.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             307                 Dec In:             307                 
  C Out:              307                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10088
val 3291
test 3292
	iters: 100, epoch: 1 | loss: 0.2431923
	speed: 0.3128s/iter; left time: 957.5566s
	iters: 200, epoch: 1 | loss: 0.2226894
	speed: 0.2785s/iter; left time: 824.6568s
	iters: 300, epoch: 1 | loss: 0.2545962
	speed: 0.2403s/iter; left time: 687.3957s
Epoch: 1 cost time: 87.13021492958069
Epoch: 1, Steps: 316 | Train Loss: 0.2729750 Vali Loss: 0.3710478 Test Loss: 0.3473413
Validation loss decreased (inf --> 0.371048).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2248006
	speed: 0.5798s/iter; left time: 1591.6799s
	iters: 200, epoch: 2 | loss: 0.2294411
	speed: 0.2606s/iter; left time: 689.1876s
	iters: 300, epoch: 2 | loss: 0.2121712
	speed: 0.2757s/iter; left time: 701.6633s
Epoch: 2 cost time: 84.89415240287781
Epoch: 2, Steps: 316 | Train Loss: 0.2260376 Vali Loss: 0.1383095 Test Loss: 0.1307945
Validation loss decreased (0.371048 --> 0.138309).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1922395
	speed: 0.6252s/iter; left time: 1518.6300s
	iters: 200, epoch: 3 | loss: 0.2160404
	speed: 0.2786s/iter; left time: 648.7584s
	iters: 300, epoch: 3 | loss: 0.1853403
	speed: 0.2663s/iter; left time: 593.4785s
Epoch: 3 cost time: 86.27835035324097
Epoch: 3, Steps: 316 | Train Loss: 0.2087863 Vali Loss: 0.1217951 Test Loss: 0.1167731
Validation loss decreased (0.138309 --> 0.121795).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1764978
	speed: 0.5861s/iter; left time: 1238.4617s
	iters: 200, epoch: 4 | loss: 0.1893514
	speed: 0.2798s/iter; left time: 563.2862s
	iters: 300, epoch: 4 | loss: 0.2012251
	speed: 0.2744s/iter; left time: 524.9382s
Epoch: 4 cost time: 85.20040082931519
Epoch: 4, Steps: 316 | Train Loss: 0.2049699 Vali Loss: 0.1185821 Test Loss: 0.1130193
Validation loss decreased (0.121795 --> 0.118582).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.1916018
	speed: 0.6075s/iter; left time: 1091.5928s
	iters: 200, epoch: 5 | loss: 0.2135909
	speed: 0.3055s/iter; left time: 518.3719s
	iters: 300, epoch: 5 | loss: 0.1970744
	speed: 0.3344s/iter; left time: 534.0108s
Epoch: 5 cost time: 96.01219320297241
Epoch: 5, Steps: 316 | Train Loss: 0.2029615 Vali Loss: 0.1161219 Test Loss: 0.1110636
Validation loss decreased (0.118582 --> 0.116122).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1952419
	speed: 0.6995s/iter; left time: 1036.0246s
	iters: 200, epoch: 6 | loss: 0.1921706
	speed: 0.3000s/iter; left time: 414.3682s
	iters: 300, epoch: 6 | loss: 0.2184215
	speed: 0.2998s/iter; left time: 384.0777s
Epoch: 6 cost time: 95.03107237815857
Epoch: 6, Steps: 316 | Train Loss: 0.2019740 Vali Loss: 0.1140397 Test Loss: 0.1087336
Validation loss decreased (0.116122 --> 0.114040).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2068732
	speed: 0.6527s/iter; left time: 760.4470s
	iters: 200, epoch: 7 | loss: 0.1999271
	speed: 0.3440s/iter; left time: 366.4041s
	iters: 300, epoch: 7 | loss: 0.1872067
	speed: 0.3472s/iter; left time: 335.0136s
Epoch: 7 cost time: 102.19361138343811
Epoch: 7, Steps: 316 | Train Loss: 0.2016186 Vali Loss: 0.1159570 Test Loss: 0.1106328
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2017156
	speed: 0.6929s/iter; left time: 588.2932s
	iters: 200, epoch: 8 | loss: 0.2180715
	speed: 0.2777s/iter; left time: 207.9780s
	iters: 300, epoch: 8 | loss: 0.2281486
	speed: 0.2782s/iter; left time: 180.5604s
Epoch: 8 cost time: 90.84016394615173
Epoch: 8, Steps: 316 | Train Loss: 0.2011188 Vali Loss: 0.1165641 Test Loss: 0.1113355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1898648
	speed: 0.6377s/iter; left time: 339.8888s
	iters: 200, epoch: 9 | loss: 0.1802746
	speed: 0.3063s/iter; left time: 132.6160s
	iters: 300, epoch: 9 | loss: 0.2268580
	speed: 0.3179s/iter; left time: 105.8720s
Epoch: 9 cost time: 97.12029838562012
Epoch: 9, Steps: 316 | Train Loss: 0.2009588 Vali Loss: 0.1185488 Test Loss: 0.1130707
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1866792
	speed: 0.6449s/iter; left time: 139.9386s
	iters: 200, epoch: 10 | loss: 0.2218310
	speed: 0.2713s/iter; left time: 31.7418s
	iters: 300, epoch: 10 | loss: 0.2103059
	speed: 0.2795s/iter; left time: 4.7515s
Epoch: 10 cost time: 88.43418908119202
Epoch: 10, Steps: 316 | Train Loss: 0.2007842 Vali Loss: 0.1168146 Test Loss: 0.1115823
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS04_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3292
test shape: (3292, 12, 307) (3292, 12, 307)
test shape: (3292, 12, 307) (3292, 12, 307)
mse:0.10879100859165192, mae:0.22391283512115479
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS07              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS07.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             883                 Dec In:             883                 
  C Out:              883                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 16827
val 5538
test 5538
	iters: 100, epoch: 1 | loss: 0.2687713
	speed: 0.7309s/iter; left time: 3772.4007s
	iters: 200, epoch: 1 | loss: 0.2418754
	speed: 0.6281s/iter; left time: 3179.0394s
	iters: 300, epoch: 1 | loss: 0.1796077
	speed: 0.6696s/iter; left time: 3322.0798s
	iters: 400, epoch: 1 | loss: 0.2149259
	speed: 0.6861s/iter; left time: 3335.2418s
	iters: 500, epoch: 1 | loss: 0.1928703
	speed: 0.6369s/iter; left time: 3032.1429s
Epoch: 1 cost time: 350.55551075935364
Epoch: 1, Steps: 526 | Train Loss: 0.2509287 Vali Loss: 0.1090066 Test Loss: 0.1111570
Validation loss decreased (inf --> 0.109007).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.2156925
	speed: 1.4999s/iter; left time: 6951.9475s
	iters: 200, epoch: 2 | loss: 0.1867502
	speed: 0.4624s/iter; left time: 2097.0830s
	iters: 300, epoch: 2 | loss: 0.1746047
	speed: 0.4630s/iter; left time: 2053.3227s
	iters: 400, epoch: 2 | loss: 0.1948880
	speed: 0.5160s/iter; left time: 2236.7909s
	iters: 500, epoch: 2 | loss: 0.1836227
	speed: 0.5146s/iter; left time: 2179.3120s
Epoch: 2 cost time: 262.91268491744995
Epoch: 2, Steps: 526 | Train Loss: 0.2031027 Vali Loss: 0.0873297 Test Loss: 0.0881985
Validation loss decreased (0.109007 --> 0.087330).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.1623894
	speed: 1.4550s/iter; left time: 5978.6222s
	iters: 200, epoch: 3 | loss: 0.1858961
	speed: 0.5438s/iter; left time: 2180.2694s
	iters: 300, epoch: 3 | loss: 0.2016902
	speed: 0.5020s/iter; left time: 1962.3444s
	iters: 400, epoch: 3 | loss: 0.1613850
	speed: 0.4337s/iter; left time: 1651.9620s
	iters: 500, epoch: 3 | loss: 0.1715037
	speed: 0.4657s/iter; left time: 1727.2726s
Epoch: 3 cost time: 262.07126212120056
Epoch: 3, Steps: 526 | Train Loss: 0.1932043 Vali Loss: 0.0869027 Test Loss: 0.0885900
Validation loss decreased (0.087330 --> 0.086903).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.1620629
	speed: 1.4520s/iter; left time: 5202.4563s
	iters: 200, epoch: 4 | loss: 0.1845607
	speed: 0.5415s/iter; left time: 1886.0430s
	iters: 300, epoch: 4 | loss: 0.1847957
	speed: 0.5286s/iter; left time: 1788.1727s
	iters: 400, epoch: 4 | loss: 0.1997191
	speed: 0.5096s/iter; left time: 1673.1487s
	iters: 500, epoch: 4 | loss: 0.1464773
	speed: 0.4454s/iter; left time: 1417.7720s
Epoch: 4 cost time: 268.14125514030457
Epoch: 4, Steps: 526 | Train Loss: 0.1903790 Vali Loss: 0.0859761 Test Loss: 0.0879198
Validation loss decreased (0.086903 --> 0.085976).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2147566
	speed: 1.3469s/iter; left time: 4117.5843s
	iters: 200, epoch: 5 | loss: 0.1921887
	speed: 0.5415s/iter; left time: 1601.1352s
	iters: 300, epoch: 5 | loss: 0.1692157
	speed: 0.5220s/iter; left time: 1491.3582s
	iters: 400, epoch: 5 | loss: 0.1859658
	speed: 0.5131s/iter; left time: 1414.5529s
	iters: 500, epoch: 5 | loss: 0.2095999
	speed: 0.5112s/iter; left time: 1358.1364s
Epoch: 5 cost time: 276.0324192047119
Epoch: 5, Steps: 526 | Train Loss: 0.1885274 Vali Loss: 0.0877057 Test Loss: 0.0893458
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.1922089
	speed: 1.5047s/iter; left time: 3808.3028s
	iters: 200, epoch: 6 | loss: 0.1854592
	speed: 0.5809s/iter; left time: 1412.2290s
	iters: 300, epoch: 6 | loss: 0.1453982
	speed: 0.5691s/iter; left time: 1326.4721s
	iters: 400, epoch: 6 | loss: 0.2040458
	speed: 0.7036s/iter; left time: 1569.8024s
	iters: 500, epoch: 6 | loss: 0.1917074
	speed: 0.6970s/iter; left time: 1485.3864s
Epoch: 6 cost time: 331.9324290752411
Epoch: 6, Steps: 526 | Train Loss: 0.1874923 Vali Loss: 0.0842022 Test Loss: 0.0853484
Validation loss decreased (0.085976 --> 0.084202).  Saving model ...
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.1772740
	speed: 1.8158s/iter; left time: 3640.6510s
	iters: 200, epoch: 7 | loss: 0.1782621
	speed: 0.6308s/iter; left time: 1201.6446s
	iters: 300, epoch: 7 | loss: 0.1994679
	speed: 0.6472s/iter; left time: 1168.1519s
	iters: 400, epoch: 7 | loss: 0.1858078
	speed: 0.6051s/iter; left time: 1031.6897s
	iters: 500, epoch: 7 | loss: 0.1891986
	speed: 0.5812s/iter; left time: 932.8038s
Epoch: 7 cost time: 331.67081451416016
Epoch: 7, Steps: 526 | Train Loss: 0.1869015 Vali Loss: 0.0841552 Test Loss: 0.0858074
Validation loss decreased (0.084202 --> 0.084155).  Saving model ...
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.2026275
	speed: 1.8374s/iter; left time: 2717.4673s
	iters: 200, epoch: 8 | loss: 0.1677720
	speed: 0.5972s/iter; left time: 823.5357s
	iters: 300, epoch: 8 | loss: 0.2143132
	speed: 0.5300s/iter; left time: 677.8586s
	iters: 400, epoch: 8 | loss: 0.1932966
	speed: 0.4874s/iter; left time: 574.6259s
	iters: 500, epoch: 8 | loss: 0.2001934
	speed: 0.4873s/iter; left time: 525.7580s
Epoch: 8 cost time: 290.07070779800415
Epoch: 8, Steps: 526 | Train Loss: 0.1865620 Vali Loss: 0.0850433 Test Loss: 0.0867802
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1569129
	speed: 1.1687s/iter; left time: 1113.7973s
	iters: 200, epoch: 9 | loss: 0.2052869
	speed: 0.4836s/iter; left time: 412.4756s
	iters: 300, epoch: 9 | loss: 0.1866856
	speed: 0.4879s/iter; left time: 367.4176s
	iters: 400, epoch: 9 | loss: 0.2032503
	speed: 0.4886s/iter; left time: 319.0541s
	iters: 500, epoch: 9 | loss: 0.2011891
	speed: 0.4895s/iter; left time: 270.6960s
Epoch: 9 cost time: 256.7097260951996
Epoch: 9, Steps: 526 | Train Loss: 0.1863447 Vali Loss: 0.0834315 Test Loss: 0.0851200
Validation loss decreased (0.084155 --> 0.083431).  Saving model ...
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1909337
	speed: 1.2103s/iter; left time: 516.7912s
	iters: 200, epoch: 10 | loss: 0.1979046
	speed: 0.4347s/iter; left time: 142.1530s
	iters: 300, epoch: 10 | loss: 0.1967989
	speed: 0.4892s/iter; left time: 111.0458s
	iters: 400, epoch: 10 | loss: 0.1827991
	speed: 0.4868s/iter; left time: 61.8210s
	iters: 500, epoch: 10 | loss: 0.2109827
	speed: 0.4877s/iter; left time: 13.1687s
Epoch: 10 cost time: 240.90024614334106
Epoch: 10, Steps: 526 | Train Loss: 0.1862669 Vali Loss: 0.0840730 Test Loss: 0.0858436
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS07_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5538
test shape: (5538, 12, 883) (5538, 12, 883)
test shape: (5538, 12, 883) (5538, 12, 883)
mse:0.0848744735121727, mae:0.20228715240955353
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           PEMS08              Model:              AGPT                

[1mData Loader[0m
  Data:               PEMS                Root Path:          ./dataset/PEMS/     
  Data Path:          PEMS08.npz          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           12                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             170                 Dec In:             170                 
  C Out:              170                 d model:            128                 
  n heads:            8                   e layers:           5                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.003               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 10606
val 3464
test 3465
	iters: 100, epoch: 1 | loss: 0.2707019
	speed: 0.0889s/iter; left time: 286.4838s
	iters: 200, epoch: 1 | loss: 0.2701244
	speed: 0.0870s/iter; left time: 271.3737s
	iters: 300, epoch: 1 | loss: 0.1964667
	speed: 0.0862s/iter; left time: 260.4743s
Epoch: 1 cost time: 28.9845187664032
Epoch: 1, Steps: 332 | Train Loss: 0.2683295 Vali Loss: 0.1923863 Test Loss: 0.1862371
Validation loss decreased (inf --> 0.192386).  Saving model ...
Updating learning rate to 0.003
	iters: 100, epoch: 2 | loss: 0.1851408
	speed: 0.2042s/iter; left time: 589.8911s
	iters: 200, epoch: 2 | loss: 0.2049273
	speed: 0.0842s/iter; left time: 234.7130s
	iters: 300, epoch: 2 | loss: 0.2137103
	speed: 0.0847s/iter; left time: 227.6933s
Epoch: 2 cost time: 28.098631381988525
Epoch: 2, Steps: 332 | Train Loss: 0.2138822 Vali Loss: 0.1362167 Test Loss: 0.1255488
Validation loss decreased (0.192386 --> 0.136217).  Saving model ...
Updating learning rate to 0.0015
	iters: 100, epoch: 3 | loss: 0.2024714
	speed: 0.1848s/iter; left time: 472.5912s
	iters: 200, epoch: 3 | loss: 0.2390240
	speed: 0.1359s/iter; left time: 333.8519s
	iters: 300, epoch: 3 | loss: 0.1756093
	speed: 0.1355s/iter; left time: 319.3301s
Epoch: 3 cost time: 38.63069796562195
Epoch: 3, Steps: 332 | Train Loss: 0.2024895 Vali Loss: 0.1150774 Test Loss: 0.1039882
Validation loss decreased (0.136217 --> 0.115077).  Saving model ...
Updating learning rate to 0.00075
	iters: 100, epoch: 4 | loss: 0.2157926
	speed: 0.3396s/iter; left time: 755.6083s
	iters: 200, epoch: 4 | loss: 0.2203835
	speed: 0.1354s/iter; left time: 287.6890s
	iters: 300, epoch: 4 | loss: 0.2097564
	speed: 0.1360s/iter; left time: 275.3417s
Epoch: 4 cost time: 45.035799980163574
Epoch: 4, Steps: 332 | Train Loss: 0.1988412 Vali Loss: 0.1117429 Test Loss: 0.1011072
Validation loss decreased (0.115077 --> 0.111743).  Saving model ...
Updating learning rate to 0.000375
	iters: 100, epoch: 5 | loss: 0.2104907
	speed: 0.3429s/iter; left time: 649.0961s
	iters: 200, epoch: 5 | loss: 0.2129013
	speed: 0.1330s/iter; left time: 238.4427s
	iters: 300, epoch: 5 | loss: 0.1923410
	speed: 0.1345s/iter; left time: 227.6860s
Epoch: 5 cost time: 44.9735951423645
Epoch: 5, Steps: 332 | Train Loss: 0.1964199 Vali Loss: 0.1110658 Test Loss: 0.1005016
Validation loss decreased (0.111743 --> 0.111066).  Saving model ...
Updating learning rate to 0.0001875
	iters: 100, epoch: 6 | loss: 0.2090088
	speed: 0.3387s/iter; left time: 528.6953s
	iters: 200, epoch: 6 | loss: 0.1858834
	speed: 0.1144s/iter; left time: 167.0710s
	iters: 300, epoch: 6 | loss: 0.1886906
	speed: 0.1028s/iter; left time: 139.9784s
Epoch: 6 cost time: 38.64920949935913
Epoch: 6, Steps: 332 | Train Loss: 0.1952261 Vali Loss: 0.1172616 Test Loss: 0.1080635
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-05
	iters: 100, epoch: 7 | loss: 0.2099589
	speed: 0.3103s/iter; left time: 381.3149s
	iters: 200, epoch: 7 | loss: 0.2184460
	speed: 0.1357s/iter; left time: 153.2564s
	iters: 300, epoch: 7 | loss: 0.2032031
	speed: 0.1355s/iter; left time: 139.3923s
Epoch: 7 cost time: 45.07327055931091
Epoch: 7, Steps: 332 | Train Loss: 0.1943541 Vali Loss: 0.1125104 Test Loss: 0.1026484
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.6875e-05
	iters: 100, epoch: 8 | loss: 0.1840592
	speed: 0.3364s/iter; left time: 301.7281s
	iters: 200, epoch: 8 | loss: 0.2017835
	speed: 0.1345s/iter; left time: 107.1841s
	iters: 300, epoch: 8 | loss: 0.1745905
	speed: 0.1361s/iter; left time: 94.8622s
Epoch: 8 cost time: 44.94242024421692
Epoch: 8, Steps: 332 | Train Loss: 0.1939353 Vali Loss: 0.1149304 Test Loss: 0.1057245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.34375e-05
	iters: 100, epoch: 9 | loss: 0.1882353
	speed: 0.3375s/iter; left time: 190.6881s
	iters: 200, epoch: 9 | loss: 0.1919771
	speed: 0.1345s/iter; left time: 62.5221s
	iters: 300, epoch: 9 | loss: 0.2034369
	speed: 0.1357s/iter; left time: 49.5427s
Epoch: 9 cost time: 44.84684920310974
Epoch: 9, Steps: 332 | Train Loss: 0.1936127 Vali Loss: 0.1134123 Test Loss: 0.1036874
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.171875e-05
	iters: 100, epoch: 10 | loss: 0.1922941
	speed: 0.3050s/iter; left time: 71.0685s
	iters: 200, epoch: 10 | loss: 0.1735471
	speed: 0.1041s/iter; left time: 13.8392s
	iters: 300, epoch: 10 | loss: 0.2198660
	speed: 0.1073s/iter; left time: 3.5398s
Epoch: 10 cost time: 35.31681251525879
Epoch: 10, Steps: 332 | Train Loss: 0.1934892 Vali Loss: 0.1126194 Test Loss: 0.1030597
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.859375e-06
>>>>>>>testing : long_term_forecast_PEMS08_AGPT_256_fixedFalse_0.003_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3465
test shape: (3465, 12, 170) (3465, 12, 170)
test shape: (3465, 12, 170) (3465, 12, 170)
mse:0.10077567398548126, mae:0.21366310119628906
