Running ETTm2 with seq_len=96, pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_96         Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1533145
	speed: 0.0981s/iter; left time: 1045.1747s
	iters: 200, epoch: 1 | loss: 0.4091955
	speed: 0.0928s/iter; left time: 979.6550s
	iters: 300, epoch: 1 | loss: 0.1512388
	speed: 0.0989s/iter; left time: 1033.8339s
	iters: 400, epoch: 1 | loss: 0.6443569
	speed: 0.1038s/iter; left time: 1074.4331s
	iters: 500, epoch: 1 | loss: 0.1471326
	speed: 0.1030s/iter; left time: 1055.9158s
	iters: 600, epoch: 1 | loss: 0.2177383
	speed: 0.1037s/iter; left time: 1052.2642s
	iters: 700, epoch: 1 | loss: 0.1558865
	speed: 0.1044s/iter; left time: 1049.0642s
	iters: 800, epoch: 1 | loss: 0.1071247
	speed: 0.1044s/iter; left time: 1038.9721s
	iters: 900, epoch: 1 | loss: 0.1555532
	speed: 0.1063s/iter; left time: 1046.8269s
	iters: 1000, epoch: 1 | loss: 0.1862043
	speed: 0.1059s/iter; left time: 1032.1890s
Epoch: 1 cost time: 109.99087023735046
Epoch: 1, Steps: 1075 | Train Loss: 0.2470156 Vali Loss: 0.1315569 Test Loss: 0.1810963
Validation loss decreased (inf --> 0.131557).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2248761
	speed: 0.6854s/iter; left time: 6563.4501s
	iters: 200, epoch: 2 | loss: 0.2824150
	speed: 0.1163s/iter; left time: 1101.7320s
	iters: 300, epoch: 2 | loss: 0.2019682
	speed: 0.1169s/iter; left time: 1095.7091s
	iters: 400, epoch: 2 | loss: 0.2351809
	speed: 0.1173s/iter; left time: 1088.0643s
	iters: 500, epoch: 2 | loss: 0.1964418
	speed: 0.1151s/iter; left time: 1055.9647s
	iters: 600, epoch: 2 | loss: 0.1423124
	speed: 0.1164s/iter; left time: 1056.0602s
	iters: 700, epoch: 2 | loss: 0.1325684
	speed: 0.1169s/iter; left time: 1049.2803s
	iters: 800, epoch: 2 | loss: 0.1504335
	speed: 0.1176s/iter; left time: 1043.4711s
	iters: 900, epoch: 2 | loss: 0.2783321
	speed: 0.1156s/iter; left time: 1014.1530s
	iters: 1000, epoch: 2 | loss: 0.2848791
	speed: 0.1165s/iter; left time: 1010.8258s
Epoch: 2 cost time: 125.32931971549988
Epoch: 2, Steps: 1075 | Train Loss: 0.2335884 Vali Loss: 0.1269654 Test Loss: 0.1760933
Validation loss decreased (0.131557 --> 0.126965).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1316345
	speed: 0.7394s/iter; left time: 6285.9264s
	iters: 200, epoch: 3 | loss: 0.6034924
	speed: 0.1168s/iter; left time: 980.9203s
	iters: 300, epoch: 3 | loss: 0.1780862
	speed: 0.1167s/iter; left time: 968.5407s
	iters: 400, epoch: 3 | loss: 0.3653071
	speed: 0.1153s/iter; left time: 945.2620s
	iters: 500, epoch: 3 | loss: 0.3129801
	speed: 0.1167s/iter; left time: 945.6966s
	iters: 600, epoch: 3 | loss: 0.1223561
	speed: 0.1167s/iter; left time: 933.7437s
	iters: 700, epoch: 3 | loss: 0.2075643
	speed: 0.1169s/iter; left time: 923.4925s
	iters: 800, epoch: 3 | loss: 0.2274727
	speed: 0.1157s/iter; left time: 902.3598s
	iters: 900, epoch: 3 | loss: 0.2095635
	speed: 0.1164s/iter; left time: 896.7152s
	iters: 1000, epoch: 3 | loss: 0.4902182
	speed: 0.1166s/iter; left time: 886.5616s
Epoch: 3 cost time: 125.28592586517334
Epoch: 3, Steps: 1075 | Train Loss: 0.2236840 Vali Loss: 0.1303945 Test Loss: 0.1802245
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1422058
	speed: 0.6946s/iter; left time: 5157.9779s
	iters: 200, epoch: 4 | loss: 0.1227740
	speed: 0.1052s/iter; left time: 770.3410s
	iters: 300, epoch: 4 | loss: 0.2152324
	speed: 0.1043s/iter; left time: 753.7090s
	iters: 400, epoch: 4 | loss: 0.1846025
	speed: 0.1053s/iter; left time: 750.2416s
	iters: 500, epoch: 4 | loss: 0.1316896
	speed: 0.1047s/iter; left time: 735.3601s
	iters: 600, epoch: 4 | loss: 0.2915281
	speed: 0.1047s/iter; left time: 725.2221s
	iters: 700, epoch: 4 | loss: 0.3358380
	speed: 0.1047s/iter; left time: 714.9484s
	iters: 800, epoch: 4 | loss: 0.1058278
	speed: 0.1044s/iter; left time: 702.2250s
	iters: 900, epoch: 4 | loss: 0.2040305
	speed: 0.1052s/iter; left time: 697.1598s
	iters: 1000, epoch: 4 | loss: 0.1288373
	speed: 0.1060s/iter; left time: 691.5772s
Epoch: 4 cost time: 112.98434805870056
Epoch: 4, Steps: 1075 | Train Loss: 0.2160673 Vali Loss: 0.1285822 Test Loss: 0.1780741
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1702369
	speed: 0.6092s/iter; left time: 3869.2716s
	iters: 200, epoch: 5 | loss: 0.1432155
	speed: 0.0955s/iter; left time: 597.2386s
	iters: 300, epoch: 5 | loss: 0.1471262
	speed: 0.0946s/iter; left time: 581.7772s
	iters: 400, epoch: 5 | loss: 0.2607697
	speed: 0.0954s/iter; left time: 577.1682s
	iters: 500, epoch: 5 | loss: 0.1614239
	speed: 0.0896s/iter; left time: 533.0657s
	iters: 600, epoch: 5 | loss: 0.2317502
	speed: 0.0824s/iter; left time: 482.0267s
	iters: 700, epoch: 5 | loss: 0.1568583
	speed: 0.0983s/iter; left time: 565.3151s
	iters: 800, epoch: 5 | loss: 0.2949825
	speed: 0.0972s/iter; left time: 549.4774s
	iters: 900, epoch: 5 | loss: 0.1218515
	speed: 0.0982s/iter; left time: 545.3135s
	iters: 1000, epoch: 5 | loss: 0.2985696
	speed: 0.0969s/iter; left time: 528.1460s
Epoch: 5 cost time: 101.70862030982971
Epoch: 5, Steps: 1075 | Train Loss: 0.2113575 Vali Loss: 0.1305563 Test Loss: 0.1813578
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.1763177067041397, mae:0.2590201199054718
Running ETTm2 with seq_len=192, pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_192_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_192_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1249791
	speed: 0.1853s/iter; left time: 1968.2232s
	iters: 200, epoch: 1 | loss: 0.1364555
	speed: 0.1879s/iter; left time: 1977.0987s
	iters: 300, epoch: 1 | loss: 0.4563523
	speed: 0.1950s/iter; left time: 2031.9200s
	iters: 400, epoch: 1 | loss: 0.3534187
	speed: 0.1938s/iter; left time: 2000.4875s
	iters: 500, epoch: 1 | loss: 0.1744419
	speed: 0.1950s/iter; left time: 1993.1767s
	iters: 600, epoch: 1 | loss: 0.1796968
	speed: 0.1942s/iter; left time: 1965.4398s
	iters: 700, epoch: 1 | loss: 0.1299981
	speed: 0.1818s/iter; left time: 1821.5358s
	iters: 800, epoch: 1 | loss: 0.2850261
	speed: 0.1773s/iter; left time: 1759.0241s
	iters: 900, epoch: 1 | loss: 0.1156445
	speed: 0.1786s/iter; left time: 1753.9532s
	iters: 1000, epoch: 1 | loss: 0.2415649
	speed: 0.1774s/iter; left time: 1724.5271s
Epoch: 1 cost time: 199.59073114395142
Epoch: 1, Steps: 1072 | Train Loss: 0.2522255 Vali Loss: 0.1227140 Test Loss: 0.1702136
Validation loss decreased (inf --> 0.122714).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4962070
	speed: 1.1723s/iter; left time: 11194.0172s
	iters: 200, epoch: 2 | loss: 0.2190595
	speed: 0.1950s/iter; left time: 1842.4140s
	iters: 300, epoch: 2 | loss: 0.2719502
	speed: 0.1718s/iter; left time: 1605.7865s
	iters: 400, epoch: 2 | loss: 0.2325048
	speed: 0.1733s/iter; left time: 1602.9614s
	iters: 500, epoch: 2 | loss: 0.1411965
	speed: 0.1678s/iter; left time: 1535.1574s
	iters: 600, epoch: 2 | loss: 0.1186001
	speed: 0.1708s/iter; left time: 1545.8916s
	iters: 700, epoch: 2 | loss: 0.1106391
	speed: 0.1726s/iter; left time: 1544.4560s
	iters: 800, epoch: 2 | loss: 0.2336973
	speed: 0.1712s/iter; left time: 1515.3195s
	iters: 900, epoch: 2 | loss: 0.1622927
	speed: 0.1703s/iter; left time: 1490.0077s
	iters: 1000, epoch: 2 | loss: 0.2762275
	speed: 0.1722s/iter; left time: 1489.3055s
Epoch: 2 cost time: 188.59599900245667
Epoch: 2, Steps: 1072 | Train Loss: 0.2315046 Vali Loss: 0.1225106 Test Loss: 0.1701067
Validation loss decreased (0.122714 --> 0.122511).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2440511
	speed: 0.9702s/iter; left time: 8224.6518s
	iters: 200, epoch: 3 | loss: 0.2709006
	speed: 0.1335s/iter; left time: 1118.3889s
	iters: 300, epoch: 3 | loss: 0.1837373
	speed: 0.1260s/iter; left time: 1043.1745s
	iters: 400, epoch: 3 | loss: 0.1233130
	speed: 0.1599s/iter; left time: 1307.1856s
	iters: 500, epoch: 3 | loss: 0.2637733
	speed: 0.1954s/iter; left time: 1578.2475s
	iters: 600, epoch: 3 | loss: 0.1695228
	speed: 0.1959s/iter; left time: 1562.3035s
	iters: 700, epoch: 3 | loss: 0.1374703
	speed: 0.1953s/iter; left time: 1538.1623s
	iters: 800, epoch: 3 | loss: 0.1745659
	speed: 0.1960s/iter; left time: 1524.5491s
	iters: 900, epoch: 3 | loss: 0.1474455
	speed: 0.1946s/iter; left time: 1493.8756s
	iters: 1000, epoch: 3 | loss: 0.2455218
	speed: 0.1956s/iter; left time: 1482.3191s
Epoch: 3 cost time: 188.93108320236206
Epoch: 3, Steps: 1072 | Train Loss: 0.2185009 Vali Loss: 0.1258055 Test Loss: 0.1782048
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1379919
	speed: 1.2031s/iter; left time: 8909.1580s
	iters: 200, epoch: 4 | loss: 0.1130727
	speed: 0.1785s/iter; left time: 1304.0115s
	iters: 300, epoch: 4 | loss: 0.1360021
	speed: 0.1777s/iter; left time: 1280.3204s
	iters: 400, epoch: 4 | loss: 0.1761708
	speed: 0.1784s/iter; left time: 1267.5143s
	iters: 500, epoch: 4 | loss: 0.2045278
	speed: 0.1778s/iter; left time: 1245.2680s
	iters: 600, epoch: 4 | loss: 0.1366400
	speed: 0.1779s/iter; left time: 1228.5812s
	iters: 700, epoch: 4 | loss: 0.2394801
	speed: 0.1778s/iter; left time: 1209.7067s
	iters: 800, epoch: 4 | loss: 0.1100216
	speed: 0.1951s/iter; left time: 1308.0920s
	iters: 900, epoch: 4 | loss: 0.4651078
	speed: 0.1948s/iter; left time: 1286.7972s
	iters: 1000, epoch: 4 | loss: 0.1583038
	speed: 0.1953s/iter; left time: 1270.4573s
Epoch: 4 cost time: 197.7735948562622
Epoch: 4, Steps: 1072 | Train Loss: 0.2075706 Vali Loss: 0.1230701 Test Loss: 0.1734487
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1299809
	speed: 1.2172s/iter; left time: 7708.2194s
	iters: 200, epoch: 5 | loss: 0.1662899
	speed: 0.1940s/iter; left time: 1209.3580s
	iters: 300, epoch: 5 | loss: 0.1777533
	speed: 0.1947s/iter; left time: 1194.0944s
	iters: 400, epoch: 5 | loss: 0.2530503
	speed: 0.1951s/iter; left time: 1177.2915s
	iters: 500, epoch: 5 | loss: 0.1228777
	speed: 0.1958s/iter; left time: 1161.7061s
	iters: 600, epoch: 5 | loss: 0.1468834
	speed: 0.1796s/iter; left time: 1047.3859s
	iters: 700, epoch: 5 | loss: 0.1370636
	speed: 0.1781s/iter; left time: 1020.9947s
	iters: 800, epoch: 5 | loss: 0.1339091
	speed: 0.1774s/iter; left time: 999.2732s
	iters: 900, epoch: 5 | loss: 0.2278648
	speed: 0.1761s/iter; left time: 974.1367s
	iters: 1000, epoch: 5 | loss: 0.1694452
	speed: 0.1781s/iter; left time: 967.6790s
Epoch: 5 cost time: 199.33950018882751
Epoch: 5, Steps: 1072 | Train Loss: 0.2005798 Vali Loss: 0.1259696 Test Loss: 0.1788390
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_192_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.1703474223613739, mae:0.25376415252685547
Running ETTm2 with seq_len=192, pred_len=192, e_layers=3, n_heads=2, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_192_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_192_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34177
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.4272212
	speed: 0.5125s/iter; left time: 1322.8734s
	iters: 200, epoch: 1 | loss: 0.2843658
	speed: 0.5254s/iter; left time: 1303.4282s
Epoch: 1 cost time: 138.87878799438477
Epoch: 1, Steps: 268 | Train Loss: 0.3411478 Vali Loss: 0.1704879 Test Loss: 0.2367322
Validation loss decreased (inf --> 0.170488).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3502380
	speed: 1.2736s/iter; left time: 2945.8726s
	iters: 200, epoch: 2 | loss: 0.2658422
	speed: 0.4756s/iter; left time: 1052.5594s
Epoch: 2 cost time: 129.9639048576355
Epoch: 2, Steps: 268 | Train Loss: 0.3168345 Vali Loss: 0.1683454 Test Loss: 0.2383169
Validation loss decreased (0.170488 --> 0.168345).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3028212
	speed: 1.2139s/iter; left time: 2482.3388s
	iters: 200, epoch: 3 | loss: 0.3881326
	speed: 0.5102s/iter; left time: 992.2804s
Epoch: 3 cost time: 132.6114044189453
Epoch: 3, Steps: 268 | Train Loss: 0.3037936 Vali Loss: 0.1669677 Test Loss: 0.2354131
Validation loss decreased (0.168345 --> 0.166968).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2626239
	speed: 1.1717s/iter; left time: 2082.1016s
	iters: 200, epoch: 4 | loss: 0.2945580
	speed: 0.4643s/iter; left time: 778.5579s
Epoch: 4 cost time: 124.08100843429565
Epoch: 4, Steps: 268 | Train Loss: 0.2931789 Vali Loss: 0.1683954 Test Loss: 0.2389891
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2622805
	speed: 1.1785s/iter; left time: 1778.2848s
	iters: 200, epoch: 5 | loss: 0.2379986
	speed: 0.4850s/iter; left time: 683.3679s
Epoch: 5 cost time: 130.27709293365479
Epoch: 5, Steps: 268 | Train Loss: 0.2858709 Vali Loss: 0.1674298 Test Loss: 0.2385264
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2377162
	speed: 1.2079s/iter; left time: 1499.0582s
	iters: 200, epoch: 6 | loss: 0.2343241
	speed: 0.4954s/iter; left time: 565.2172s
Epoch: 6 cost time: 132.35543966293335
Epoch: 6, Steps: 268 | Train Loss: 0.2811542 Vali Loss: 0.1688176 Test Loss: 0.2417728
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_192_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.23608291149139404, mae:0.2988281548023224
Running ETTm2 with seq_len=288, pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_288_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_288_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34177
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1921483
	speed: 0.3086s/iter; left time: 3268.4855s
	iters: 200, epoch: 1 | loss: 0.2548283
	speed: 0.3024s/iter; left time: 3172.8451s
	iters: 300, epoch: 1 | loss: 0.2346569
	speed: 0.2932s/iter; left time: 3046.7634s
	iters: 400, epoch: 1 | loss: 0.2630934
	speed: 0.2715s/iter; left time: 2793.5724s
	iters: 500, epoch: 1 | loss: 0.2312354
	speed: 0.2725s/iter; left time: 2776.7655s
	iters: 600, epoch: 1 | loss: 0.1209484
	speed: 0.2718s/iter; left time: 2742.7731s
	iters: 700, epoch: 1 | loss: 0.2270860
	speed: 0.2757s/iter; left time: 2754.9209s
	iters: 800, epoch: 1 | loss: 0.2088448
	speed: 0.2739s/iter; left time: 2709.4106s
	iters: 900, epoch: 1 | loss: 0.2332288
	speed: 0.2841s/iter; left time: 2781.7998s
	iters: 1000, epoch: 1 | loss: 0.2748279
	speed: 0.3012s/iter; left time: 2918.6392s
Epoch: 1 cost time: 306.5155990123749
Epoch: 1, Steps: 1069 | Train Loss: 0.2564041 Vali Loss: 0.1268580 Test Loss: 0.1754074
Validation loss decreased (inf --> 0.126858).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1268460
	speed: 1.9038s/iter; left time: 18128.1189s
	iters: 200, epoch: 2 | loss: 0.1481065
	speed: 0.2707s/iter; left time: 2550.2366s
	iters: 300, epoch: 2 | loss: 0.2467746
	speed: 0.2698s/iter; left time: 2514.8933s
	iters: 400, epoch: 2 | loss: 0.4702263
	speed: 0.2701s/iter; left time: 2490.4554s
	iters: 500, epoch: 2 | loss: 0.2987912
	speed: 0.2738s/iter; left time: 2497.2576s
	iters: 600, epoch: 2 | loss: 0.1424179
	speed: 0.2740s/iter; left time: 2472.1625s
	iters: 700, epoch: 2 | loss: 0.3917943
	speed: 0.2853s/iter; left time: 2545.4700s
	iters: 800, epoch: 2 | loss: 0.2018673
	speed: 0.3030s/iter; left time: 2673.4616s
	iters: 900, epoch: 2 | loss: 0.2929876
	speed: 0.3049s/iter; left time: 2659.6910s
	iters: 1000, epoch: 2 | loss: 0.1951320
	speed: 0.2893s/iter; left time: 2494.3449s
Epoch: 2 cost time: 302.5766062736511
Epoch: 2, Steps: 1069 | Train Loss: 0.2200223 Vali Loss: 0.1238359 Test Loss: 0.1731589
Validation loss decreased (0.126858 --> 0.123836).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3440034
	speed: 1.7806s/iter; left time: 15051.2960s
	iters: 200, epoch: 3 | loss: 0.1662581
	speed: 0.3049s/iter; left time: 2546.9981s
	iters: 300, epoch: 3 | loss: 0.2651947
	speed: 0.3016s/iter; left time: 2488.9264s
	iters: 400, epoch: 3 | loss: 0.1973540
	speed: 0.3050s/iter; left time: 2486.6328s
	iters: 500, epoch: 3 | loss: 0.1559694
	speed: 0.3037s/iter; left time: 2445.6453s
	iters: 600, epoch: 3 | loss: 0.2131442
	speed: 0.3032s/iter; left time: 2411.3690s
	iters: 700, epoch: 3 | loss: 0.1635880
	speed: 0.3052s/iter; left time: 2396.9866s
	iters: 800, epoch: 3 | loss: 0.1607504
	speed: 0.3029s/iter; left time: 2348.5033s
	iters: 900, epoch: 3 | loss: 0.1338584
	speed: 0.3035s/iter; left time: 2322.3235s
	iters: 1000, epoch: 3 | loss: 0.5273404
	speed: 0.3036s/iter; left time: 2292.8289s
Epoch: 3 cost time: 324.7756052017212
Epoch: 3, Steps: 1069 | Train Loss: 0.1969510 Vali Loss: 0.1265771 Test Loss: 0.1733674
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2930247
	speed: 1.9131s/iter; left time: 14126.6557s
	iters: 200, epoch: 4 | loss: 0.1538564
	speed: 0.2748s/iter; left time: 2001.7319s
	iters: 300, epoch: 4 | loss: 0.1539993
	speed: 0.2742s/iter; left time: 1969.5945s
	iters: 400, epoch: 4 | loss: 0.1104360
	speed: 0.2747s/iter; left time: 1945.9919s
	iters: 500, epoch: 4 | loss: 0.1207355
	speed: 0.2731s/iter; left time: 1907.3140s
	iters: 600, epoch: 4 | loss: 0.2513573
	speed: 0.2763s/iter; left time: 1901.8023s
	iters: 700, epoch: 4 | loss: 0.1178567
	speed: 0.2721s/iter; left time: 1845.8098s
	iters: 800, epoch: 4 | loss: 0.2034777
	speed: 0.2756s/iter; left time: 1842.3917s
	iters: 900, epoch: 4 | loss: 0.1845593
	speed: 0.2760s/iter; left time: 1817.1065s
	iters: 1000, epoch: 4 | loss: 0.1480198
	speed: 0.2314s/iter; left time: 1500.5535s
Epoch: 4 cost time: 287.37972712516785
Epoch: 4, Steps: 1069 | Train Loss: 0.1865539 Vali Loss: 0.1255492 Test Loss: 0.1762137
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1446970
	speed: 1.3396s/iter; left time: 8459.7736s
	iters: 200, epoch: 5 | loss: 0.1302332
	speed: 0.1974s/iter; left time: 1226.9056s
	iters: 300, epoch: 5 | loss: 0.1272207
	speed: 0.1991s/iter; left time: 1217.4705s
	iters: 400, epoch: 5 | loss: 0.1490064
	speed: 0.1968s/iter; left time: 1183.4792s
	iters: 500, epoch: 5 | loss: 0.1471209
	speed: 0.2292s/iter; left time: 1355.8540s
	iters: 600, epoch: 5 | loss: 0.1202681
	speed: 0.2295s/iter; left time: 1334.5293s
	iters: 700, epoch: 5 | loss: 0.1763232
	speed: 0.2298s/iter; left time: 1313.3068s
	iters: 800, epoch: 5 | loss: 0.1520770
	speed: 0.2290s/iter; left time: 1285.6761s
	iters: 900, epoch: 5 | loss: 0.1842929
	speed: 0.2158s/iter; left time: 1190.0267s
	iters: 1000, epoch: 5 | loss: 0.1533909
	speed: 0.2051s/iter; left time: 1110.5418s
Epoch: 5 cost time: 226.78824257850647
Epoch: 5, Steps: 1069 | Train Loss: 0.1774313 Vali Loss: 0.1257394 Test Loss: 0.1758699
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_288_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.17335109412670135, mae:0.2588287889957428
Running ETTm2 with seq_len=288, pred_len=192, e_layers=3, n_heads=2, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_288_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_288_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34081
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3665500
	speed: 0.5302s/iter; left time: 1363.1528s
	iters: 200, epoch: 1 | loss: 0.3332396
	speed: 0.5243s/iter; left time: 1295.4422s
Epoch: 1 cost time: 140.57322931289673
Epoch: 1, Steps: 267 | Train Loss: 0.3352111 Vali Loss: 0.1747372 Test Loss: 0.2393639
Validation loss decreased (inf --> 0.174737).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2648916
	speed: 1.3079s/iter; left time: 3013.2929s
	iters: 200, epoch: 2 | loss: 0.2010799
	speed: 0.5254s/iter; left time: 1158.0422s
Epoch: 2 cost time: 140.37099623680115
Epoch: 2, Steps: 267 | Train Loss: 0.2889450 Vali Loss: 0.1714208 Test Loss: 0.2377863
Validation loss decreased (0.174737 --> 0.171421).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2495445
	speed: 1.3372s/iter; left time: 2723.7757s
	iters: 200, epoch: 3 | loss: 0.2329573
	speed: 0.5303s/iter; left time: 1027.1912s
Epoch: 3 cost time: 142.7428069114685
Epoch: 3, Steps: 267 | Train Loss: 0.2623836 Vali Loss: 0.1702610 Test Loss: 0.2391417
Validation loss decreased (0.171421 --> 0.170261).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2058279
	speed: 1.3294s/iter; left time: 2352.9670s
	iters: 200, epoch: 4 | loss: 0.2406089
	speed: 0.4602s/iter; left time: 768.5666s
Epoch: 4 cost time: 128.72598958015442
Epoch: 4, Steps: 267 | Train Loss: 0.2484162 Vali Loss: 0.1710234 Test Loss: 0.2386249
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2729358
	speed: 1.2144s/iter; left time: 1825.2377s
	iters: 200, epoch: 5 | loss: 0.2462063
	speed: 0.5237s/iter; left time: 734.7949s
Epoch: 5 cost time: 138.512704372406
Epoch: 5, Steps: 267 | Train Loss: 0.2424682 Vali Loss: 0.1696746 Test Loss: 0.2418523
Validation loss decreased (0.170261 --> 0.169675).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2719908
	speed: 1.3109s/iter; left time: 1620.3125s
	iters: 200, epoch: 6 | loss: 0.2010806
	speed: 0.5248s/iter; left time: 596.2285s
Epoch: 6 cost time: 140.22720336914062
Epoch: 6, Steps: 267 | Train Loss: 0.2387367 Vali Loss: 0.1707351 Test Loss: 0.2449764
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2326752
	speed: 1.3065s/iter; left time: 1266.0300s
	iters: 200, epoch: 7 | loss: 0.1950415
	speed: 0.5236s/iter; left time: 454.9818s
Epoch: 7 cost time: 140.17425346374512
Epoch: 7, Steps: 267 | Train Loss: 0.2375156 Vali Loss: 0.1707577 Test Loss: 0.2434675
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2440764
	speed: 1.3554s/iter; left time: 951.4783s
	iters: 200, epoch: 8 | loss: 0.2683792
	speed: 0.5296s/iter; left time: 318.8092s
Epoch: 8 cost time: 141.76225757598877
Epoch: 8, Steps: 267 | Train Loss: 0.2360718 Vali Loss: 0.1712780 Test Loss: 0.2437226
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_288_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.24258039891719818, mae:0.30574336647987366
Running ETTm2 with seq_len=384, pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_384_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_384_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34081
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1688373
	speed: 0.3191s/iter; left time: 3369.9310s
	iters: 200, epoch: 1 | loss: 0.1516995
	speed: 0.3143s/iter; left time: 3288.1470s
	iters: 300, epoch: 1 | loss: 0.1742792
	speed: 0.3142s/iter; left time: 3255.6485s
	iters: 400, epoch: 1 | loss: 0.2274273
	speed: 0.3146s/iter; left time: 3228.6000s
	iters: 500, epoch: 1 | loss: 0.2020527
	speed: 0.3137s/iter; left time: 3187.9792s
	iters: 600, epoch: 1 | loss: 0.1506020
	speed: 0.3139s/iter; left time: 3158.0169s
	iters: 700, epoch: 1 | loss: 0.3453809
	speed: 0.2840s/iter; left time: 2828.4674s
	iters: 800, epoch: 1 | loss: 0.2085522
	speed: 0.2658s/iter; left time: 2621.1906s
	iters: 900, epoch: 1 | loss: 0.3684143
	speed: 0.2683s/iter; left time: 2618.4513s
	iters: 1000, epoch: 1 | loss: 0.1449285
	speed: 0.2679s/iter; left time: 2588.6179s
Epoch: 1 cost time: 315.5024559497833
Epoch: 1, Steps: 1066 | Train Loss: 0.2579870 Vali Loss: 0.1875272 Test Loss: 0.2717376
Validation loss decreased (inf --> 0.187527).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1432983
	speed: 1.6526s/iter; left time: 15691.8750s
	iters: 200, epoch: 2 | loss: 0.1730774
	speed: 0.2740s/iter; left time: 2574.3383s
	iters: 300, epoch: 2 | loss: 0.1716213
	speed: 0.2768s/iter; left time: 2573.2210s
	iters: 400, epoch: 2 | loss: 0.2170612
	speed: 0.2442s/iter; left time: 2245.0487s
	iters: 500, epoch: 2 | loss: 0.2144043
	speed: 0.2736s/iter; left time: 2488.5657s
	iters: 600, epoch: 2 | loss: 0.1395152
	speed: 0.2725s/iter; left time: 2451.5388s
	iters: 700, epoch: 2 | loss: 0.3284816
	speed: 0.2761s/iter; left time: 2456.3419s
	iters: 800, epoch: 2 | loss: 0.3084666
	speed: 0.2791s/iter; left time: 2454.5702s
	iters: 900, epoch: 2 | loss: 0.2614457
	speed: 0.2785s/iter; left time: 2421.4655s
	iters: 1000, epoch: 2 | loss: 0.1179282
	speed: 0.1891s/iter; left time: 1625.1702s
Epoch: 2 cost time: 275.81582617759705
Epoch: 2, Steps: 1066 | Train Loss: 0.2221267 Vali Loss: 0.1221956 Test Loss: 0.1729808
Validation loss decreased (0.187527 --> 0.122196).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1891440
	speed: 1.8168s/iter; left time: 15313.8028s
	iters: 200, epoch: 3 | loss: 0.3913828
	speed: 0.3149s/iter; left time: 2622.4839s
	iters: 300, epoch: 3 | loss: 0.2376669
	speed: 0.3161s/iter; left time: 2601.1852s
	iters: 400, epoch: 3 | loss: 0.1474353
	speed: 0.3168s/iter; left time: 2575.1030s
	iters: 500, epoch: 3 | loss: 0.1910038
	speed: 0.3172s/iter; left time: 2546.9482s
	iters: 600, epoch: 3 | loss: 0.1299533
	speed: 0.3164s/iter; left time: 2508.4506s
	iters: 700, epoch: 3 | loss: 0.1548553
	speed: 0.3160s/iter; left time: 2473.9513s
	iters: 800, epoch: 3 | loss: 0.1338860
	speed: 0.3162s/iter; left time: 2444.0111s
	iters: 900, epoch: 3 | loss: 0.1339528
	speed: 0.2912s/iter; left time: 2221.8723s
	iters: 1000, epoch: 3 | loss: 0.1779955
	speed: 0.2671s/iter; left time: 2010.9842s
Epoch: 3 cost time: 326.59967017173767
Epoch: 3, Steps: 1066 | Train Loss: 0.1928803 Vali Loss: 0.1265246 Test Loss: 0.1801508
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1593504
	speed: 1.7485s/iter; left time: 12873.8693s
	iters: 200, epoch: 4 | loss: 0.1280892
	speed: 0.3159s/iter; left time: 2294.2458s
	iters: 300, epoch: 4 | loss: 0.1818374
	speed: 0.3161s/iter; left time: 2263.8820s
	iters: 400, epoch: 4 | loss: 0.1821083
	speed: 0.3159s/iter; left time: 2231.3269s
	iters: 500, epoch: 4 | loss: 0.2314463
	speed: 0.3149s/iter; left time: 2192.3164s
	iters: 600, epoch: 4 | loss: 0.1478969
	speed: 0.3170s/iter; left time: 2175.7478s
	iters: 700, epoch: 4 | loss: 0.2384781
	speed: 0.3180s/iter; left time: 2150.9416s
	iters: 800, epoch: 4 | loss: 0.2059051
	speed: 0.3161s/iter; left time: 2106.1042s
	iters: 900, epoch: 4 | loss: 0.1813143
	speed: 0.3187s/iter; left time: 2091.7077s
	iters: 1000, epoch: 4 | loss: 0.1440841
	speed: 0.3161s/iter; left time: 2043.0120s
Epoch: 4 cost time: 337.2601935863495
Epoch: 4, Steps: 1066 | Train Loss: 0.1801160 Vali Loss: 0.1250234 Test Loss: 0.1835708
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1234013
	speed: 1.8850s/iter; left time: 11869.6036s
	iters: 200, epoch: 5 | loss: 0.1053546
	speed: 0.3152s/iter; left time: 1953.5789s
	iters: 300, epoch: 5 | loss: 0.2663907
	speed: 0.3152s/iter; left time: 1921.9076s
	iters: 400, epoch: 5 | loss: 0.1133665
	speed: 0.3157s/iter; left time: 1893.4258s
	iters: 500, epoch: 5 | loss: 0.2001871
	speed: 0.3152s/iter; left time: 1858.8182s
	iters: 600, epoch: 5 | loss: 0.2516063
	speed: 0.3163s/iter; left time: 1833.6183s
	iters: 700, epoch: 5 | loss: 0.1042619
	speed: 0.3151s/iter; left time: 1795.3040s
	iters: 800, epoch: 5 | loss: 0.1253746
	speed: 0.3156s/iter; left time: 1766.2056s
	iters: 900, epoch: 5 | loss: 0.2236389
	speed: 0.3166s/iter; left time: 1740.5687s
	iters: 1000, epoch: 5 | loss: 0.3263949
	speed: 0.3154s/iter; left time: 1702.1570s
Epoch: 5 cost time: 336.1596086025238
Epoch: 5, Steps: 1066 | Train Loss: 0.1723047 Vali Loss: 0.1268208 Test Loss: 0.1844526
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_384_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.1731797754764557, mae:0.26463016867637634
Running ETTm2 with seq_len=384, pred_len=192, e_layers=3, n_heads=2, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_384_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_384_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33985
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3807228
	speed: 0.5840s/iter; left time: 1495.5367s
	iters: 200, epoch: 1 | loss: 0.2745135
	speed: 0.5296s/iter; left time: 1303.4062s
Epoch: 1 cost time: 146.0094931125641
Epoch: 1, Steps: 266 | Train Loss: 0.3295398 Vali Loss: 0.1643582 Test Loss: 0.2337542
Validation loss decreased (inf --> 0.164358).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3562607
	speed: 1.3581s/iter; left time: 3116.7639s
	iters: 200, epoch: 2 | loss: 0.2492228
	speed: 0.5296s/iter; left time: 1162.5603s
Epoch: 2 cost time: 143.12415385246277
Epoch: 2, Steps: 266 | Train Loss: 0.2824335 Vali Loss: 0.1770233 Test Loss: 0.2547009
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3160010
	speed: 1.5029s/iter; left time: 3049.4003s
	iters: 200, epoch: 3 | loss: 0.2612966
	speed: 0.5788s/iter; left time: 1116.4351s
Epoch: 3 cost time: 153.96317052841187
Epoch: 3, Steps: 266 | Train Loss: 0.2530518 Vali Loss: 0.1676935 Test Loss: 0.2330442
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2382582
	speed: 1.5062s/iter; left time: 2655.3584s
	iters: 200, epoch: 4 | loss: 0.2499048
	speed: 0.5799s/iter; left time: 964.3894s
Epoch: 4 cost time: 154.39291501045227
Epoch: 4, Steps: 266 | Train Loss: 0.2397319 Vali Loss: 0.1657611 Test Loss: 0.2431700
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_384_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.2343861609697342, mae:0.3085331916809082
Running ETTm2 with seq_len=384, pred_len=336, e_layers=1, n_heads=4, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_384_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_384_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33841
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6125628
	speed: 0.1885s/iter; left time: 1975.7074s
	iters: 200, epoch: 1 | loss: 0.3369561
	speed: 0.1845s/iter; left time: 1914.9134s
	iters: 300, epoch: 1 | loss: 0.2251213
	speed: 0.1920s/iter; left time: 1974.0505s
	iters: 400, epoch: 1 | loss: 0.3261299
	speed: 0.1929s/iter; left time: 1964.1194s
	iters: 500, epoch: 1 | loss: 0.2498648
	speed: 0.1912s/iter; left time: 1927.1684s
	iters: 600, epoch: 1 | loss: 0.6894583
	speed: 0.1988s/iter; left time: 1984.3829s
	iters: 700, epoch: 1 | loss: 0.2889595
	speed: 0.2259s/iter; left time: 2232.0078s
	iters: 800, epoch: 1 | loss: 0.3415875
	speed: 0.2220s/iter; left time: 2171.1094s
	iters: 900, epoch: 1 | loss: 0.4637890
	speed: 0.2229s/iter; left time: 2157.7930s
	iters: 1000, epoch: 1 | loss: 0.3356263
	speed: 0.2220s/iter; left time: 2126.7452s
Epoch: 1 cost time: 217.07033467292786
Epoch: 1, Steps: 1058 | Train Loss: 0.4191726 Vali Loss: 0.2194908 Test Loss: 0.2972442
Validation loss decreased (inf --> 0.219491).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3337326
	speed: 1.5720s/iter; left time: 14812.8326s
	iters: 200, epoch: 2 | loss: 0.4704148
	speed: 0.2215s/iter; left time: 2064.7579s
	iters: 300, epoch: 2 | loss: 0.4079594
	speed: 0.2212s/iter; left time: 2040.1618s
	iters: 400, epoch: 2 | loss: 0.2545789
	speed: 0.2193s/iter; left time: 2001.0801s
	iters: 500, epoch: 2 | loss: 0.3513063
	speed: 0.2196s/iter; left time: 1981.8930s
	iters: 600, epoch: 2 | loss: 0.4415959
	speed: 0.2200s/iter; left time: 1962.9221s
	iters: 700, epoch: 2 | loss: 0.3241302
	speed: 0.2192s/iter; left time: 1933.7359s
	iters: 800, epoch: 2 | loss: 0.3869447
	speed: 0.2210s/iter; left time: 1927.8204s
	iters: 900, epoch: 2 | loss: 0.2825612
	speed: 0.2209s/iter; left time: 1905.0368s
	iters: 1000, epoch: 2 | loss: 0.3004345
	speed: 0.2196s/iter; left time: 1871.3907s
Epoch: 2 cost time: 233.15926384925842
Epoch: 2, Steps: 1058 | Train Loss: 0.3647869 Vali Loss: 0.2114110 Test Loss: 0.2776176
Validation loss decreased (0.219491 --> 0.211411).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3277437
	speed: 1.5648s/iter; left time: 13089.5135s
	iters: 200, epoch: 3 | loss: 0.1853582
	speed: 0.2197s/iter; left time: 1815.6371s
	iters: 300, epoch: 3 | loss: 0.2851834
	speed: 0.2206s/iter; left time: 1801.4969s
	iters: 400, epoch: 3 | loss: 0.4526480
	speed: 0.2205s/iter; left time: 1778.7135s
	iters: 500, epoch: 3 | loss: 0.3132648
	speed: 0.2210s/iter; left time: 1759.8996s
	iters: 600, epoch: 3 | loss: 0.3242014
	speed: 0.2208s/iter; left time: 1736.2817s
	iters: 700, epoch: 3 | loss: 0.2883844
	speed: 0.2199s/iter; left time: 1707.7245s
	iters: 800, epoch: 3 | loss: 0.5149678
	speed: 0.2200s/iter; left time: 1686.2467s
	iters: 900, epoch: 3 | loss: 0.5275533
	speed: 0.2195s/iter; left time: 1660.4343s
	iters: 1000, epoch: 3 | loss: 0.2846057
	speed: 0.2196s/iter; left time: 1639.2871s
Epoch: 3 cost time: 231.8796923160553
Epoch: 3, Steps: 1058 | Train Loss: 0.3354691 Vali Loss: 0.2300106 Test Loss: 0.3028931
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3179229
	speed: 1.4146s/iter; left time: 10336.1216s
	iters: 200, epoch: 4 | loss: 0.2060731
	speed: 0.2159s/iter; left time: 1556.1162s
	iters: 300, epoch: 4 | loss: 0.4319640
	speed: 0.1933s/iter; left time: 1373.7027s
	iters: 400, epoch: 4 | loss: 0.3329578
	speed: 0.1960s/iter; left time: 1373.3827s
	iters: 500, epoch: 4 | loss: 0.3132348
	speed: 0.1956s/iter; left time: 1350.8337s
	iters: 600, epoch: 4 | loss: 0.2673698
	speed: 0.1880s/iter; left time: 1279.8377s
	iters: 700, epoch: 4 | loss: 0.2862721
	speed: 0.1951s/iter; left time: 1308.3258s
	iters: 800, epoch: 4 | loss: 0.2850841
	speed: 0.1929s/iter; left time: 1274.3823s
	iters: 900, epoch: 4 | loss: 0.1890229
	speed: 0.1936s/iter; left time: 1259.6017s
	iters: 1000, epoch: 4 | loss: 0.2217746
	speed: 0.1935s/iter; left time: 1239.7175s
Epoch: 4 cost time: 209.95813632011414
Epoch: 4, Steps: 1058 | Train Loss: 0.3197339 Vali Loss: 0.2171556 Test Loss: 0.2867942
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2008937
	speed: 1.5370s/iter; left time: 9604.4237s
	iters: 200, epoch: 5 | loss: 0.1876567
	speed: 0.2196s/iter; left time: 1350.3113s
	iters: 300, epoch: 5 | loss: 0.3310805
	speed: 0.2208s/iter; left time: 1335.8016s
	iters: 400, epoch: 5 | loss: 0.3427257
	speed: 0.2205s/iter; left time: 1311.5165s
	iters: 500, epoch: 5 | loss: 0.2335159
	speed: 0.2195s/iter; left time: 1283.7313s
	iters: 600, epoch: 5 | loss: 0.3047837
	speed: 0.2218s/iter; left time: 1275.0203s
	iters: 700, epoch: 5 | loss: 0.4086454
	speed: 0.2207s/iter; left time: 1246.6800s
	iters: 800, epoch: 5 | loss: 0.2269163
	speed: 0.2201s/iter; left time: 1221.5091s
	iters: 900, epoch: 5 | loss: 0.3290355
	speed: 0.2199s/iter; left time: 1198.3442s
	iters: 1000, epoch: 5 | loss: 0.3461414
	speed: 0.2205s/iter; left time: 1179.2365s
Epoch: 5 cost time: 233.43594694137573
Epoch: 5, Steps: 1058 | Train Loss: 0.3121885 Vali Loss: 0.2174867 Test Loss: 0.2921451
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_384_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.2778196632862091, mae:0.3352014124393463
Running ETTm2 with seq_len=512, pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_512_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_512_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33953
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.3811053
	speed: 0.3762s/iter; left time: 3958.2672s
	iters: 200, epoch: 1 | loss: 0.3111109
	speed: 0.3405s/iter; left time: 3548.5325s
	iters: 300, epoch: 1 | loss: 0.2104131
	speed: 0.3434s/iter; left time: 3544.6542s
	iters: 400, epoch: 1 | loss: 0.2025616
	speed: 0.3414s/iter; left time: 3489.3551s
	iters: 500, epoch: 1 | loss: 0.1851083
	speed: 0.3305s/iter; left time: 3344.7230s
	iters: 600, epoch: 1 | loss: 0.1942209
	speed: 0.3469s/iter; left time: 3475.9796s
	iters: 700, epoch: 1 | loss: 0.1321958
	speed: 0.3181s/iter; left time: 3155.4515s
	iters: 800, epoch: 1 | loss: 0.2360869
	speed: 0.2387s/iter; left time: 2344.3593s
	iters: 900, epoch: 1 | loss: 0.2124536
	speed: 0.3582s/iter; left time: 3482.2204s
	iters: 1000, epoch: 1 | loss: 0.2292346
	speed: 0.4049s/iter; left time: 3895.7435s
Epoch: 1 cost time: 365.1351089477539
Epoch: 1, Steps: 1062 | Train Loss: 0.2573286 Vali Loss: 0.1345549 Test Loss: 0.1970578
Validation loss decreased (inf --> 0.134555).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1739611
	speed: 2.4980s/iter; left time: 23628.9838s
	iters: 200, epoch: 2 | loss: 0.1947385
	speed: 0.4064s/iter; left time: 3803.9236s
	iters: 300, epoch: 2 | loss: 0.1239679
	speed: 0.4063s/iter; left time: 3761.5899s
	iters: 400, epoch: 2 | loss: 0.1953461
	speed: 0.4048s/iter; left time: 3707.1380s
	iters: 500, epoch: 2 | loss: 0.1586373
	speed: 0.4035s/iter; left time: 3655.0913s
	iters: 600, epoch: 2 | loss: 0.2765153
	speed: 0.4052s/iter; left time: 3630.3523s
	iters: 700, epoch: 2 | loss: 0.2429238
	speed: 0.4046s/iter; left time: 3584.6624s
	iters: 800, epoch: 2 | loss: 0.5266757
	speed: 0.4062s/iter; left time: 3557.7528s
	iters: 900, epoch: 2 | loss: 0.1727008
	speed: 0.4067s/iter; left time: 3521.5115s
	iters: 1000, epoch: 2 | loss: 0.1339607
	speed: 0.4081s/iter; left time: 3493.3064s
Epoch: 2 cost time: 430.9388072490692
Epoch: 2, Steps: 1062 | Train Loss: 0.2096081 Vali Loss: 0.1359851 Test Loss: 0.1858630
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1683662
	speed: 2.1626s/iter; left time: 18159.4606s
	iters: 200, epoch: 3 | loss: 0.3751553
	speed: 0.2570s/iter; left time: 2132.2499s
	iters: 300, epoch: 3 | loss: 0.1478502
	speed: 0.2662s/iter; left time: 2181.8820s
	iters: 400, epoch: 3 | loss: 0.2053560
	speed: 0.2690s/iter; left time: 2178.0480s
	iters: 500, epoch: 3 | loss: 0.1261085
	speed: 0.3858s/iter; left time: 3085.1098s
	iters: 600, epoch: 3 | loss: 0.2715430
	speed: 0.4074s/iter; left time: 3217.0461s
	iters: 700, epoch: 3 | loss: 0.2091724
	speed: 0.4058s/iter; left time: 3163.8519s
	iters: 800, epoch: 3 | loss: 0.2081008
	speed: 0.4078s/iter; left time: 3138.8243s
	iters: 900, epoch: 3 | loss: 0.1714002
	speed: 0.4105s/iter; left time: 3118.7117s
	iters: 1000, epoch: 3 | loss: 0.1348372
	speed: 0.4081s/iter; left time: 3059.7121s
Epoch: 3 cost time: 372.32111263275146
Epoch: 3, Steps: 1062 | Train Loss: 0.1780936 Vali Loss: 0.1279614 Test Loss: 0.1814993
Validation loss decreased (0.134555 --> 0.127961).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2043669
	speed: 2.5413s/iter; left time: 18640.1384s
	iters: 200, epoch: 4 | loss: 0.1636840
	speed: 0.4066s/iter; left time: 2942.0625s
	iters: 300, epoch: 4 | loss: 0.1979763
	speed: 0.4077s/iter; left time: 2909.1524s
	iters: 400, epoch: 4 | loss: 0.1359055
	speed: 0.4069s/iter; left time: 2862.2015s
	iters: 500, epoch: 4 | loss: 0.1647328
	speed: 0.4063s/iter; left time: 2817.7300s
	iters: 600, epoch: 4 | loss: 0.1356427
	speed: 0.4066s/iter; left time: 2778.8077s
	iters: 700, epoch: 4 | loss: 0.1216910
	speed: 0.4052s/iter; left time: 2729.0102s
	iters: 800, epoch: 4 | loss: 0.1550023
	speed: 0.4075s/iter; left time: 2703.7133s
	iters: 900, epoch: 4 | loss: 0.1194428
	speed: 0.4100s/iter; left time: 2679.0444s
	iters: 1000, epoch: 4 | loss: 0.0949967
	speed: 0.4100s/iter; left time: 2638.2210s
Epoch: 4 cost time: 430.81109738349915
Epoch: 4, Steps: 1062 | Train Loss: 0.1629011 Vali Loss: 0.1282580 Test Loss: 0.1922792
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1621886
	speed: 2.2946s/iter; left time: 14394.0958s
	iters: 200, epoch: 5 | loss: 0.0945819
	speed: 0.4075s/iter; left time: 2515.3887s
	iters: 300, epoch: 5 | loss: 0.1761181
	speed: 0.4045s/iter; left time: 2456.2690s
	iters: 400, epoch: 5 | loss: 0.1394343
	speed: 0.4055s/iter; left time: 2422.0546s
	iters: 500, epoch: 5 | loss: 0.1715917
	speed: 0.4061s/iter; left time: 2385.2584s
	iters: 600, epoch: 5 | loss: 0.1819866
	speed: 0.4070s/iter; left time: 2349.4955s
	iters: 700, epoch: 5 | loss: 0.1687332
	speed: 0.4070s/iter; left time: 2308.9444s
	iters: 800, epoch: 5 | loss: 0.1728827
	speed: 0.4091s/iter; left time: 2279.8623s
	iters: 900, epoch: 5 | loss: 0.1242263
	speed: 0.4060s/iter; left time: 2222.0817s
	iters: 1000, epoch: 5 | loss: 0.2046222
	speed: 0.4057s/iter; left time: 2179.8475s
Epoch: 5 cost time: 431.9243059158325
Epoch: 5, Steps: 1062 | Train Loss: 0.1548582 Vali Loss: 0.1300493 Test Loss: 0.1866944
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2456011
	speed: 2.4873s/iter; left time: 12961.2714s
	iters: 200, epoch: 6 | loss: 0.1168440
	speed: 0.3551s/iter; left time: 1815.1190s
	iters: 300, epoch: 6 | loss: 0.1664153
	speed: 0.3510s/iter; left time: 1758.9631s
	iters: 400, epoch: 6 | loss: 0.2137568
	speed: 0.3544s/iter; left time: 1740.4239s
	iters: 500, epoch: 6 | loss: 0.0979417
	speed: 0.3459s/iter; left time: 1664.1480s
	iters: 600, epoch: 6 | loss: 0.2158574
	speed: 0.2730s/iter; left time: 1286.1298s
	iters: 700, epoch: 6 | loss: 0.2117000
	speed: 0.2867s/iter; left time: 1322.1431s
	iters: 800, epoch: 6 | loss: 0.0982270
	speed: 0.3351s/iter; left time: 1511.6905s
	iters: 900, epoch: 6 | loss: 0.1356390
	speed: 0.3592s/iter; left time: 1584.5064s
	iters: 1000, epoch: 6 | loss: 0.2067590
	speed: 0.4105s/iter; left time: 1769.6264s
Epoch: 6 cost time: 370.29644751548767
Epoch: 6, Steps: 1062 | Train Loss: 0.1506893 Vali Loss: 0.1311337 Test Loss: 0.1896541
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_512_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.1817038357257843, mae:0.2716367542743683
Running ETTm2 with seq_len=512, pred_len=192, e_layers=3, n_heads=2, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_512_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_512_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33857
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2643488
	speed: 0.9065s/iter; left time: 2312.4757s
	iters: 200, epoch: 1 | loss: 0.3642952
	speed: 0.9049s/iter; left time: 2217.8463s
Epoch: 1 cost time: 239.83792185783386
Epoch: 1, Steps: 265 | Train Loss: 0.3287602 Vali Loss: 0.1701196 Test Loss: 0.2304980
Validation loss decreased (inf --> 0.170120).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1794083
	speed: 2.1977s/iter; left time: 5023.9726s
	iters: 200, epoch: 2 | loss: 0.2744355
	speed: 0.9075s/iter; left time: 1983.7513s
Epoch: 2 cost time: 240.99639320373535
Epoch: 2, Steps: 265 | Train Loss: 0.2713482 Vali Loss: 0.1746152 Test Loss: 0.2444865
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3085251
	speed: 1.9642s/iter; left time: 3969.7172s
	iters: 200, epoch: 3 | loss: 0.2252313
	speed: 0.8923s/iter; left time: 1714.1839s
Epoch: 3 cost time: 225.89883708953857
Epoch: 3, Steps: 265 | Train Loss: 0.2417977 Vali Loss: 0.1744217 Test Loss: 0.2434523
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2266126
	speed: 2.1791s/iter; left time: 3826.4354s
	iters: 200, epoch: 4 | loss: 0.2412738
	speed: 0.9050s/iter; left time: 1498.6554s
Epoch: 4 cost time: 240.25944304466248
Epoch: 4, Steps: 265 | Train Loss: 0.2300904 Vali Loss: 0.1723625 Test Loss: 0.2511472
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_512_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.23115679621696472, mae:0.30477064847946167
Running ETTm2 with seq_len=512, pred_len=336, e_layers=1, n_heads=4, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_512_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_512_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33713
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6062139
	speed: 0.2878s/iter; left time: 3005.0410s
	iters: 200, epoch: 1 | loss: 0.3895885
	speed: 0.2823s/iter; left time: 2919.1478s
	iters: 300, epoch: 1 | loss: 0.2631943
	speed: 0.2837s/iter; left time: 2904.9595s
	iters: 400, epoch: 1 | loss: 0.5087342
	speed: 0.2559s/iter; left time: 2595.1227s
	iters: 500, epoch: 1 | loss: 0.9313264
	speed: 0.2408s/iter; left time: 2418.1002s
	iters: 600, epoch: 1 | loss: 0.4747924
	speed: 0.2433s/iter; left time: 2419.1143s
	iters: 700, epoch: 1 | loss: 0.2690104
	speed: 0.2447s/iter; left time: 2408.0470s
	iters: 800, epoch: 1 | loss: 0.8126186
	speed: 0.2467s/iter; left time: 2403.3383s
	iters: 900, epoch: 1 | loss: 0.3542121
	speed: 0.2456s/iter; left time: 2367.7886s
	iters: 1000, epoch: 1 | loss: 0.3124376
	speed: 0.2428s/iter; left time: 2316.2979s
Epoch: 1 cost time: 270.78081727027893
Epoch: 1, Steps: 1054 | Train Loss: 0.4219892 Vali Loss: 0.2193456 Test Loss: 0.2861535
Validation loss decreased (inf --> 0.219346).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2712770
	speed: 1.7906s/iter; left time: 16808.6329s
	iters: 200, epoch: 2 | loss: 0.3491584
	speed: 0.2811s/iter; left time: 2610.6783s
	iters: 300, epoch: 2 | loss: 0.4156777
	speed: 0.2815s/iter; left time: 2586.5435s
	iters: 400, epoch: 2 | loss: 0.2616619
	speed: 0.2844s/iter; left time: 2584.2642s
	iters: 500, epoch: 2 | loss: 0.4677805
	speed: 0.2831s/iter; left time: 2544.5621s
	iters: 600, epoch: 2 | loss: 0.3411312
	speed: 0.2835s/iter; left time: 2519.7378s
	iters: 700, epoch: 2 | loss: 0.4644344
	speed: 0.2826s/iter; left time: 2482.9853s
	iters: 800, epoch: 2 | loss: 0.2017858
	speed: 0.2826s/iter; left time: 2455.3649s
	iters: 900, epoch: 2 | loss: 0.2768652
	speed: 0.2840s/iter; left time: 2438.3506s
	iters: 1000, epoch: 2 | loss: 0.2481282
	speed: 0.2823s/iter; left time: 2395.7625s
Epoch: 2 cost time: 294.84100580215454
Epoch: 2, Steps: 1054 | Train Loss: 0.3552868 Vali Loss: 0.2112298 Test Loss: 0.2893743
Validation loss decreased (0.219346 --> 0.211230).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4511683
	speed: 2.0850s/iter; left time: 17373.9775s
	iters: 200, epoch: 3 | loss: 0.2581268
	speed: 0.2830s/iter; left time: 2330.2361s
	iters: 300, epoch: 3 | loss: 0.2507465
	speed: 0.2831s/iter; left time: 2302.5074s
	iters: 400, epoch: 3 | loss: 0.3074791
	speed: 0.2818s/iter; left time: 2264.0689s
	iters: 500, epoch: 3 | loss: 0.2267700
	speed: 0.2831s/iter; left time: 2245.4941s
	iters: 600, epoch: 3 | loss: 0.2842596
	speed: 0.2807s/iter; left time: 2198.4038s
	iters: 700, epoch: 3 | loss: 0.2682163
	speed: 0.2838s/iter; left time: 2194.7379s
	iters: 800, epoch: 3 | loss: 0.3634835
	speed: 0.2843s/iter; left time: 2170.0330s
	iters: 900, epoch: 3 | loss: 0.5903298
	speed: 0.2835s/iter; left time: 2135.7262s
	iters: 1000, epoch: 3 | loss: 0.2936852
	speed: 0.2820s/iter; left time: 2095.8441s
Epoch: 3 cost time: 298.46605825424194
Epoch: 3, Steps: 1054 | Train Loss: 0.3162123 Vali Loss: 0.2226072 Test Loss: 0.2948319
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3576453
	speed: 1.9021s/iter; left time: 13845.1948s
	iters: 200, epoch: 4 | loss: 0.1866190
	speed: 0.2457s/iter; left time: 1763.5588s
	iters: 300, epoch: 4 | loss: 0.2924110
	speed: 0.2820s/iter; left time: 1996.1965s
	iters: 400, epoch: 4 | loss: 0.4276641
	speed: 0.2823s/iter; left time: 1969.8696s
	iters: 500, epoch: 4 | loss: 0.2066076
	speed: 0.2821s/iter; left time: 1940.2939s
	iters: 600, epoch: 4 | loss: 0.2473919
	speed: 0.2820s/iter; left time: 1911.8533s
	iters: 700, epoch: 4 | loss: 0.2900204
	speed: 0.2830s/iter; left time: 1890.3635s
	iters: 800, epoch: 4 | loss: 0.3205405
	speed: 0.2813s/iter; left time: 1850.5139s
	iters: 900, epoch: 4 | loss: 0.2728044
	speed: 0.2812s/iter; left time: 1821.8874s
	iters: 1000, epoch: 4 | loss: 0.4106322
	speed: 0.2810s/iter; left time: 1792.2989s
Epoch: 4 cost time: 289.47552847862244
Epoch: 4, Steps: 1054 | Train Loss: 0.2979733 Vali Loss: 0.2259535 Test Loss: 0.3011705
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2131288
	speed: 2.0757s/iter; left time: 12921.3318s
	iters: 200, epoch: 5 | loss: 0.3719609
	speed: 0.2445s/iter; left time: 1497.7302s
	iters: 300, epoch: 5 | loss: 0.1825047
	speed: 0.2452s/iter; left time: 1477.5370s
	iters: 400, epoch: 5 | loss: 0.2516817
	speed: 0.2404s/iter; left time: 1424.5261s
	iters: 500, epoch: 5 | loss: 0.3803817
	speed: 0.2432s/iter; left time: 1416.4675s
	iters: 600, epoch: 5 | loss: 0.2364952
	speed: 0.2397s/iter; left time: 1372.5119s
	iters: 700, epoch: 5 | loss: 0.3286306
	speed: 0.2431s/iter; left time: 1367.4166s
	iters: 800, epoch: 5 | loss: 0.3069170
	speed: 0.2441s/iter; left time: 1348.4317s
	iters: 900, epoch: 5 | loss: 0.3634068
	speed: 0.2627s/iter; left time: 1425.2404s
	iters: 1000, epoch: 5 | loss: 0.3346122
	speed: 0.2827s/iter; left time: 1505.1631s
Epoch: 5 cost time: 267.45818638801575
Epoch: 5, Steps: 1054 | Train Loss: 0.2892961 Vali Loss: 0.2229382 Test Loss: 0.3031940
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_512_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.2895931005477905, mae:0.3446739614009857
Running ETTm2 with seq_len=736, pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_736_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_736_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33729
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2804423
	speed: 0.5749s/iter; left time: 6008.7089s
	iters: 200, epoch: 1 | loss: 0.2124697
	speed: 0.5716s/iter; left time: 5916.5060s
	iters: 300, epoch: 1 | loss: 0.2925324
	speed: 0.5696s/iter; left time: 5839.2604s
	iters: 400, epoch: 1 | loss: 0.2136390
	speed: 0.5723s/iter; left time: 5809.1283s
	iters: 500, epoch: 1 | loss: 0.2980092
	speed: 0.5717s/iter; left time: 5746.5531s
	iters: 600, epoch: 1 | loss: 0.2288500
	speed: 0.5726s/iter; left time: 5698.2293s
	iters: 700, epoch: 1 | loss: 0.1737891
	speed: 0.5724s/iter; left time: 5638.2469s
	iters: 800, epoch: 1 | loss: 0.3465976
	speed: 0.5723s/iter; left time: 5580.1511s
	iters: 900, epoch: 1 | loss: 0.2397336
	speed: 0.5709s/iter; left time: 5509.6711s
	iters: 1000, epoch: 1 | loss: 0.2143068
	speed: 0.5717s/iter; left time: 5460.7720s
Epoch: 1 cost time: 603.2847993373871
Epoch: 1, Steps: 1055 | Train Loss: 0.2617597 Vali Loss: 0.1288137 Test Loss: 0.1792418
Validation loss decreased (inf --> 0.128814).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2008539
	speed: 3.4328s/iter; left time: 32254.5952s
	iters: 200, epoch: 2 | loss: 0.2537043
	speed: 0.4825s/iter; left time: 4485.5466s
	iters: 300, epoch: 2 | loss: 0.1477142
	speed: 0.5076s/iter; left time: 4668.0389s
	iters: 400, epoch: 2 | loss: 0.1397730
	speed: 0.5719s/iter; left time: 5202.2012s
	iters: 500, epoch: 2 | loss: 0.1716575
	speed: 0.5722s/iter; left time: 5147.1942s
	iters: 600, epoch: 2 | loss: 0.1774874
	speed: 0.5726s/iter; left time: 5093.9736s
	iters: 700, epoch: 2 | loss: 0.1722846
	speed: 0.5721s/iter; left time: 5032.1516s
	iters: 800, epoch: 2 | loss: 0.3887875
	speed: 0.5707s/iter; left time: 4962.7761s
	iters: 900, epoch: 2 | loss: 0.1482099
	speed: 0.5408s/iter; left time: 4648.8056s
	iters: 1000, epoch: 2 | loss: 0.1421751
	speed: 0.4861s/iter; left time: 4130.0496s
Epoch: 2 cost time: 561.8166975975037
Epoch: 2, Steps: 1055 | Train Loss: 0.1993628 Vali Loss: 0.1409162 Test Loss: 0.1998806
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1082532
	speed: 3.3072s/iter; left time: 27585.5624s
	iters: 200, epoch: 3 | loss: 0.1658408
	speed: 0.5722s/iter; left time: 4715.7492s
	iters: 300, epoch: 3 | loss: 0.1806819
	speed: 0.5714s/iter; left time: 4651.4946s
	iters: 400, epoch: 3 | loss: 0.1645215
	speed: 0.4709s/iter; left time: 3786.8134s
	iters: 500, epoch: 3 | loss: 0.2760383
	speed: 0.4737s/iter; left time: 3761.5028s
	iters: 600, epoch: 3 | loss: 0.1298948
	speed: 0.5068s/iter; left time: 3973.9950s
	iters: 700, epoch: 3 | loss: 0.1444881
	speed: 0.5700s/iter; left time: 4412.7195s
	iters: 800, epoch: 3 | loss: 0.2985243
	speed: 0.5727s/iter; left time: 4376.0771s
	iters: 900, epoch: 3 | loss: 0.0989675
	speed: 0.5717s/iter; left time: 4311.3879s
	iters: 1000, epoch: 3 | loss: 0.1762397
	speed: 0.5713s/iter; left time: 4251.1906s
Epoch: 3 cost time: 576.6758210659027
Epoch: 3, Steps: 1055 | Train Loss: 0.1707856 Vali Loss: 0.1339709 Test Loss: 0.1905719
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1249085
	speed: 3.5231s/iter; left time: 25669.6113s
	iters: 200, epoch: 4 | loss: 0.1168828
	speed: 0.5704s/iter; left time: 4098.6878s
	iters: 300, epoch: 4 | loss: 0.1129399
	speed: 0.5727s/iter; left time: 4057.9784s
	iters: 400, epoch: 4 | loss: 0.1522367
	speed: 0.5715s/iter; left time: 3992.2612s
	iters: 500, epoch: 4 | loss: 0.1611604
	speed: 0.5712s/iter; left time: 3932.9449s
	iters: 600, epoch: 4 | loss: 0.1395541
	speed: 0.5643s/iter; left time: 3829.4273s
	iters: 700, epoch: 4 | loss: 0.1781033
	speed: 0.4746s/iter; left time: 3173.2669s
	iters: 800, epoch: 4 | loss: 0.1283243
	speed: 0.4767s/iter; left time: 3139.8145s
	iters: 900, epoch: 4 | loss: 0.1322038
	speed: 0.4697s/iter; left time: 3046.3682s
	iters: 1000, epoch: 4 | loss: 0.1476483
	speed: 0.4805s/iter; left time: 3068.2655s
Epoch: 4 cost time: 555.690149307251
Epoch: 4, Steps: 1055 | Train Loss: 0.1571041 Vali Loss: 0.1379485 Test Loss: 0.1916002
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_736_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.17947010695934296, mae:0.27588146924972534
Running ETTm2 with seq_len=736, pred_len=192, e_layers=3, n_heads=2, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_736_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_736_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33633
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2885760
	speed: 0.9782s/iter; left time: 2475.8210s
	iters: 200, epoch: 1 | loss: 0.2396909
	speed: 1.0404s/iter; left time: 2529.1729s
Epoch: 1 cost time: 269.6092915534973
Epoch: 1, Steps: 263 | Train Loss: 0.3339116 Vali Loss: 0.1696603 Test Loss: 0.2471068
Validation loss decreased (inf --> 0.169660).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2134519
	speed: 2.5470s/iter; left time: 5776.5922s
	iters: 200, epoch: 2 | loss: 0.2450589
	speed: 1.0692s/iter; left time: 2317.9852s
Epoch: 2 cost time: 280.4718699455261
Epoch: 2, Steps: 263 | Train Loss: 0.2560039 Vali Loss: 0.1751963 Test Loss: 0.2717032
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2475654
	speed: 2.5586s/iter; left time: 5130.0024s
	iters: 200, epoch: 3 | loss: 0.1957217
	speed: 1.0543s/iter; left time: 2008.4687s
Epoch: 3 cost time: 283.16949129104614
Epoch: 3, Steps: 263 | Train Loss: 0.2244598 Vali Loss: 0.1714850 Test Loss: 0.2590801
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2260581
	speed: 2.8135s/iter; left time: 4901.1021s
	iters: 200, epoch: 4 | loss: 0.1861671
	speed: 1.2217s/iter; left time: 2006.1079s
Epoch: 4 cost time: 319.9579038619995
Epoch: 4, Steps: 263 | Train Loss: 0.2120386 Vali Loss: 0.1713182 Test Loss: 0.2673846
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_736_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.24777169525623322, mae:0.3163936138153076
Running ETTm2 with seq_len=736, pred_len=336, e_layers=1, n_heads=4, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_736_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_736_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33489
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4913425
	speed: 0.4102s/iter; left time: 4253.8114s
	iters: 200, epoch: 1 | loss: 0.2819265
	speed: 0.4061s/iter; left time: 4170.6759s
	iters: 300, epoch: 1 | loss: 0.5287701
	speed: 0.4043s/iter; left time: 4112.2286s
	iters: 400, epoch: 1 | loss: 0.6832796
	speed: 0.4070s/iter; left time: 4099.0243s
	iters: 500, epoch: 1 | loss: 0.5161512
	speed: 0.4082s/iter; left time: 4070.1487s
	iters: 600, epoch: 1 | loss: 0.2467764
	speed: 0.4081s/iter; left time: 4028.5201s
	iters: 700, epoch: 1 | loss: 0.2538999
	speed: 0.4085s/iter; left time: 3991.1722s
	iters: 800, epoch: 1 | loss: 0.3808833
	speed: 0.4071s/iter; left time: 3937.3405s
	iters: 900, epoch: 1 | loss: 0.3204656
	speed: 0.4073s/iter; left time: 3898.0912s
	iters: 1000, epoch: 1 | loss: 0.3526006
	speed: 0.4112s/iter; left time: 3894.7266s
Epoch: 1 cost time: 426.9625358581543
Epoch: 1, Steps: 1047 | Train Loss: 0.4085621 Vali Loss: 0.2102211 Test Loss: 0.2945164
Validation loss decreased (inf --> 0.210221).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1998342
	speed: 2.9351s/iter; left time: 27367.0415s
	iters: 200, epoch: 2 | loss: 0.2536765
	speed: 0.4088s/iter; left time: 3770.8046s
	iters: 300, epoch: 2 | loss: 0.2451037
	speed: 0.4094s/iter; left time: 3735.7077s
	iters: 400, epoch: 2 | loss: 0.4031594
	speed: 0.3772s/iter; left time: 3404.0248s
	iters: 500, epoch: 2 | loss: 0.5240284
	speed: 0.3612s/iter; left time: 3223.3546s
	iters: 600, epoch: 2 | loss: 0.2940501
	speed: 0.3540s/iter; left time: 3123.4920s
	iters: 700, epoch: 2 | loss: 0.2307060
	speed: 0.3563s/iter; left time: 3108.6030s
	iters: 800, epoch: 2 | loss: 0.4638825
	speed: 0.3637s/iter; left time: 3136.3732s
	iters: 900, epoch: 2 | loss: 0.5423933
	speed: 0.4135s/iter; left time: 3525.0696s
	iters: 1000, epoch: 2 | loss: 0.3325759
	speed: 0.4132s/iter; left time: 3480.7826s
Epoch: 2 cost time: 406.17714262008667
Epoch: 2, Steps: 1047 | Train Loss: 0.3275195 Vali Loss: 0.2122167 Test Loss: 0.3075350
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3656974
	speed: 2.7690s/iter; left time: 22918.9704s
	iters: 200, epoch: 3 | loss: 0.2587556
	speed: 0.3632s/iter; left time: 2970.0281s
	iters: 300, epoch: 3 | loss: 0.3986994
	speed: 0.3670s/iter; left time: 2964.2062s
	iters: 400, epoch: 3 | loss: 0.2871535
	speed: 0.3860s/iter; left time: 3078.7693s
	iters: 500, epoch: 3 | loss: 0.1554786
	speed: 0.4069s/iter; left time: 3205.0983s
	iters: 600, epoch: 3 | loss: 0.3658624
	speed: 0.4061s/iter; left time: 3158.2474s
	iters: 700, epoch: 3 | loss: 0.3429562
	speed: 0.4101s/iter; left time: 3148.2041s
	iters: 800, epoch: 3 | loss: 0.1850796
	speed: 0.4096s/iter; left time: 3103.7077s
	iters: 900, epoch: 3 | loss: 0.2637879
	speed: 0.4110s/iter; left time: 3073.1491s
	iters: 1000, epoch: 3 | loss: 0.3737769
	speed: 0.4085s/iter; left time: 3013.4015s
Epoch: 3 cost time: 412.24360179901123
Epoch: 3, Steps: 1047 | Train Loss: 0.2897948 Vali Loss: 0.2140622 Test Loss: 0.3127443
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2640316
	speed: 2.9350s/iter; left time: 21220.1335s
	iters: 200, epoch: 4 | loss: 0.3197465
	speed: 0.4070s/iter; left time: 2902.2648s
	iters: 300, epoch: 4 | loss: 0.2434494
	speed: 0.4073s/iter; left time: 2863.4556s
	iters: 400, epoch: 4 | loss: 0.2578313
	speed: 0.4089s/iter; left time: 2833.5626s
	iters: 500, epoch: 4 | loss: 0.3811491
	speed: 0.4082s/iter; left time: 2787.8793s
	iters: 600, epoch: 4 | loss: 0.2780039
	speed: 0.3747s/iter; left time: 2521.8913s
	iters: 700, epoch: 4 | loss: 0.2447865
	speed: 0.3503s/iter; left time: 2322.7510s
	iters: 800, epoch: 4 | loss: 0.3807397
	speed: 0.3589s/iter; left time: 2343.9309s
	iters: 900, epoch: 4 | loss: 0.3808548
	speed: 0.3624s/iter; left time: 2330.1459s
	iters: 1000, epoch: 4 | loss: 0.2305297
	speed: 0.3553s/iter; left time: 2248.9977s
Epoch: 4 cost time: 403.0607707500458
Epoch: 4, Steps: 1047 | Train Loss: 0.2722125 Vali Loss: 0.2214480 Test Loss: 0.3153804
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_736_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.2947481572628021, mae:0.34618067741394043
Running ETTm2 with seq_len=736, pred_len=720, e_layers=3, n_heads=4, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_736_720       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_736_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33105
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4588514
	speed: 1.2972s/iter; left time: 3231.3302s
	iters: 200, epoch: 1 | loss: 0.4145327
	speed: 1.2135s/iter; left time: 2901.4592s
Epoch: 1 cost time: 319.29339599609375
Epoch: 1, Steps: 259 | Train Loss: 0.4901018 Vali Loss: 0.3104817 Test Loss: 0.4119643
Validation loss decreased (inf --> 0.310482).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3491682
	speed: 2.7938s/iter; left time: 6235.6783s
	iters: 200, epoch: 2 | loss: 0.4205554
	speed: 1.1589s/iter; left time: 2470.8245s
Epoch: 2 cost time: 300.10040974617004
Epoch: 2, Steps: 259 | Train Loss: 0.3877526 Vali Loss: 0.3149577 Test Loss: 0.4499914
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3555293
	speed: 2.7949s/iter; left time: 5514.3300s
	iters: 200, epoch: 3 | loss: 0.2984791
	speed: 1.1146s/iter; left time: 2087.6546s
Epoch: 3 cost time: 288.46413564682007
Epoch: 3, Steps: 259 | Train Loss: 0.3427317 Vali Loss: 0.3181306 Test Loss: 0.4486960
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2844226
	speed: 2.4294s/iter; left time: 4164.0316s
	iters: 200, epoch: 4 | loss: 0.2776231
	speed: 1.0485s/iter; left time: 1692.2254s
Epoch: 4 cost time: 273.8879110813141
Epoch: 4, Steps: 259 | Train Loss: 0.3190186 Vali Loss: 0.3228453 Test Loss: 0.4447429
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_736_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.40945786237716675, mae:0.41704273223876953
Running ETTm2 with seq_len=1024, pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_1024_96       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_1024_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33441
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1919012
	speed: 0.8159s/iter; left time: 8453.7634s
	iters: 200, epoch: 1 | loss: 0.3304418
	speed: 0.8128s/iter; left time: 8340.3084s
	iters: 300, epoch: 1 | loss: 0.2736725
	speed: 0.8130s/iter; left time: 8260.5413s
	iters: 400, epoch: 1 | loss: 0.4611795
	speed: 0.8141s/iter; left time: 8191.0874s
	iters: 500, epoch: 1 | loss: 0.3975122
	speed: 0.8127s/iter; left time: 8095.0822s
	iters: 600, epoch: 1 | loss: 0.2480924
	speed: 0.8144s/iter; left time: 8030.4818s
	iters: 700, epoch: 1 | loss: 0.2139502
	speed: 0.8141s/iter; left time: 7946.8243s
	iters: 800, epoch: 1 | loss: 0.1977320
	speed: 0.8150s/iter; left time: 7874.0608s
	iters: 900, epoch: 1 | loss: 0.2134227
	speed: 0.8144s/iter; left time: 7786.2739s
	iters: 1000, epoch: 1 | loss: 0.1452359
	speed: 0.8131s/iter; left time: 7692.5943s
Epoch: 1 cost time: 851.3934926986694
Epoch: 1, Steps: 1046 | Train Loss: 0.2753695 Vali Loss: 0.1381076 Test Loss: 0.2087834
Validation loss decreased (inf --> 0.138108).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1144770
	speed: 4.7348s/iter; left time: 44104.7450s
	iters: 200, epoch: 2 | loss: 0.1917866
	speed: 0.8135s/iter; left time: 7496.6338s
	iters: 300, epoch: 2 | loss: 0.2634373
	speed: 0.8134s/iter; left time: 7414.2579s
	iters: 400, epoch: 2 | loss: 0.2254350
	speed: 0.8146s/iter; left time: 7343.2256s
	iters: 500, epoch: 2 | loss: 0.1734259
	speed: 0.8163s/iter; left time: 7277.0635s
	iters: 600, epoch: 2 | loss: 0.1990271
	speed: 0.8166s/iter; left time: 7198.3389s
	iters: 700, epoch: 2 | loss: 0.1190036
	speed: 0.8164s/iter; left time: 7114.9337s
	iters: 800, epoch: 2 | loss: 0.1752315
	speed: 0.8163s/iter; left time: 7032.3129s
	iters: 900, epoch: 2 | loss: 0.2486186
	speed: 0.8136s/iter; left time: 6928.1562s
	iters: 1000, epoch: 2 | loss: 0.1266700
	speed: 0.8138s/iter; left time: 6847.7737s
Epoch: 2 cost time: 852.0899510383606
Epoch: 2, Steps: 1046 | Train Loss: 0.2004374 Vali Loss: 0.1678284 Test Loss: 0.2317923
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2438598
	speed: 4.4476s/iter; left time: 36777.1677s
	iters: 200, epoch: 3 | loss: 0.2289618
	speed: 0.6168s/iter; left time: 5038.9635s
	iters: 300, epoch: 3 | loss: 0.1754831
	speed: 0.7715s/iter; left time: 6225.3717s
	iters: 400, epoch: 3 | loss: 0.1883944
	speed: 0.8144s/iter; left time: 6489.9591s
	iters: 500, epoch: 3 | loss: 0.1736389
	speed: 0.8153s/iter; left time: 6415.2126s
	iters: 600, epoch: 3 | loss: 0.2008369
	speed: 0.8161s/iter; left time: 6340.1294s
	iters: 700, epoch: 3 | loss: 0.1805258
	speed: 0.8157s/iter; left time: 6255.2983s
	iters: 800, epoch: 3 | loss: 0.1944731
	speed: 0.8148s/iter; left time: 6167.3726s
	iters: 900, epoch: 3 | loss: 0.1752672
	speed: 0.8129s/iter; left time: 6071.5613s
	iters: 1000, epoch: 3 | loss: 0.1856892
	speed: 0.8159s/iter; left time: 6012.2591s
Epoch: 3 cost time: 801.5609662532806
Epoch: 3, Steps: 1046 | Train Loss: 0.1710677 Vali Loss: 0.1639566 Test Loss: 0.2238908
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1847803
	speed: 4.9676s/iter; left time: 35880.7177s
	iters: 200, epoch: 4 | loss: 0.1782883
	speed: 0.8146s/iter; left time: 5802.3688s
	iters: 300, epoch: 4 | loss: 0.1761256
	speed: 0.8122s/iter; left time: 5704.1629s
	iters: 400, epoch: 4 | loss: 0.2408940
	speed: 0.7802s/iter; left time: 5401.2433s
	iters: 500, epoch: 4 | loss: 0.1218444
	speed: 0.7118s/iter; left time: 4856.5454s
	iters: 600, epoch: 4 | loss: 0.1547468
	speed: 0.7206s/iter; left time: 4844.6256s
	iters: 700, epoch: 4 | loss: 0.1097348
	speed: 0.7959s/iter; left time: 5271.5430s
	iters: 800, epoch: 4 | loss: 0.1481317
	speed: 0.8152s/iter; left time: 5317.8089s
	iters: 900, epoch: 4 | loss: 0.1197116
	speed: 0.8124s/iter; left time: 5217.8299s
	iters: 1000, epoch: 4 | loss: 0.1084993
	speed: 0.8138s/iter; left time: 5145.5408s
Epoch: 4 cost time: 826.3813560009003
Epoch: 4, Steps: 1046 | Train Loss: 0.1671369 Vali Loss: 0.1339047 Test Loss: 0.1884558
Validation loss decreased (0.138108 --> 0.133905).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1006305
	speed: 4.9641s/iter; left time: 30663.4187s
	iters: 200, epoch: 5 | loss: 0.2336017
	speed: 0.7704s/iter; left time: 4682.0045s
	iters: 300, epoch: 5 | loss: 0.2242656
	speed: 0.7104s/iter; left time: 4245.8667s
	iters: 400, epoch: 5 | loss: 0.1220072
	speed: 0.7094s/iter; left time: 4168.9725s
	iters: 500, epoch: 5 | loss: 0.1556411
	speed: 0.7099s/iter; left time: 4100.9059s
	iters: 600, epoch: 5 | loss: 0.1085566
	speed: 0.7652s/iter; left time: 4343.9554s
	iters: 700, epoch: 5 | loss: 0.1321873
	speed: 0.8172s/iter; left time: 4557.2827s
	iters: 800, epoch: 5 | loss: 0.1860228
	speed: 0.7577s/iter; left time: 4149.8597s
	iters: 900, epoch: 5 | loss: 0.1318170
	speed: 0.7125s/iter; left time: 3830.8692s
	iters: 1000, epoch: 5 | loss: 0.1569767
	speed: 0.7249s/iter; left time: 3825.2140s
Epoch: 5 cost time: 786.2259232997894
Epoch: 5, Steps: 1046 | Train Loss: 0.1506450 Vali Loss: 0.1320259 Test Loss: 0.1901065
Validation loss decreased (0.133905 --> 0.132026).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1017017
	speed: 4.9557s/iter; left time: 25427.7984s
	iters: 200, epoch: 6 | loss: 0.1546724
	speed: 0.8147s/iter; left time: 4098.9029s
	iters: 300, epoch: 6 | loss: 0.1271315
	speed: 0.8146s/iter; left time: 4016.8649s
	iters: 400, epoch: 6 | loss: 0.1780662
	speed: 0.8144s/iter; left time: 3934.3220s
	iters: 500, epoch: 6 | loss: 0.1104934
	speed: 0.8148s/iter; left time: 3854.5834s
	iters: 600, epoch: 6 | loss: 0.1089683
	speed: 0.8143s/iter; left time: 3770.8996s
	iters: 700, epoch: 6 | loss: 0.1466852
	speed: 0.8173s/iter; left time: 3703.0090s
	iters: 800, epoch: 6 | loss: 0.1950721
	speed: 0.8148s/iter; left time: 3610.2635s
	iters: 900, epoch: 6 | loss: 0.1196207
	speed: 0.8127s/iter; left time: 3519.8404s
	iters: 1000, epoch: 6 | loss: 0.1238220
	speed: 0.8143s/iter; left time: 3445.2412s
Epoch: 6 cost time: 851.6068799495697
Epoch: 6, Steps: 1046 | Train Loss: 0.1504902 Vali Loss: 0.1363550 Test Loss: 0.1969391
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1617494
	speed: 4.7187s/iter; left time: 19275.9762s
	iters: 200, epoch: 7 | loss: 0.2035214
	speed: 0.8137s/iter; left time: 3242.5690s
	iters: 300, epoch: 7 | loss: 0.1064438
	speed: 0.8133s/iter; left time: 3159.6951s
	iters: 400, epoch: 7 | loss: 0.1300946
	speed: 0.8128s/iter; left time: 3076.3563s
	iters: 500, epoch: 7 | loss: 0.2182693
	speed: 0.8146s/iter; left time: 3001.7572s
	iters: 600, epoch: 7 | loss: 0.1953817
	speed: 0.7618s/iter; left time: 2731.0877s
	iters: 700, epoch: 7 | loss: 0.1192963
	speed: 0.7142s/iter; left time: 2489.1123s
	iters: 800, epoch: 7 | loss: 0.1826945
	speed: 0.7156s/iter; left time: 2422.3236s
	iters: 900, epoch: 7 | loss: 0.1174770
	speed: 0.7156s/iter; left time: 2350.6326s
	iters: 1000, epoch: 7 | loss: 0.1358634
	speed: 0.7834s/iter; left time: 2495.2106s
Epoch: 7 cost time: 813.1803419589996
Epoch: 7, Steps: 1046 | Train Loss: 0.1457767 Vali Loss: 0.1327944 Test Loss: 0.1910432
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1714692
	speed: 4.8050s/iter; left time: 14602.3620s
	iters: 200, epoch: 8 | loss: 0.1307535
	speed: 0.7118s/iter; left time: 2092.1119s
	iters: 300, epoch: 8 | loss: 0.1205289
	speed: 0.7055s/iter; left time: 2002.9380s
	iters: 400, epoch: 8 | loss: 0.1428048
	speed: 0.6399s/iter; left time: 1752.6344s
	iters: 500, epoch: 8 | loss: 0.1307702
	speed: 0.8103s/iter; left time: 2138.2804s
	iters: 600, epoch: 8 | loss: 0.1012911
	speed: 0.8115s/iter; left time: 2060.4251s
	iters: 700, epoch: 8 | loss: 0.1201937
	speed: 0.8100s/iter; left time: 1975.5365s
	iters: 800, epoch: 8 | loss: 0.1395937
	speed: 0.8080s/iter; left time: 1889.9264s
	iters: 900, epoch: 8 | loss: 0.1508337
	speed: 0.8100s/iter; left time: 1813.6867s
	iters: 1000, epoch: 8 | loss: 0.0934941
	speed: 0.8105s/iter; left time: 1733.6233s
Epoch: 8 cost time: 799.9962327480316
Epoch: 8, Steps: 1046 | Train Loss: 0.1438291 Vali Loss: 0.1322648 Test Loss: 0.1900033
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_1024_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.1900583654642105, mae:0.28249305486679077
Running ETTm2 with seq_len=1024, pred_len=192, e_layers=3, n_heads=2, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_1024_192      Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_1024_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33345
val 11329
test 11329
Traceback (most recent call last):
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/run.py", line 138, in <module>
    exp.train(setting)
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/exp/exp_AGPT.py", line 131, in train
    outputs, aux_loss = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/models/AGPT_loss_G.py", line 226, in forward
    dec_out, budget_loss = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/models/AGPT_loss_G.py", line 202, in forecast
    enc_out, attns = self.encoder(enc_out)
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/layers/Transformer_EncDec.py", line 74, in forward
    x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/layers/Transformer_EncDec.py", line 48, in forward
    y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 904.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 844.56 MiB is free. Process 1382320 has 46.61 GiB memory in use. Process 2784764 has 19.77 GiB memory in use. Process 2887374 has 11.93 GiB memory in use. Of the allocated memory 11.36 GiB is allocated by PyTorch, and 86.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running ETTm2 with seq_len=1024, pred_len=336, e_layers=1, n_heads=4, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_1024_336      Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_1024_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33201
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.7081850
	speed: 0.5527s/iter; left time: 5682.7505s
	iters: 200, epoch: 1 | loss: 0.3935907
	speed: 0.4861s/iter; left time: 4949.4558s
	iters: 300, epoch: 1 | loss: 0.2941576
	speed: 0.4675s/iter; left time: 4712.4014s
	iters: 400, epoch: 1 | loss: 0.5806737
	speed: 0.4756s/iter; left time: 4747.1662s
	iters: 500, epoch: 1 | loss: 0.2488091
	speed: 0.4934s/iter; left time: 4875.5798s
	iters: 600, epoch: 1 | loss: 0.2990519
	speed: 0.5477s/iter; left time: 5356.8876s
	iters: 700, epoch: 1 | loss: 0.2878466
	speed: 0.5449s/iter; left time: 5274.9201s
	iters: 800, epoch: 1 | loss: 0.2406672
	speed: 0.5463s/iter; left time: 5234.5222s
	iters: 900, epoch: 1 | loss: 0.4188097
	speed: 0.5249s/iter; left time: 4976.4635s
	iters: 1000, epoch: 1 | loss: 0.3451748
	speed: 0.4752s/iter; left time: 4458.0223s
Epoch: 1 cost time: 529.4370551109314
Epoch: 1, Steps: 1038 | Train Loss: 0.4162233 Vali Loss: 0.2141268 Test Loss: 0.2966470
Validation loss decreased (inf --> 0.214127).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3823133
	speed: 3.6455s/iter; left time: 33695.7684s
	iters: 200, epoch: 2 | loss: 0.2353470
	speed: 0.5461s/iter; left time: 4993.3608s
	iters: 300, epoch: 2 | loss: 0.2999454
	speed: 0.5445s/iter; left time: 4924.2778s
	iters: 400, epoch: 2 | loss: 0.2454876
	speed: 0.5465s/iter; left time: 4887.3223s
	iters: 500, epoch: 2 | loss: 0.2751732
	speed: 0.5456s/iter; left time: 4824.3269s
	iters: 600, epoch: 2 | loss: 0.3368818
	speed: 0.5455s/iter; left time: 4769.7131s
	iters: 700, epoch: 2 | loss: 0.3008746
	speed: 0.5472s/iter; left time: 4729.6287s
	iters: 800, epoch: 2 | loss: 0.1913322
	speed: 0.5457s/iter; left time: 4662.0900s
	iters: 900, epoch: 2 | loss: 0.4091234
	speed: 0.5422s/iter; left time: 4577.4416s
	iters: 1000, epoch: 2 | loss: 0.3270823
	speed: 0.4773s/iter; left time: 3981.8563s
Epoch: 2 cost time: 556.6015267372131
Epoch: 2, Steps: 1038 | Train Loss: 0.3194234 Vali Loss: 0.2255330 Test Loss: 0.3067687
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3998974
	speed: 3.7575s/iter; left time: 30830.4219s
	iters: 200, epoch: 3 | loss: 0.4314725
	speed: 0.5454s/iter; left time: 4420.4640s
	iters: 300, epoch: 3 | loss: 0.2551143
	speed: 0.5458s/iter; left time: 4369.2069s
	iters: 400, epoch: 3 | loss: 0.2455773
	speed: 0.5465s/iter; left time: 4320.0852s
	iters: 500, epoch: 3 | loss: 0.2323438
	speed: 0.5453s/iter; left time: 4256.3051s
	iters: 600, epoch: 3 | loss: 0.2698006
	speed: 0.5450s/iter; left time: 4198.9090s
	iters: 700, epoch: 3 | loss: 0.3745604
	speed: 0.5454s/iter; left time: 4147.9378s
	iters: 800, epoch: 3 | loss: 0.4455601
	speed: 0.5469s/iter; left time: 4104.3583s
	iters: 900, epoch: 3 | loss: 0.1742871
	speed: 0.5488s/iter; left time: 4063.6948s
	iters: 1000, epoch: 3 | loss: 0.2354732
	speed: 0.5469s/iter; left time: 3995.0771s
Epoch: 3 cost time: 567.193794965744
Epoch: 3, Steps: 1038 | Train Loss: 0.2867007 Vali Loss: 0.2275228 Test Loss: 0.3145734
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3166282
	speed: 3.8829s/iter; left time: 27828.4181s
	iters: 200, epoch: 4 | loss: 0.2130197
	speed: 0.4683s/iter; left time: 3309.5853s
	iters: 300, epoch: 4 | loss: 0.2837030
	speed: 0.4788s/iter; left time: 3335.5063s
	iters: 400, epoch: 4 | loss: 0.2087665
	speed: 0.5038s/iter; left time: 3459.3319s
	iters: 500, epoch: 4 | loss: 0.4116536
	speed: 0.5454s/iter; left time: 3690.4802s
	iters: 600, epoch: 4 | loss: 0.2491751
	speed: 0.5461s/iter; left time: 3640.7294s
	iters: 700, epoch: 4 | loss: 0.3708856
	speed: 0.5058s/iter; left time: 3321.7434s
	iters: 800, epoch: 4 | loss: 0.2667907
	speed: 0.4797s/iter; left time: 3102.3386s
	iters: 900, epoch: 4 | loss: 0.1951845
	speed: 0.4783s/iter; left time: 3045.2576s
	iters: 1000, epoch: 4 | loss: 0.3611020
	speed: 0.4790s/iter; left time: 3001.6768s
Epoch: 4 cost time: 514.6179151535034
Epoch: 4, Steps: 1038 | Train Loss: 0.2662408 Vali Loss: 0.2383818 Test Loss: 0.3156420
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_1024_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.296720027923584, mae:0.3540992736816406
Running ETTm2 with seq_len=1024, pred_len=720, e_layers=3, n_heads=4, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_1024_720      Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_1024_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32817
val 10801
test 10801
Traceback (most recent call last):
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/run.py", line 138, in <module>
    exp.train(setting)
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/exp/exp_AGPT.py", line 131, in train
    outputs, aux_loss = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/models/AGPT_loss_G.py", line 226, in forward
    dec_out, budget_loss = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/models/AGPT_loss_G.py", line 202, in forecast
    enc_out, attns = self.encoder(enc_out)
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/layers/Transformer_EncDec.py", line 74, in forward
    x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/pfs/zitao_team/kuiyeding/AGPT/layers/Transformer_EncDec.py", line 48, in forward
    y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py", line 308, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py", line 304, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 904.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 366.56 MiB is free. Process 1382320 has 46.61 GiB memory in use. Process 2784764 has 20.02 GiB memory in use. Process 3203504 has 12.15 GiB memory in use. Of the allocated memory 11.58 GiB is allocated by PyTorch, and 77.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
