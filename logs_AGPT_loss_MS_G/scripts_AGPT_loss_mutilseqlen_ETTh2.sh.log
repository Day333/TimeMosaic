Running ETTh2 with seq_len=96, pred_len=96...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_96         Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3054337
	speed: 0.0389s/iter; left time: 99.3532s
	iters: 200, epoch: 1 | loss: 0.3655540
	speed: 0.0482s/iter; left time: 118.1745s
Epoch: 1 cost time: 13.18919825553894
Epoch: 1, Steps: 265 | Train Loss: 0.4616092 Vali Loss: 0.2236956 Test Loss: 0.3092421
Validation loss decreased (inf --> 0.223696).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5676401
	speed: 0.1925s/iter; left time: 440.1679s
	iters: 200, epoch: 2 | loss: 0.3679957
	speed: 0.0673s/iter; left time: 147.1807s
Epoch: 2 cost time: 17.90050983428955
Epoch: 2, Steps: 265 | Train Loss: 0.4214157 Vali Loss: 0.2281266 Test Loss: 0.2927909
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1984069
	speed: 0.1888s/iter; left time: 381.5280s
	iters: 200, epoch: 3 | loss: 0.3716423
	speed: 0.0661s/iter; left time: 127.0140s
Epoch: 3 cost time: 17.831361293792725
Epoch: 3, Steps: 265 | Train Loss: 0.3818867 Vali Loss: 0.2245622 Test Loss: 0.2990732
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3602787
	speed: 0.1806s/iter; left time: 317.1415s
	iters: 200, epoch: 4 | loss: 0.3599055
	speed: 0.0584s/iter; left time: 96.6318s
Epoch: 4 cost time: 16.194624662399292
Epoch: 4, Steps: 265 | Train Loss: 0.3604860 Vali Loss: 0.2307258 Test Loss: 0.3013305
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.31115368008613586, mae:0.3560003340244293
Running ETTh2 with seq_len=96, pred_len=192...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_192        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.7692388
	speed: 0.0732s/iter; left time: 184.4617s
	iters: 200, epoch: 1 | loss: 0.3888977
	speed: 0.0665s/iter; left time: 161.0307s
Epoch: 1 cost time: 17.9885675907135
Epoch: 1, Steps: 262 | Train Loss: 0.5690136 Vali Loss: 0.2802192 Test Loss: 0.3833923
Validation loss decreased (inf --> 0.280219).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4250091
	speed: 0.1931s/iter; left time: 436.1987s
	iters: 200, epoch: 2 | loss: 0.4095716
	speed: 0.0649s/iter; left time: 140.1212s
Epoch: 2 cost time: 17.444007635116577
Epoch: 2, Steps: 262 | Train Loss: 0.5411279 Vali Loss: 0.2835674 Test Loss: 0.3805263
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5394662
	speed: 0.1913s/iter; left time: 381.9465s
	iters: 200, epoch: 3 | loss: 0.5909851
	speed: 0.0589s/iter; left time: 111.7984s
Epoch: 3 cost time: 16.485018968582153
Epoch: 3, Steps: 262 | Train Loss: 0.5018582 Vali Loss: 0.2857907 Test Loss: 0.3733740
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6224002
	speed: 0.1768s/iter; left time: 306.7330s
	iters: 200, epoch: 4 | loss: 0.8134804
	speed: 0.0630s/iter; left time: 102.9870s
Epoch: 4 cost time: 16.63052487373352
Epoch: 4, Steps: 262 | Train Loss: 0.4781303 Vali Loss: 0.2933428 Test Loss: 0.3800306
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.37666743993759155, mae:0.39670151472091675
Running ETTh2 with seq_len=96, pred_len=336...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_336        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5828817
	speed: 0.0743s/iter; left time: 183.7047s
	iters: 200, epoch: 1 | loss: 0.2999434
	speed: 0.0688s/iter; left time: 163.1250s
Epoch: 1 cost time: 18.274452447891235
Epoch: 1, Steps: 257 | Train Loss: 0.6784418 Vali Loss: 0.3608352 Test Loss: 0.4245884
Validation loss decreased (inf --> 0.360835).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4952371
	speed: 0.2003s/iter; left time: 443.3602s
	iters: 200, epoch: 2 | loss: 0.3996096
	speed: 0.0699s/iter; left time: 147.7844s
Epoch: 2 cost time: 17.92256259918213
Epoch: 2, Steps: 257 | Train Loss: 0.6486158 Vali Loss: 0.3788695 Test Loss: 0.4160174
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9167013
	speed: 0.1942s/iter; left time: 379.9984s
	iters: 200, epoch: 3 | loss: 0.5953271
	speed: 0.0671s/iter; left time: 124.6141s
Epoch: 3 cost time: 17.511597394943237
Epoch: 3, Steps: 257 | Train Loss: 0.6171665 Vali Loss: 0.3706104 Test Loss: 0.4260883
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9479745
	speed: 0.2053s/iter; left time: 348.9898s
	iters: 200, epoch: 4 | loss: 0.4912427
	speed: 0.0731s/iter; left time: 116.9551s
Epoch: 4 cost time: 18.684932231903076
Epoch: 4, Steps: 257 | Train Loss: 0.5925007 Vali Loss: 0.3743877 Test Loss: 0.4206892
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.42048266530036926, mae:0.4294712245464325
Running ETTh2 with seq_len=96, pred_len=720...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_96_720        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_96_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 1.1191144
	speed: 0.0788s/iter; left time: 185.2068s
	iters: 200, epoch: 1 | loss: 1.1313127
	speed: 0.0685s/iter; left time: 154.1044s
Epoch: 1 cost time: 18.006266832351685
Epoch: 1, Steps: 245 | Train Loss: 0.8733552 Vali Loss: 0.5804017 Test Loss: 0.4476654
Validation loss decreased (inf --> 0.580402).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7400860
	speed: 0.1821s/iter; left time: 383.5757s
	iters: 200, epoch: 2 | loss: 0.7947627
	speed: 0.0641s/iter; left time: 128.5136s
Epoch: 2 cost time: 16.212237119674683
Epoch: 2, Steps: 245 | Train Loss: 0.8451942 Vali Loss: 0.5931705 Test Loss: 0.4515487
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6433992
	speed: 0.1815s/iter; left time: 337.8427s
	iters: 200, epoch: 3 | loss: 0.8617612
	speed: 0.0663s/iter; left time: 116.7158s
Epoch: 3 cost time: 16.41664433479309
Epoch: 3, Steps: 245 | Train Loss: 0.8158997 Vali Loss: 0.6055910 Test Loss: 0.4315406
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7176242
	speed: 0.1853s/iter; left time: 299.3884s
	iters: 200, epoch: 4 | loss: 0.8266971
	speed: 0.0697s/iter; left time: 105.6558s
Epoch: 4 cost time: 17.346983432769775
Epoch: 4, Steps: 245 | Train Loss: 0.7936142 Vali Loss: 0.6267856 Test Loss: 0.4419144
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_96_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.44598087668418884, mae:0.45800331234931946
Running ETTh2 with seq_len=192, pred_len=96...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_192_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_192_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3306645
	speed: 0.1110s/iter; left time: 279.8712s
	iters: 200, epoch: 1 | loss: 0.2385516
	speed: 0.0971s/iter; left time: 235.1794s
Epoch: 1 cost time: 27.401936054229736
Epoch: 1, Steps: 262 | Train Loss: 0.4559489 Vali Loss: 0.2315734 Test Loss: 0.3194770
Validation loss decreased (inf --> 0.231573).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2565319
	speed: 0.3054s/iter; left time: 689.7870s
	iters: 200, epoch: 2 | loss: 0.2592487
	speed: 0.1363s/iter; left time: 294.3703s
Epoch: 2 cost time: 33.471872329711914
Epoch: 2, Steps: 262 | Train Loss: 0.3974042 Vali Loss: 0.2256615 Test Loss: 0.3256887
Validation loss decreased (0.231573 --> 0.225662).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3126038
	speed: 0.2784s/iter; left time: 555.9713s
	iters: 200, epoch: 3 | loss: 0.5201864
	speed: 0.0519s/iter; left time: 98.3898s
Epoch: 3 cost time: 14.438592672348022
Epoch: 3, Steps: 262 | Train Loss: 0.3504287 Vali Loss: 0.2281094 Test Loss: 0.3006425
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4838933
	speed: 0.1741s/iter; left time: 302.0683s
	iters: 200, epoch: 4 | loss: 0.5002273
	speed: 0.0996s/iter; left time: 162.8406s
Epoch: 4 cost time: 21.64143943786621
Epoch: 4, Steps: 262 | Train Loss: 0.3242287 Vali Loss: 0.2297555 Test Loss: 0.3151434
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3323129
	speed: 0.2420s/iter; left time: 356.4833s
	iters: 200, epoch: 5 | loss: 0.2158315
	speed: 0.0573s/iter; left time: 78.6849s
Epoch: 5 cost time: 18.275880098342896
Epoch: 5, Steps: 262 | Train Loss: 0.3213195 Vali Loss: 0.2214219 Test Loss: 0.3115346
Validation loss decreased (0.225662 --> 0.221422).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3538522
	speed: 0.1729s/iter; left time: 209.3366s
	iters: 200, epoch: 6 | loss: 0.3612427
	speed: 0.0556s/iter; left time: 61.7259s
Epoch: 6 cost time: 16.338618516921997
Epoch: 6, Steps: 262 | Train Loss: 0.3081153 Vali Loss: 0.2211413 Test Loss: 0.3117335
Validation loss decreased (0.221422 --> 0.221141).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2704422
	speed: 0.2515s/iter; left time: 238.6587s
	iters: 200, epoch: 7 | loss: 0.3312494
	speed: 0.0794s/iter; left time: 67.3769s
Epoch: 7 cost time: 20.725402355194092
Epoch: 7, Steps: 262 | Train Loss: 0.3035865 Vali Loss: 0.2210262 Test Loss: 0.3122821
Validation loss decreased (0.221141 --> 0.221026).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2725748
	speed: 0.1782s/iter; left time: 122.4026s
	iters: 200, epoch: 8 | loss: 0.1980767
	speed: 0.0512s/iter; left time: 30.0369s
Epoch: 8 cost time: 13.94991660118103
Epoch: 8, Steps: 262 | Train Loss: 0.3018467 Vali Loss: 0.2228476 Test Loss: 0.3137809
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2141185
	speed: 0.2158s/iter; left time: 91.7193s
	iters: 200, epoch: 9 | loss: 0.3325252
	speed: 0.0836s/iter; left time: 27.1548s
Epoch: 9 cost time: 23.032674312591553
Epoch: 9, Steps: 262 | Train Loss: 0.3001362 Vali Loss: 0.2266974 Test Loss: 0.3144565
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2389584
	speed: 0.3066s/iter; left time: 49.9825s
	iters: 200, epoch: 10 | loss: 0.3127189
	speed: 0.1067s/iter; left time: 6.7190s
Epoch: 10 cost time: 29.359291076660156
Epoch: 10, Steps: 262 | Train Loss: 0.3003280 Vali Loss: 0.2215055 Test Loss: 0.3130808
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_192_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.3141796290874481, mae:0.3597542643547058
Running ETTh2 with seq_len=192, pred_len=192...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_192_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_192_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8257
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.4509611
	speed: 0.1110s/iter; left time: 276.5295s
	iters: 200, epoch: 1 | loss: 0.4556409
	speed: 0.1089s/iter; left time: 260.3608s
Epoch: 1 cost time: 28.533986568450928
Epoch: 1, Steps: 259 | Train Loss: 0.5523397 Vali Loss: 0.2805867 Test Loss: 0.3652696
Validation loss decreased (inf --> 0.280587).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2738411
	speed: 0.3738s/iter; left time: 834.2960s
	iters: 200, epoch: 2 | loss: 0.4933973
	speed: 0.1133s/iter; left time: 241.6573s
Epoch: 2 cost time: 28.12405824661255
Epoch: 2, Steps: 259 | Train Loss: 0.5002443 Vali Loss: 0.2749116 Test Loss: 0.3643116
Validation loss decreased (0.280587 --> 0.274912).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4714302
	speed: 0.3419s/iter; left time: 674.5515s
	iters: 200, epoch: 3 | loss: 0.5922831
	speed: 0.1058s/iter; left time: 198.1890s
Epoch: 3 cost time: 27.62994909286499
Epoch: 3, Steps: 259 | Train Loss: 0.4494375 Vali Loss: 0.2866660 Test Loss: 0.4030086
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2606226
	speed: 0.3188s/iter; left time: 546.4425s
	iters: 200, epoch: 4 | loss: 0.4621681
	speed: 0.1035s/iter; left time: 167.1186s
Epoch: 4 cost time: 27.71881103515625
Epoch: 4, Steps: 259 | Train Loss: 0.4215515 Vali Loss: 0.2824564 Test Loss: 0.3951676
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4882343
	speed: 0.3170s/iter; left time: 461.1673s
	iters: 200, epoch: 5 | loss: 0.3960376
	speed: 0.1068s/iter; left time: 144.7711s
Epoch: 5 cost time: 27.933921575546265
Epoch: 5, Steps: 259 | Train Loss: 0.4079193 Vali Loss: 0.2875557 Test Loss: 0.3896386
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_192_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.35969802737236023, mae:0.39402398467063904
Running ETTh2 with seq_len=192, pred_len=336...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_192_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_192_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.4189703
	speed: 0.1209s/iter; left time: 295.2201s
	iters: 200, epoch: 1 | loss: 0.6642978
	speed: 0.1185s/iter; left time: 277.3259s
Epoch: 1 cost time: 30.732020616531372
Epoch: 1, Steps: 254 | Train Loss: 0.6454593 Vali Loss: 0.3938626 Test Loss: 0.3900013
Validation loss decreased (inf --> 0.393863).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5071492
	speed: 0.3773s/iter; left time: 825.1144s
	iters: 200, epoch: 2 | loss: 0.4575782
	speed: 0.1275s/iter; left time: 266.0662s
Epoch: 2 cost time: 31.577090978622437
Epoch: 2, Steps: 254 | Train Loss: 0.5983837 Vali Loss: 0.3776389 Test Loss: 0.4170912
Validation loss decreased (0.393863 --> 0.377639).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6279669
	speed: 0.3851s/iter; left time: 744.3318s
	iters: 200, epoch: 3 | loss: 0.3342367
	speed: 0.1118s/iter; left time: 204.9585s
Epoch: 3 cost time: 28.96764039993286
Epoch: 3, Steps: 254 | Train Loss: 0.5519943 Vali Loss: 0.3733526 Test Loss: 0.4156261
Validation loss decreased (0.377639 --> 0.373353).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3680083
	speed: 0.3221s/iter; left time: 540.8450s
	iters: 200, epoch: 4 | loss: 0.6241372
	speed: 0.0869s/iter; left time: 137.2453s
Epoch: 4 cost time: 24.66172742843628
Epoch: 4, Steps: 254 | Train Loss: 0.5209596 Vali Loss: 0.3779234 Test Loss: 0.4276139
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4354069
	speed: 0.4455s/iter; left time: 634.7938s
	iters: 200, epoch: 5 | loss: 0.6556730
	speed: 0.0889s/iter; left time: 117.8409s
Epoch: 5 cost time: 23.135671615600586
Epoch: 5, Steps: 254 | Train Loss: 0.5045172 Vali Loss: 0.3804890 Test Loss: 0.4294351
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6127028
	speed: 0.4428s/iter; left time: 518.5543s
	iters: 200, epoch: 6 | loss: 0.4259923
	speed: 0.0878s/iter; left time: 94.0454s
Epoch: 6 cost time: 21.761824369430542
Epoch: 6, Steps: 254 | Train Loss: 0.4951453 Vali Loss: 0.3845714 Test Loss: 0.4254268
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_192_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.41109171509742737, mae:0.4337502717971802
Running ETTh2 with seq_len=192, pred_len=720...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_192_720       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_192_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 1.1526905
	speed: 0.0906s/iter; left time: 210.2108s
	iters: 200, epoch: 1 | loss: 0.7059385
	speed: 0.0810s/iter; left time: 179.8355s
Epoch: 1 cost time: 20.46497082710266
Epoch: 1, Steps: 242 | Train Loss: 0.8341288 Vali Loss: 0.5897002 Test Loss: 0.4262377
Validation loss decreased (inf --> 0.589700).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4948053
	speed: 0.3987s/iter; left time: 828.9535s
	iters: 200, epoch: 2 | loss: 0.8066542
	speed: 0.1204s/iter; left time: 238.3596s
Epoch: 2 cost time: 29.475058555603027
Epoch: 2, Steps: 242 | Train Loss: 0.7900735 Vali Loss: 0.6041293 Test Loss: 0.4364300
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0074793
	speed: 0.3494s/iter; left time: 641.9003s
	iters: 200, epoch: 3 | loss: 0.5465793
	speed: 0.1205s/iter; left time: 209.2790s
Epoch: 3 cost time: 29.408247470855713
Epoch: 3, Steps: 242 | Train Loss: 0.7524526 Vali Loss: 0.5876284 Test Loss: 0.4457651
Validation loss decreased (0.589700 --> 0.587628).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9889677
	speed: 0.3396s/iter; left time: 541.7241s
	iters: 200, epoch: 4 | loss: 0.9787375
	speed: 0.1193s/iter; left time: 178.3700s
Epoch: 4 cost time: 29.84857702255249
Epoch: 4, Steps: 242 | Train Loss: 0.7271505 Vali Loss: 0.6126015 Test Loss: 0.4600330
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7200089
	speed: 0.3817s/iter; left time: 516.4334s
	iters: 200, epoch: 5 | loss: 0.8113801
	speed: 0.1301s/iter; left time: 163.0643s
Epoch: 5 cost time: 31.479959964752197
Epoch: 5, Steps: 242 | Train Loss: 0.7118913 Vali Loss: 0.6104901 Test Loss: 0.4593447
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5491647
	speed: 0.3377s/iter; left time: 375.1737s
	iters: 200, epoch: 6 | loss: 0.6252335
	speed: 0.1537s/iter; left time: 155.3900s
Epoch: 6 cost time: 36.97798132896423
Epoch: 6, Steps: 242 | Train Loss: 0.7052785 Vali Loss: 0.6186208 Test Loss: 0.4602827
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_192_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.44127586483955383, mae:0.4589906930923462
Running ETTh2 with seq_len=288, pred_len=96...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_288_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_288_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8257
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.4005638
	speed: 0.1983s/iter; left time: 493.9220s
	iters: 200, epoch: 1 | loss: 0.4501505
	speed: 0.1960s/iter; left time: 468.6060s
Epoch: 1 cost time: 49.50534915924072
Epoch: 1, Steps: 259 | Train Loss: 0.4523904 Vali Loss: 0.2471241 Test Loss: 0.3302364
Validation loss decreased (inf --> 0.247124).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5657011
	speed: 0.5085s/iter; left time: 1135.0149s
	iters: 200, epoch: 2 | loss: 0.3808988
	speed: 0.1820s/iter; left time: 388.0353s
Epoch: 2 cost time: 49.69874620437622
Epoch: 2, Steps: 259 | Train Loss: 0.3777979 Vali Loss: 0.2640534 Test Loss: 0.3777742
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2636052
	speed: 0.4858s/iter; left time: 958.4953s
	iters: 200, epoch: 3 | loss: 0.2944196
	speed: 0.1974s/iter; left time: 369.7171s
Epoch: 3 cost time: 47.183966875076294
Epoch: 3, Steps: 259 | Train Loss: 0.3268093 Vali Loss: 0.2238182 Test Loss: 0.3196535
Validation loss decreased (0.247124 --> 0.223818).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2705699
	speed: 0.4525s/iter; left time: 775.5122s
	iters: 200, epoch: 4 | loss: 0.3279364
	speed: 0.0814s/iter; left time: 131.3301s
Epoch: 4 cost time: 25.364595651626587
Epoch: 4, Steps: 259 | Train Loss: 0.3059338 Vali Loss: 0.2253013 Test Loss: 0.3223639
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2735052
	speed: 0.2830s/iter; left time: 411.7787s
	iters: 200, epoch: 5 | loss: 0.2807756
	speed: 0.0982s/iter; left time: 133.0594s
Epoch: 5 cost time: 26.88257908821106
Epoch: 5, Steps: 259 | Train Loss: 0.2926180 Vali Loss: 0.2245115 Test Loss: 0.3150139
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1796301
	speed: 0.3266s/iter; left time: 390.6435s
	iters: 200, epoch: 6 | loss: 0.1605286
	speed: 0.0964s/iter; left time: 105.6334s
Epoch: 6 cost time: 27.24268388748169
Epoch: 6, Steps: 259 | Train Loss: 0.2844735 Vali Loss: 0.2261967 Test Loss: 0.3151532
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_288_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.31889018416404724, mae:0.36635321378707886
Running ETTh2 with seq_len=288, pred_len=192...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_288_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_288_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8161
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.4107077
	speed: 0.1010s/iter; left time: 248.5661s
	iters: 200, epoch: 1 | loss: 0.4779082
	speed: 0.0936s/iter; left time: 221.0802s
Epoch: 1 cost time: 24.873637437820435
Epoch: 1, Steps: 256 | Train Loss: 0.5436584 Vali Loss: 0.3036369 Test Loss: 0.4046878
Validation loss decreased (inf --> 0.303637).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5546963
	speed: 0.5909s/iter; left time: 1303.0363s
	iters: 200, epoch: 2 | loss: 0.3342681
	speed: 0.1827s/iter; left time: 384.5545s
Epoch: 2 cost time: 47.31669330596924
Epoch: 2, Steps: 256 | Train Loss: 0.4691912 Vali Loss: 0.2967184 Test Loss: 0.4049996
Validation loss decreased (0.303637 --> 0.296718).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5384536
	speed: 0.5417s/iter; left time: 1055.8241s
	iters: 200, epoch: 3 | loss: 0.4694187
	speed: 0.1529s/iter; left time: 282.6779s
Epoch: 3 cost time: 42.07585120201111
Epoch: 3, Steps: 256 | Train Loss: 0.4032938 Vali Loss: 0.2940282 Test Loss: 0.4164326
Validation loss decreased (0.296718 --> 0.294028).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3854178
	speed: 0.5005s/iter; left time: 847.2835s
	iters: 200, epoch: 4 | loss: 0.4947393
	speed: 0.1841s/iter; left time: 293.3118s
Epoch: 4 cost time: 46.524431228637695
Epoch: 4, Steps: 256 | Train Loss: 0.3743250 Vali Loss: 0.2948205 Test Loss: 0.4125304
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4724618
	speed: 0.5269s/iter; left time: 757.1991s
	iters: 200, epoch: 5 | loss: 0.3829678
	speed: 0.1594s/iter; left time: 213.0785s
Epoch: 5 cost time: 42.200820207595825
Epoch: 5, Steps: 256 | Train Loss: 0.3577087 Vali Loss: 0.2984119 Test Loss: 0.4114278
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3507161
	speed: 0.5219s/iter; left time: 616.3187s
	iters: 200, epoch: 6 | loss: 0.3094939
	speed: 0.1734s/iter; left time: 187.4385s
Epoch: 6 cost time: 46.3061580657959
Epoch: 6, Steps: 256 | Train Loss: 0.3493734 Vali Loss: 0.2905651 Test Loss: 0.4017456
Validation loss decreased (0.294028 --> 0.290565).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3957368
	speed: 0.4966s/iter; left time: 459.3844s
	iters: 200, epoch: 7 | loss: 0.3624304
	speed: 0.1598s/iter; left time: 131.8149s
Epoch: 7 cost time: 42.02284002304077
Epoch: 7, Steps: 256 | Train Loss: 0.3516569 Vali Loss: 0.2958623 Test Loss: 0.4063368
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5151938
	speed: 0.5245s/iter; left time: 350.8948s
	iters: 200, epoch: 8 | loss: 0.3966169
	speed: 0.1856s/iter; left time: 105.5883s
Epoch: 8 cost time: 47.45796060562134
Epoch: 8, Steps: 256 | Train Loss: 0.3448538 Vali Loss: 0.2976193 Test Loss: 0.4079197
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3854007
	speed: 0.5167s/iter; left time: 213.4000s
	iters: 200, epoch: 9 | loss: 0.3038608
	speed: 0.1520s/iter; left time: 47.5735s
Epoch: 9 cost time: 38.19473433494568
Epoch: 9, Steps: 256 | Train Loss: 0.3425055 Vali Loss: 0.2966543 Test Loss: 0.4072238
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_288_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.39609163999557495, mae:0.41281622648239136
Running ETTh2 with seq_len=288, pred_len=336...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_288_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_288_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8017
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3971375
	speed: 0.1386s/iter; left time: 334.2666s
	iters: 200, epoch: 1 | loss: 0.6080304
	speed: 0.1339s/iter; left time: 309.3651s
Epoch: 1 cost time: 33.690194845199585
Epoch: 1, Steps: 251 | Train Loss: 0.6371808 Vali Loss: 0.3606928 Test Loss: 0.3980033
Validation loss decreased (inf --> 0.360693).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3003845
	speed: 0.6907s/iter; left time: 1491.9558s
	iters: 200, epoch: 2 | loss: 0.2999076
	speed: 0.1594s/iter; left time: 328.4453s
Epoch: 2 cost time: 39.89954710006714
Epoch: 2, Steps: 251 | Train Loss: 0.5688682 Vali Loss: 0.3809209 Test Loss: 0.3942271
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5010036
	speed: 0.5513s/iter; left time: 1052.5141s
	iters: 200, epoch: 3 | loss: 0.3797397
	speed: 0.1838s/iter; left time: 332.5395s
Epoch: 3 cost time: 43.62243461608887
Epoch: 3, Steps: 251 | Train Loss: 0.5114106 Vali Loss: 0.3750413 Test Loss: 0.4300311
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3769819
	speed: 0.5192s/iter; left time: 860.8152s
	iters: 200, epoch: 4 | loss: 0.3394948
	speed: 0.1929s/iter; left time: 300.5122s
Epoch: 4 cost time: 48.43013000488281
Epoch: 4, Steps: 251 | Train Loss: 0.4775292 Vali Loss: 0.3856715 Test Loss: 0.4257572
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_288_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.3940138816833496, mae:0.4266583025455475
Running ETTh2 with seq_len=288, pred_len=720...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_288_720       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_288_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7633
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.8394212
	speed: 0.1990s/iter; left time: 455.8129s
	iters: 200, epoch: 1 | loss: 0.7259650
	speed: 0.1872s/iter; left time: 410.1463s
Epoch: 1 cost time: 46.364203214645386
Epoch: 1, Steps: 239 | Train Loss: 0.8192870 Vali Loss: 0.6342130 Test Loss: 0.4244344
Validation loss decreased (inf --> 0.634213).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8554996
	speed: 0.4400s/iter; left time: 902.8574s
	iters: 200, epoch: 2 | loss: 0.5864092
	speed: 0.1596s/iter; left time: 311.5786s
Epoch: 2 cost time: 39.00434851646423
Epoch: 2, Steps: 239 | Train Loss: 0.7565260 Vali Loss: 0.6770318 Test Loss: 0.4266986
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8812884
	speed: 0.4582s/iter; left time: 830.7460s
	iters: 200, epoch: 3 | loss: 0.5628765
	speed: 0.2045s/iter; left time: 350.3005s
Epoch: 3 cost time: 48.642807483673096
Epoch: 3, Steps: 239 | Train Loss: 0.7056160 Vali Loss: 0.6250311 Test Loss: 0.4773008
Validation loss decreased (0.634213 --> 0.625031).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6981240
	speed: 0.6129s/iter; left time: 964.6795s
	iters: 200, epoch: 4 | loss: 0.4971165
	speed: 0.1935s/iter; left time: 285.2062s
Epoch: 4 cost time: 49.014660120010376
Epoch: 4, Steps: 239 | Train Loss: 0.6704320 Vali Loss: 0.6432517 Test Loss: 0.4718828
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4879161
	speed: 0.4977s/iter; left time: 664.4703s
	iters: 200, epoch: 5 | loss: 0.5493012
	speed: 0.1986s/iter; left time: 245.2113s
Epoch: 5 cost time: 47.146596908569336
Epoch: 5, Steps: 239 | Train Loss: 0.6514751 Vali Loss: 0.6476480 Test Loss: 0.4820206
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5392705
	speed: 0.4510s/iter; left time: 494.3274s
	iters: 200, epoch: 6 | loss: 0.7745253
	speed: 0.1672s/iter; left time: 166.5156s
Epoch: 6 cost time: 40.57444977760315
Epoch: 6, Steps: 239 | Train Loss: 0.6413995 Vali Loss: 0.6505541 Test Loss: 0.4945498
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_288_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.4743989408016205, mae:0.48262351751327515
Running ETTh2 with seq_len=384, pred_len=96...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_384_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_384_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8161
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3045309
	speed: 0.1692s/iter; left time: 416.3067s
	iters: 200, epoch: 1 | loss: 0.3743304
	speed: 0.1811s/iter; left time: 427.4645s
Epoch: 1 cost time: 46.06204032897949
Epoch: 1, Steps: 256 | Train Loss: 0.4634756 Vali Loss: 0.2469634 Test Loss: 0.3353076
Validation loss decreased (inf --> 0.246963).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3382651
	speed: 0.5093s/iter; left time: 1123.0376s
	iters: 200, epoch: 2 | loss: 0.3795871
	speed: 0.1349s/iter; left time: 284.0228s
Epoch: 2 cost time: 38.94072365760803
Epoch: 2, Steps: 256 | Train Loss: 0.3728739 Vali Loss: 0.2272624 Test Loss: 0.3335757
Validation loss decreased (0.246963 --> 0.227262).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3959571
	speed: 0.4006s/iter; left time: 780.7793s
	iters: 200, epoch: 3 | loss: 0.3874278
	speed: 0.2415s/iter; left time: 446.4921s
Epoch: 3 cost time: 57.42166471481323
Epoch: 3, Steps: 256 | Train Loss: 0.3142898 Vali Loss: 0.2289132 Test Loss: 0.3393793
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2139146
	speed: 0.6816s/iter; left time: 1153.9449s
	iters: 200, epoch: 4 | loss: 0.2051045
	speed: 0.2389s/iter; left time: 380.6246s
Epoch: 4 cost time: 62.78995394706726
Epoch: 4, Steps: 256 | Train Loss: 0.2887859 Vali Loss: 0.2277401 Test Loss: 0.3310864
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3876179
	speed: 0.6896s/iter; left time: 990.9769s
	iters: 200, epoch: 5 | loss: 0.2250271
	speed: 0.2500s/iter; left time: 334.2039s
Epoch: 5 cost time: 63.57704997062683
Epoch: 5, Steps: 256 | Train Loss: 0.2771656 Vali Loss: 0.2265251 Test Loss: 0.3350219
Validation loss decreased (0.227262 --> 0.226525).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2425821
	speed: 0.5986s/iter; left time: 706.9518s
	iters: 200, epoch: 6 | loss: 0.3789175
	speed: 0.2595s/iter; left time: 280.5055s
Epoch: 6 cost time: 61.731205701828
Epoch: 6, Steps: 256 | Train Loss: 0.2760994 Vali Loss: 0.2297582 Test Loss: 0.3342458
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1561635
	speed: 0.6927s/iter; left time: 640.7698s
	iters: 200, epoch: 7 | loss: 0.2235283
	speed: 0.2627s/iter; left time: 216.7280s
Epoch: 7 cost time: 65.89819860458374
Epoch: 7, Steps: 256 | Train Loss: 0.2683385 Vali Loss: 0.2274163 Test Loss: 0.3313600
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2164759
	speed: 0.6874s/iter; left time: 459.8691s
	iters: 200, epoch: 8 | loss: 0.1761904
	speed: 0.2450s/iter; left time: 139.4212s
Epoch: 8 cost time: 61.65604877471924
Epoch: 8, Steps: 256 | Train Loss: 0.2654188 Vali Loss: 0.2279519 Test Loss: 0.3322627
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_384_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.33476483821868896, mae:0.375193327665329
Running ETTh2 with seq_len=384, pred_len=192...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_384_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_384_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8065
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5550088
	speed: 0.2539s/iter; left time: 617.1937s
	iters: 200, epoch: 1 | loss: 0.6199490
	speed: 0.2373s/iter; left time: 553.2338s
Epoch: 1 cost time: 60.30316495895386
Epoch: 1, Steps: 253 | Train Loss: 0.5468624 Vali Loss: 0.2912923 Test Loss: 0.4015619
Validation loss decreased (inf --> 0.291292).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5542790
	speed: 0.5851s/iter; left time: 1274.2981s
	iters: 200, epoch: 2 | loss: 0.3910707
	speed: 0.2138s/iter; left time: 444.3117s
Epoch: 2 cost time: 52.55453038215637
Epoch: 2, Steps: 253 | Train Loss: 0.4471151 Vali Loss: 0.2950227 Test Loss: 0.3987492
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4470262
	speed: 0.5171s/iter; left time: 995.4835s
	iters: 200, epoch: 3 | loss: 0.5332093
	speed: 0.1245s/iter; left time: 227.2567s
Epoch: 3 cost time: 34.26411056518555
Epoch: 3, Steps: 253 | Train Loss: 0.3824531 Vali Loss: 0.2897860 Test Loss: 0.4279880
Validation loss decreased (0.291292 --> 0.289786).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2741958
	speed: 0.6533s/iter; left time: 1092.2751s
	iters: 200, epoch: 4 | loss: 0.3063044
	speed: 0.2428s/iter; left time: 381.6755s
Epoch: 4 cost time: 64.35167694091797
Epoch: 4, Steps: 253 | Train Loss: 0.3504056 Vali Loss: 0.2945713 Test Loss: 0.4097174
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3619884
	speed: 0.7597s/iter; left time: 1078.0723s
	iters: 200, epoch: 5 | loss: 0.3646257
	speed: 0.2569s/iter; left time: 338.8083s
Epoch: 5 cost time: 65.06492304801941
Epoch: 5, Steps: 253 | Train Loss: 0.3361243 Vali Loss: 0.2956286 Test Loss: 0.4195678
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4434564
	speed: 0.6658s/iter; left time: 776.3475s
	iters: 200, epoch: 6 | loss: 0.3366185
	speed: 0.2191s/iter; left time: 233.5310s
Epoch: 6 cost time: 52.51450252532959
Epoch: 6, Steps: 253 | Train Loss: 0.3279793 Vali Loss: 0.2934197 Test Loss: 0.4234252
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_384_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.421562522649765, mae:0.42925891280174255
Running ETTh2 with seq_len=384, pred_len=336...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_384_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_384_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7921
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.7744365
	speed: 0.2675s/iter; left time: 636.9462s
	iters: 200, epoch: 1 | loss: 0.7700402
	speed: 0.2690s/iter; left time: 613.5833s
Epoch: 1 cost time: 66.18552756309509
Epoch: 1, Steps: 248 | Train Loss: 0.6303305 Vali Loss: 0.3826166 Test Loss: 0.4272538
Validation loss decreased (inf --> 0.382617).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5524013
	speed: 0.6818s/iter; left time: 1454.1901s
	iters: 200, epoch: 2 | loss: 0.5902506
	speed: 0.2743s/iter; left time: 557.7451s
Epoch: 2 cost time: 67.07018423080444
Epoch: 2, Steps: 248 | Train Loss: 0.5479557 Vali Loss: 0.3774649 Test Loss: 0.4583039
Validation loss decreased (0.382617 --> 0.377465).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4609802
	speed: 0.6413s/iter; left time: 1208.7629s
	iters: 200, epoch: 3 | loss: 0.4057775
	speed: 0.2006s/iter; left time: 357.9824s
Epoch: 3 cost time: 50.93273377418518
Epoch: 3, Steps: 248 | Train Loss: 0.4846239 Vali Loss: 0.3770357 Test Loss: 0.4412273
Validation loss decreased (0.377465 --> 0.377036).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5185038
	speed: 0.5782s/iter; left time: 946.5286s
	iters: 200, epoch: 4 | loss: 0.3327219
	speed: 0.1822s/iter; left time: 279.9705s
Epoch: 4 cost time: 48.11466979980469
Epoch: 4, Steps: 248 | Train Loss: 0.4499166 Vali Loss: 0.3793223 Test Loss: 0.4585919
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5125858
	speed: 0.5593s/iter; left time: 776.8043s
	iters: 200, epoch: 5 | loss: 0.5121142
	speed: 0.1991s/iter; left time: 256.6851s
Epoch: 5 cost time: 50.97897410392761
Epoch: 5, Steps: 248 | Train Loss: 0.4298543 Vali Loss: 0.3914193 Test Loss: 0.4719306
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3946449
	speed: 0.5815s/iter; left time: 663.4611s
	iters: 200, epoch: 6 | loss: 0.3229413
	speed: 0.2119s/iter; left time: 220.6342s
Epoch: 6 cost time: 55.16032910346985
Epoch: 6, Steps: 248 | Train Loss: 0.4205981 Vali Loss: 0.3864197 Test Loss: 0.4763975
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_384_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.4361402094364166, mae:0.45224183797836304
Running ETTh2 with seq_len=384, pred_len=720...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_384_720       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_384_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7537
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 1.0226839
	speed: 0.2751s/iter; left time: 621.9823s
	iters: 200, epoch: 1 | loss: 0.9429650
	speed: 0.2735s/iter; left time: 591.1107s
Epoch: 1 cost time: 64.36162281036377
Epoch: 1, Steps: 236 | Train Loss: 0.8134045 Vali Loss: 0.6394241 Test Loss: 0.4512275
Validation loss decreased (inf --> 0.639424).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6708414
	speed: 0.6184s/iter; left time: 1252.3061s
	iters: 200, epoch: 2 | loss: 0.8090636
	speed: 0.2700s/iter; left time: 519.6626s
Epoch: 2 cost time: 61.68898248672485
Epoch: 2, Steps: 236 | Train Loss: 0.7352781 Vali Loss: 0.6092203 Test Loss: 0.4868786
Validation loss decreased (0.639424 --> 0.609220).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0731091
	speed: 0.5839s/iter; left time: 1044.6332s
	iters: 200, epoch: 3 | loss: 0.3021854
	speed: 0.2560s/iter; left time: 432.3677s
Epoch: 3 cost time: 60.498786211013794
Epoch: 3, Steps: 236 | Train Loss: 0.6732084 Vali Loss: 0.6779139 Test Loss: 0.4853470
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8729140
	speed: 0.6166s/iter; left time: 957.5464s
	iters: 200, epoch: 4 | loss: 0.5107530
	speed: 0.2522s/iter; left time: 366.4203s
Epoch: 4 cost time: 60.72992181777954
Epoch: 4, Steps: 236 | Train Loss: 0.6354342 Vali Loss: 0.6960422 Test Loss: 0.4932468
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9791181
	speed: 0.6306s/iter; left time: 830.4543s
	iters: 200, epoch: 5 | loss: 0.5155085
	speed: 0.2605s/iter; left time: 316.9855s
Epoch: 5 cost time: 63.18327450752258
Epoch: 5, Steps: 236 | Train Loss: 0.6157236 Vali Loss: 0.7102408 Test Loss: 0.5038049
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_384_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.48489442467689514, mae:0.5008503198623657
Running ETTh2 with seq_len=512, pred_len=96...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_512_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_512_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8033
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.6067298
	speed: 0.1568s/iter; left time: 379.5078s
	iters: 200, epoch: 1 | loss: 0.4596162
	speed: 0.1441s/iter; left time: 334.4896s
Epoch: 1 cost time: 41.12496757507324
Epoch: 1, Steps: 252 | Train Loss: 0.4780080 Vali Loss: 0.2618207 Test Loss: 0.3552187
Validation loss decreased (inf --> 0.261821).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3182726
	speed: 0.6184s/iter; left time: 1341.2013s
	iters: 200, epoch: 2 | loss: 0.4059746
	speed: 0.2590s/iter; left time: 535.8142s
Epoch: 2 cost time: 64.23857283592224
Epoch: 2, Steps: 252 | Train Loss: 0.3657537 Vali Loss: 0.2611164 Test Loss: 0.3466272
Validation loss decreased (0.261821 --> 0.261116).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2338265
	speed: 0.8048s/iter; left time: 1542.8759s
	iters: 200, epoch: 3 | loss: 0.2482154
	speed: 0.2685s/iter; left time: 487.8371s
Epoch: 3 cost time: 73.96955490112305
Epoch: 3, Steps: 252 | Train Loss: 0.2980282 Vali Loss: 0.2495676 Test Loss: 0.3304496
Validation loss decreased (0.261116 --> 0.249568).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2930449
	speed: 0.8169s/iter; left time: 1360.0570s
	iters: 200, epoch: 4 | loss: 0.2000762
	speed: 0.3176s/iter; left time: 497.0224s
Epoch: 4 cost time: 81.08595132827759
Epoch: 4, Steps: 252 | Train Loss: 0.2703617 Vali Loss: 0.2424269 Test Loss: 0.3340982
Validation loss decreased (0.249568 --> 0.242427).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2413278
	speed: 0.8701s/iter; left time: 1229.5183s
	iters: 200, epoch: 5 | loss: 0.2618562
	speed: 0.3305s/iter; left time: 433.9172s
Epoch: 5 cost time: 79.60468029975891
Epoch: 5, Steps: 252 | Train Loss: 0.2579795 Vali Loss: 0.2392390 Test Loss: 0.3307431
Validation loss decreased (0.242427 --> 0.239239).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2458964
	speed: 0.7517s/iter; left time: 872.7066s
	iters: 200, epoch: 6 | loss: 0.2415539
	speed: 0.3378s/iter; left time: 358.4301s
Epoch: 6 cost time: 82.1569607257843
Epoch: 6, Steps: 252 | Train Loss: 0.2507389 Vali Loss: 0.2485250 Test Loss: 0.3351965
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1997959
	speed: 0.8798s/iter; left time: 799.7402s
	iters: 200, epoch: 7 | loss: 0.2441261
	speed: 0.3207s/iter; left time: 259.4551s
Epoch: 7 cost time: 81.79993414878845
Epoch: 7, Steps: 252 | Train Loss: 0.2459715 Vali Loss: 0.2410277 Test Loss: 0.3348221
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2591292
	speed: 0.7017s/iter; left time: 461.0146s
	iters: 200, epoch: 8 | loss: 0.2339234
	speed: 0.1673s/iter; left time: 93.2097s
Epoch: 8 cost time: 47.037415504455566
Epoch: 8, Steps: 252 | Train Loss: 0.2450142 Vali Loss: 0.2424275 Test Loss: 0.3384332
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_512_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.33086511492729187, mae:0.3777289390563965
Running ETTh2 with seq_len=512, pred_len=192...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_512_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_512_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7937
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.4764638
	speed: 0.2608s/iter; left time: 623.6859s
	iters: 200, epoch: 1 | loss: 0.4109931
	speed: 0.2451s/iter; left time: 561.5653s
Epoch: 1 cost time: 60.87161564826965
Epoch: 1, Steps: 249 | Train Loss: 0.5580978 Vali Loss: 0.3559464 Test Loss: 0.3705603
Validation loss decreased (inf --> 0.355946).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4813853
	speed: 0.8182s/iter; left time: 1752.5082s
	iters: 200, epoch: 2 | loss: 0.5011747
	speed: 0.3048s/iter; left time: 622.5015s
Epoch: 2 cost time: 79.21408343315125
Epoch: 2, Steps: 249 | Train Loss: 0.5031555 Vali Loss: 0.3284116 Test Loss: 0.3917211
Validation loss decreased (0.355946 --> 0.328412).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3970622
	speed: 0.8240s/iter; left time: 1559.7497s
	iters: 200, epoch: 3 | loss: 0.4280511
	speed: 0.2369s/iter; left time: 424.7410s
Epoch: 3 cost time: 64.15564632415771
Epoch: 3, Steps: 249 | Train Loss: 0.4193735 Vali Loss: 0.3117497 Test Loss: 0.3874024
Validation loss decreased (0.328412 --> 0.311750).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3565078
	speed: 0.8079s/iter; left time: 1328.2345s
	iters: 200, epoch: 4 | loss: 0.4138836
	speed: 0.2983s/iter; left time: 460.5715s
Epoch: 4 cost time: 77.36461639404297
Epoch: 4, Steps: 249 | Train Loss: 0.3826303 Vali Loss: 0.3286909 Test Loss: 0.3989779
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2930703
	speed: 0.8607s/iter; left time: 1200.6603s
	iters: 200, epoch: 5 | loss: 0.2765031
	speed: 0.3243s/iter; left time: 419.9058s
Epoch: 5 cost time: 80.92410898208618
Epoch: 5, Steps: 249 | Train Loss: 0.3647615 Vali Loss: 0.3196717 Test Loss: 0.3845593
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3146909
	speed: 0.8604s/iter; left time: 985.9993s
	iters: 200, epoch: 6 | loss: 0.5835847
	speed: 0.2913s/iter; left time: 304.6679s
Epoch: 6 cost time: 74.21447157859802
Epoch: 6, Steps: 249 | Train Loss: 0.3523799 Vali Loss: 0.3278236 Test Loss: 0.3980424
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_512_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.3826621174812317, mae:0.4164106547832489
Running ETTh2 with seq_len=512, pred_len=336...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_512_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_512_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7793
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.6335006
	speed: 0.2717s/iter; left time: 636.1519s
	iters: 200, epoch: 1 | loss: 0.8423408
	speed: 0.2306s/iter; left time: 516.6744s
Epoch: 1 cost time: 60.18925642967224
Epoch: 1, Steps: 244 | Train Loss: 0.6432957 Vali Loss: 0.4110406 Test Loss: 0.4463605
Validation loss decreased (inf --> 0.411041).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4870249
	speed: 0.6551s/iter; left time: 1373.7851s
	iters: 200, epoch: 2 | loss: 0.3935232
	speed: 0.2666s/iter; left time: 532.4729s
Epoch: 2 cost time: 63.967021226882935
Epoch: 2, Steps: 244 | Train Loss: 0.5328212 Vali Loss: 0.4295735 Test Loss: 0.4698453
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4737136
	speed: 0.6382s/iter; left time: 1182.5221s
	iters: 200, epoch: 3 | loss: 0.3679022
	speed: 0.1712s/iter; left time: 300.0905s
Epoch: 3 cost time: 49.173351764678955
Epoch: 3, Steps: 244 | Train Loss: 0.4620591 Vali Loss: 0.4201935 Test Loss: 0.4579763
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6168721
	speed: 0.4699s/iter; left time: 756.0740s
	iters: 200, epoch: 4 | loss: 0.4124970
	speed: 0.2646s/iter; left time: 399.2554s
Epoch: 4 cost time: 57.58582854270935
Epoch: 4, Steps: 244 | Train Loss: 0.4221456 Vali Loss: 0.4229919 Test Loss: 0.4840892
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_512_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.4406880736351013, mae:0.4525918662548065
Running ETTh2 with seq_len=512, pred_len=720...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_512_720       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_512_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7409
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.8791865
	speed: 0.3688s/iter; left time: 819.0636s
	iters: 200, epoch: 1 | loss: 0.5742534
	speed: 0.3545s/iter; left time: 751.9203s
Epoch: 1 cost time: 83.4612295627594
Epoch: 1, Steps: 232 | Train Loss: 0.8027395 Vali Loss: 0.7049080 Test Loss: 0.4572637
Validation loss decreased (inf --> 0.704908).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6026377
	speed: 0.8075s/iter; left time: 1606.0731s
	iters: 200, epoch: 2 | loss: 0.9174960
	speed: 0.3274s/iter; left time: 618.5333s
Epoch: 2 cost time: 77.92496657371521
Epoch: 2, Steps: 232 | Train Loss: 0.7047056 Vali Loss: 0.7623517 Test Loss: 0.5246879
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7185853
	speed: 0.6732s/iter; left time: 1182.8216s
	iters: 200, epoch: 3 | loss: 0.6802615
	speed: 0.3527s/iter; left time: 584.4753s
Epoch: 3 cost time: 78.73836135864258
Epoch: 3, Steps: 232 | Train Loss: 0.6183199 Vali Loss: 0.7415557 Test Loss: 0.5572905
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3929286
	speed: 0.7813s/iter; left time: 1191.5243s
	iters: 200, epoch: 4 | loss: 0.4868145
	speed: 0.3495s/iter; left time: 498.0442s
Epoch: 4 cost time: 80.4718656539917
Epoch: 4, Steps: 232 | Train Loss: 0.5707611 Vali Loss: 0.7411838 Test Loss: 0.5689215
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_512_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.4556662440299988, mae:0.4721168577671051
Running ETTh2 with seq_len=736, pred_len=96...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_736_96        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_736_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7809
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3227090
	speed: 0.4443s/iter; left time: 1044.4678s
	iters: 200, epoch: 1 | loss: 0.3454593
	speed: 0.4116s/iter; left time: 926.4191s
Epoch: 1 cost time: 104.06374478340149
Epoch: 1, Steps: 245 | Train Loss: 0.4967961 Vali Loss: 0.2669491 Test Loss: 0.3330850
Validation loss decreased (inf --> 0.266949).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3419591
	speed: 1.1459s/iter; left time: 2413.2067s
	iters: 200, epoch: 2 | loss: 0.3817745
	speed: 0.4707s/iter; left time: 944.1533s
Epoch: 2 cost time: 115.06903028488159
Epoch: 2, Steps: 245 | Train Loss: 0.3729517 Vali Loss: 0.2653497 Test Loss: 0.3372941
Validation loss decreased (0.266949 --> 0.265350).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3709839
	speed: 1.2051s/iter; left time: 2242.7480s
	iters: 200, epoch: 3 | loss: 0.2952389
	speed: 0.4652s/iter; left time: 819.2618s
Epoch: 3 cost time: 110.61058831214905
Epoch: 3, Steps: 245 | Train Loss: 0.3007996 Vali Loss: 0.2657181 Test Loss: 0.3187075
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2549587
	speed: 0.9489s/iter; left time: 1533.4771s
	iters: 200, epoch: 4 | loss: 0.2856447
	speed: 0.3283s/iter; left time: 497.6522s
Epoch: 4 cost time: 85.25697684288025
Epoch: 4, Steps: 245 | Train Loss: 0.2774006 Vali Loss: 0.2753680 Test Loss: 0.3233362
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2372638
	speed: 0.8581s/iter; left time: 1176.4193s
	iters: 200, epoch: 5 | loss: 0.1788197
	speed: 0.2991s/iter; left time: 380.1044s
Epoch: 5 cost time: 78.45452666282654
Epoch: 5, Steps: 245 | Train Loss: 0.2680732 Vali Loss: 0.2582729 Test Loss: 0.3192729
Validation loss decreased (0.265350 --> 0.258273).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2168259
	speed: 1.0216s/iter; left time: 1150.2664s
	iters: 200, epoch: 6 | loss: 0.2501987
	speed: 0.3829s/iter; left time: 392.8613s
Epoch: 6 cost time: 93.32861971855164
Epoch: 6, Steps: 245 | Train Loss: 0.2612375 Vali Loss: 0.2614460 Test Loss: 0.3262165
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1844887
	speed: 1.1112s/iter; left time: 978.9455s
	iters: 200, epoch: 7 | loss: 0.2791176
	speed: 0.4507s/iter; left time: 351.9619s
Epoch: 7 cost time: 111.49925971031189
Epoch: 7, Steps: 245 | Train Loss: 0.2514229 Vali Loss: 0.2557293 Test Loss: 0.3176642
Validation loss decreased (0.258273 --> 0.255729).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2887933
	speed: 1.2151s/iter; left time: 772.8092s
	iters: 200, epoch: 8 | loss: 0.1948464
	speed: 0.4716s/iter; left time: 252.7792s
Epoch: 8 cost time: 113.28833031654358
Epoch: 8, Steps: 245 | Train Loss: 0.2550771 Vali Loss: 0.2589476 Test Loss: 0.3226961
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2092488
	speed: 1.0525s/iter; left time: 411.5094s
	iters: 200, epoch: 9 | loss: 0.2930879
	speed: 0.4816s/iter; left time: 140.1538s
Epoch: 9 cost time: 109.54016900062561
Epoch: 9, Steps: 245 | Train Loss: 0.2470261 Vali Loss: 0.2588401 Test Loss: 0.3202775
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.4511140
	speed: 1.2332s/iter; left time: 180.0532s
	iters: 200, epoch: 10 | loss: 0.2866765
	speed: 0.4719s/iter; left time: 21.7070s
Epoch: 10 cost time: 114.33460092544556
Epoch: 10, Steps: 245 | Train Loss: 0.2466387 Vali Loss: 0.2577424 Test Loss: 0.3195005
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_736_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.3171025216579437, mae:0.37073731422424316
Running ETTh2 with seq_len=736, pred_len=192...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_736_192       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_736_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7713
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5279462
	speed: 0.3806s/iter; left time: 883.3104s
	iters: 200, epoch: 1 | loss: 0.5792624
	speed: 0.4311s/iter; left time: 957.4613s
Epoch: 1 cost time: 101.55949473381042
Epoch: 1, Steps: 242 | Train Loss: 0.5750403 Vali Loss: 0.3393543 Test Loss: 0.3964240
Validation loss decreased (inf --> 0.339354).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4174298
	speed: 1.0551s/iter; left time: 2193.5926s
	iters: 200, epoch: 2 | loss: 0.3405187
	speed: 0.3564s/iter; left time: 705.3616s
Epoch: 2 cost time: 82.94033932685852
Epoch: 2, Steps: 242 | Train Loss: 0.4420418 Vali Loss: 0.4834453 Test Loss: 0.4138807
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6385819
	speed: 0.8700s/iter; left time: 1598.2636s
	iters: 200, epoch: 3 | loss: 0.3626676
	speed: 0.2524s/iter; left time: 438.3644s
Epoch: 3 cost time: 66.71847796440125
Epoch: 3, Steps: 242 | Train Loss: 0.3902722 Vali Loss: 0.3370269 Test Loss: 0.3985634
Validation loss decreased (0.339354 --> 0.337027).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2240091
	speed: 0.9339s/iter; left time: 1489.5673s
	iters: 200, epoch: 4 | loss: 0.2874130
	speed: 0.4896s/iter; left time: 731.9905s
Epoch: 4 cost time: 116.18625116348267
Epoch: 4, Steps: 242 | Train Loss: 0.3307137 Vali Loss: 0.3643928 Test Loss: 0.4078885
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2349476
	speed: 1.2182s/iter; left time: 1648.2880s
	iters: 200, epoch: 5 | loss: 0.4703173
	speed: 0.4685s/iter; left time: 586.9715s
Epoch: 5 cost time: 114.718421459198
Epoch: 5, Steps: 242 | Train Loss: 0.3196063 Vali Loss: 0.3619862 Test Loss: 0.4001552
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3042059
	speed: 1.0588s/iter; left time: 1176.3129s
	iters: 200, epoch: 6 | loss: 0.3349234
	speed: 0.4487s/iter; left time: 453.5956s
Epoch: 6 cost time: 103.55595922470093
Epoch: 6, Steps: 242 | Train Loss: 0.3049467 Vali Loss: 0.3545905 Test Loss: 0.3954540
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_736_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.39665865898132324, mae:0.42236658930778503
Running ETTh2 with seq_len=736, pred_len=336...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_736_336       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_736_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7569
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.8689805
	speed: 0.4621s/iter; left time: 1049.4390s
	iters: 200, epoch: 1 | loss: 0.8221392
	speed: 0.4611s/iter; left time: 1001.1282s
Epoch: 1 cost time: 110.36849188804626
Epoch: 1, Steps: 237 | Train Loss: 0.6640062 Vali Loss: 0.4541842 Test Loss: 0.4573764
Validation loss decreased (inf --> 0.454184).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4957848
	speed: 1.0885s/iter; left time: 2213.9758s
	iters: 200, epoch: 2 | loss: 0.5233870
	speed: 0.3995s/iter; left time: 772.6749s
Epoch: 2 cost time: 95.67038369178772
Epoch: 2, Steps: 237 | Train Loss: 0.5145271 Vali Loss: 0.4761820 Test Loss: 0.4854220
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3567915
	speed: 1.1336s/iter; left time: 2037.0600s
	iters: 200, epoch: 3 | loss: 0.3512197
	speed: 0.4857s/iter; left time: 824.2761s
Epoch: 3 cost time: 112.71881985664368
Epoch: 3, Steps: 237 | Train Loss: 0.4222682 Vali Loss: 0.4651178 Test Loss: 0.4629185
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3122917
	speed: 1.1644s/iter; left time: 1816.4957s
	iters: 200, epoch: 4 | loss: 0.4171504
	speed: 0.3457s/iter; left time: 504.7627s
Epoch: 4 cost time: 91.03958559036255
Epoch: 4, Steps: 237 | Train Loss: 0.3767937 Vali Loss: 0.4690064 Test Loss: 0.4634226
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_736_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.45161858201026917, mae:0.45576879382133484
Running ETTh2 with seq_len=736, pred_len=720...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_736_720       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_736_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7185
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 1.0397719
	speed: 0.2666s/iter; left time: 573.5257s
	iters: 200, epoch: 1 | loss: 0.5724669
	speed: 0.2162s/iter; left time: 443.3924s
Epoch: 1 cost time: 57.159799575805664
Epoch: 1, Steps: 225 | Train Loss: 0.7976653 Vali Loss: 0.7824183 Test Loss: 0.4499842
Validation loss decreased (inf --> 0.782418).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6385052
	speed: 0.8250s/iter; left time: 1589.0298s
	iters: 200, epoch: 2 | loss: 0.5397992
	speed: 0.4714s/iter; left time: 860.7940s
Epoch: 2 cost time: 98.62834072113037
Epoch: 2, Steps: 225 | Train Loss: 0.6142793 Vali Loss: 0.8414264 Test Loss: 0.5624733
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5093359
	speed: 1.0330s/iter; left time: 1757.1054s
	iters: 200, epoch: 3 | loss: 0.5146025
	speed: 0.4773s/iter; left time: 764.1851s
Epoch: 3 cost time: 106.62616467475891
Epoch: 3, Steps: 225 | Train Loss: 0.5042239 Vali Loss: 0.8436701 Test Loss: 0.5362609
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5223722
	speed: 1.0327s/iter; left time: 1524.2393s
	iters: 200, epoch: 4 | loss: 0.5937579
	speed: 0.3627s/iter; left time: 499.0677s
Epoch: 4 cost time: 92.3022837638855
Epoch: 4, Steps: 225 | Train Loss: 0.4408780 Vali Loss: 0.9100024 Test Loss: 0.5799037
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_736_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.44890642166137695, mae:0.46929359436035156
Running ETTh2 with seq_len=1024, pred_len=96...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_1024_96       Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_1024_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7521
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5285693
	speed: 0.6331s/iter; left time: 1431.5015s
	iters: 200, epoch: 1 | loss: 0.3157063
	speed: 0.6470s/iter; left time: 1398.0929s
Epoch: 1 cost time: 149.97918128967285
Epoch: 1, Steps: 236 | Train Loss: 0.5567290 Vali Loss: 0.4174173 Test Loss: 0.4085502
Validation loss decreased (inf --> 0.417417).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3452222
	speed: 1.6225s/iter; left time: 3285.6626s
	iters: 200, epoch: 2 | loss: 0.3425561
	speed: 0.6544s/iter; left time: 1259.7429s
Epoch: 2 cost time: 150.89276599884033
Epoch: 2, Steps: 236 | Train Loss: 0.3788374 Vali Loss: 0.2727054 Test Loss: 0.3469843
Validation loss decreased (0.417417 --> 0.272705).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3005020
	speed: 1.3847s/iter; left time: 2477.2226s
	iters: 200, epoch: 3 | loss: 0.2591883
	speed: 0.6359s/iter; left time: 1074.0939s
Epoch: 3 cost time: 144.38882613182068
Epoch: 3, Steps: 236 | Train Loss: 0.2933504 Vali Loss: 0.2820142 Test Loss: 0.3547051
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2396119
	speed: 1.3844s/iter; left time: 2149.9995s
	iters: 200, epoch: 4 | loss: 0.2664162
	speed: 0.4554s/iter; left time: 661.7551s
Epoch: 4 cost time: 110.65487790107727
Epoch: 4, Steps: 236 | Train Loss: 0.2599358 Vali Loss: 0.2785566 Test Loss: 0.3406041
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3871508
	speed: 1.0376s/iter; left time: 1366.4814s
	iters: 200, epoch: 5 | loss: 0.2061057
	speed: 0.4926s/iter; left time: 599.4690s
Epoch: 5 cost time: 106.78069639205933
Epoch: 5, Steps: 236 | Train Loss: 0.2464659 Vali Loss: 0.2990136 Test Loss: 0.3482393
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_1024_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.3464374840259552, mae:0.3932587504386902
Running ETTh2 with seq_len=1024, pred_len=192...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_1024_192      Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_1024_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7425
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 1.1549871
	speed: 0.6301s/iter; left time: 1405.7327s
	iters: 200, epoch: 1 | loss: 0.4485901
	speed: 0.6552s/iter; left time: 1396.1667s
Epoch: 1 cost time: 150.2171835899353
Epoch: 1, Steps: 233 | Train Loss: 0.5911501 Vali Loss: 0.4520973 Test Loss: 0.4245799
Validation loss decreased (inf --> 0.452097).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3926124
	speed: 1.4933s/iter; left time: 2983.7066s
	iters: 200, epoch: 2 | loss: 0.3760056
	speed: 0.5420s/iter; left time: 1028.6421s
Epoch: 2 cost time: 130.93306756019592
Epoch: 2, Steps: 233 | Train Loss: 0.3955129 Vali Loss: 0.4244563 Test Loss: 0.4219329
Validation loss decreased (0.452097 --> 0.424456).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2878997
	speed: 1.5925s/iter; left time: 2810.7596s
	iters: 200, epoch: 3 | loss: 0.2998442
	speed: 0.6281s/iter; left time: 1045.8277s
Epoch: 3 cost time: 148.15754055976868
Epoch: 3, Steps: 233 | Train Loss: 0.3062168 Vali Loss: 0.3836280 Test Loss: 0.3893448
Validation loss decreased (0.424456 --> 0.383628).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2889346
	speed: 1.5795s/iter; left time: 2419.7332s
	iters: 200, epoch: 4 | loss: 0.3083386
	speed: 0.5099s/iter; left time: 730.1183s
Epoch: 4 cost time: 131.59597444534302
Epoch: 4, Steps: 233 | Train Loss: 0.2711606 Vali Loss: 0.4001569 Test Loss: 0.3927784
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2199123
	speed: 1.3591s/iter; left time: 1765.4773s
	iters: 200, epoch: 5 | loss: 0.3967496
	speed: 0.4918s/iter; left time: 589.6924s
Epoch: 5 cost time: 112.61930561065674
Epoch: 5, Steps: 233 | Train Loss: 0.2574978 Vali Loss: 0.3902061 Test Loss: 0.3935083
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2176490
	speed: 1.2145s/iter; left time: 1294.6135s
	iters: 200, epoch: 6 | loss: 0.4183904
	speed: 0.5912s/iter; left time: 571.0851s
Epoch: 6 cost time: 122.25002241134644
Epoch: 6, Steps: 233 | Train Loss: 0.2578359 Vali Loss: 0.4201967 Test Loss: 0.3961237
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_1024_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 192, 7) (2689, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.38280031085014343, mae:0.4195091426372528
Running ETTh2 with seq_len=1024, pred_len=336...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_1024_336      Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_1024_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7281
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5423598
	speed: 0.6585s/iter; left time: 1436.2023s
	iters: 200, epoch: 1 | loss: 0.6453646
	speed: 0.6397s/iter; left time: 1331.1299s
Epoch: 1 cost time: 147.09268164634705
Epoch: 1, Steps: 228 | Train Loss: 0.6743627 Vali Loss: 0.5259075 Test Loss: 0.4369351
Validation loss decreased (inf --> 0.525908).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4173566
	speed: 1.5104s/iter; left time: 2949.8270s
	iters: 200, epoch: 2 | loss: 0.3036697
	speed: 0.6270s/iter; left time: 1161.8174s
Epoch: 2 cost time: 144.8225016593933
Epoch: 2, Steps: 228 | Train Loss: 0.4695514 Vali Loss: 0.5517689 Test Loss: 0.4937015
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3252725
	speed: 1.2700s/iter; left time: 2190.6799s
	iters: 200, epoch: 3 | loss: 0.4558314
	speed: 0.5125s/iter; left time: 832.8454s
Epoch: 3 cost time: 122.97107267379761
Epoch: 3, Steps: 228 | Train Loss: 0.3673183 Vali Loss: 0.5267652 Test Loss: 0.4750701
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2699162
	speed: 1.5614s/iter; left time: 2337.4509s
	iters: 200, epoch: 4 | loss: 0.2980256
	speed: 0.6475s/iter; left time: 904.5120s
Epoch: 4 cost time: 147.46080470085144
Epoch: 4, Steps: 228 | Train Loss: 0.3159593 Vali Loss: 0.5118535 Test Loss: 0.4454134
Validation loss decreased (0.525908 --> 0.511853).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3655557
	speed: 1.4996s/iter; left time: 1902.9948s
	iters: 200, epoch: 5 | loss: 0.2188387
	speed: 0.3876s/iter; left time: 453.1571s
Epoch: 5 cost time: 108.62863492965698
Epoch: 5, Steps: 228 | Train Loss: 0.2902868 Vali Loss: 0.5497965 Test Loss: 0.4800222
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3002036
	speed: 0.9084s/iter; left time: 945.6740s
	iters: 200, epoch: 6 | loss: 0.2249413
	speed: 0.5133s/iter; left time: 483.0577s
Epoch: 6 cost time: 105.70881748199463
Epoch: 6, Steps: 228 | Train Loss: 0.2778527 Vali Loss: 0.5370864 Test Loss: 0.4658484
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2470283
	speed: 1.4496s/iter; left time: 1178.4992s
	iters: 200, epoch: 7 | loss: 0.1934466
	speed: 0.6689s/iter; left time: 476.9462s
Epoch: 7 cost time: 150.0216612815857
Epoch: 7, Steps: 228 | Train Loss: 0.2697673 Vali Loss: 0.5370644 Test Loss: 0.4690066
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_1024_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.43997466564178467, mae:0.46335193514823914
Running ETTh2 with seq_len=1024, pred_len=720...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTh2_1024_720      Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTh2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTh2_1024_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6897
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7948585
	speed: 0.5529s/iter; left time: 1139.4468s
	iters: 200, epoch: 1 | loss: 0.6651394
	speed: 0.6417s/iter; left time: 1258.4346s
Epoch: 1 cost time: 130.02102613449097
Epoch: 1, Steps: 216 | Train Loss: 0.8031130 Vali Loss: 0.7948124 Test Loss: 0.4707295
Validation loss decreased (inf --> 0.794812).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4541779
	speed: 1.4007s/iter; left time: 2584.2698s
	iters: 200, epoch: 2 | loss: 0.3856343
	speed: 0.6677s/iter; left time: 1165.2178s
Epoch: 2 cost time: 145.5990288257599
Epoch: 2, Steps: 216 | Train Loss: 0.5653291 Vali Loss: 0.8939123 Test Loss: 0.6814657
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4033077
	speed: 1.4148s/iter; left time: 2304.7319s
	iters: 200, epoch: 3 | loss: 0.3427624
	speed: 0.5444s/iter; left time: 832.4507s
Epoch: 3 cost time: 131.7600131034851
Epoch: 3, Steps: 216 | Train Loss: 0.4053427 Vali Loss: 0.8401867 Test Loss: 0.5462432
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3285801
	speed: 1.3008s/iter; left time: 1837.9994s
	iters: 200, epoch: 4 | loss: 0.2456512
	speed: 0.6552s/iter; left time: 860.2587s
Epoch: 4 cost time: 144.1407594680786
Epoch: 4, Steps: 216 | Train Loss: 0.3332243 Vali Loss: 0.8397192 Test Loss: 0.5909200
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTh2_1024_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.46945255994796753, mae:0.4793051779270172
