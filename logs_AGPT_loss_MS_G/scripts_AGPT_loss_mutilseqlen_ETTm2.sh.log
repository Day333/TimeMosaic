Running ETTm2 with pred_len=96, e_layers=3, n_heads=16, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_96         Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            16                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1533145
	speed: 0.0438s/iter; left time: 466.9090s
	iters: 200, epoch: 1 | loss: 0.4091955
	speed: 0.0599s/iter; left time: 631.5176s
	iters: 300, epoch: 1 | loss: 0.1512388
	speed: 0.0600s/iter; left time: 626.9156s
	iters: 400, epoch: 1 | loss: 0.6443569
	speed: 0.0625s/iter; left time: 646.8195s
	iters: 500, epoch: 1 | loss: 0.1471326
	speed: 0.0680s/iter; left time: 697.2441s
	iters: 600, epoch: 1 | loss: 0.2177383
	speed: 0.0665s/iter; left time: 674.8968s
	iters: 700, epoch: 1 | loss: 0.1558865
	speed: 0.0602s/iter; left time: 604.9303s
	iters: 800, epoch: 1 | loss: 0.1071247
	speed: 0.0640s/iter; left time: 637.3599s
	iters: 900, epoch: 1 | loss: 0.1555532
	speed: 0.0685s/iter; left time: 675.1134s
	iters: 1000, epoch: 1 | loss: 0.1862043
	speed: 0.0651s/iter; left time: 634.5320s
Epoch: 1 cost time: 66.65635585784912
Epoch: 1, Steps: 1075 | Train Loss: 0.2470156 Vali Loss: 0.1315569 Test Loss: 0.1810963
Validation loss decreased (inf --> 0.131557).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2248761
	speed: 0.3939s/iter; left time: 3771.7880s
	iters: 200, epoch: 2 | loss: 0.2824150
	speed: 0.0578s/iter; left time: 547.3130s
	iters: 300, epoch: 2 | loss: 0.2019682
	speed: 0.0663s/iter; left time: 621.6357s
	iters: 400, epoch: 2 | loss: 0.2351809
	speed: 0.0648s/iter; left time: 601.0133s
	iters: 500, epoch: 2 | loss: 0.1964418
	speed: 0.0587s/iter; left time: 538.5232s
	iters: 600, epoch: 2 | loss: 0.1423124
	speed: 0.0611s/iter; left time: 554.4437s
	iters: 700, epoch: 2 | loss: 0.1325684
	speed: 0.0656s/iter; left time: 588.6830s
	iters: 800, epoch: 2 | loss: 0.1504335
	speed: 0.0634s/iter; left time: 562.8722s
	iters: 900, epoch: 2 | loss: 0.2783321
	speed: 0.0621s/iter; left time: 545.1459s
	iters: 1000, epoch: 2 | loss: 0.2848791
	speed: 0.0613s/iter; left time: 531.9598s
Epoch: 2 cost time: 66.56565737724304
Epoch: 2, Steps: 1075 | Train Loss: 0.2335884 Vali Loss: 0.1269654 Test Loss: 0.1760933
Validation loss decreased (0.131557 --> 0.126965).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1316345
	speed: 0.3996s/iter; left time: 3396.6545s
	iters: 200, epoch: 3 | loss: 0.6034924
	speed: 0.0573s/iter; left time: 481.4614s
	iters: 300, epoch: 3 | loss: 0.1780862
	speed: 0.0544s/iter; left time: 451.7994s
	iters: 400, epoch: 3 | loss: 0.3653071
	speed: 0.0468s/iter; left time: 383.7914s
	iters: 500, epoch: 3 | loss: 0.3129801
	speed: 0.0565s/iter; left time: 457.6938s
	iters: 600, epoch: 3 | loss: 0.1223561
	speed: 0.0648s/iter; left time: 518.2640s
	iters: 700, epoch: 3 | loss: 0.2075643
	speed: 0.0645s/iter; left time: 509.4931s
	iters: 800, epoch: 3 | loss: 0.2274727
	speed: 0.0531s/iter; left time: 414.5447s
	iters: 900, epoch: 3 | loss: 0.2095635
	speed: 0.0559s/iter; left time: 430.5020s
	iters: 1000, epoch: 3 | loss: 0.4902182
	speed: 0.0651s/iter; left time: 494.8516s
Epoch: 3 cost time: 63.44241285324097
Epoch: 3, Steps: 1075 | Train Loss: 0.2236840 Vali Loss: 0.1303945 Test Loss: 0.1802245
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1422058
	speed: 0.3746s/iter; left time: 2781.7230s
	iters: 200, epoch: 4 | loss: 0.1227740
	speed: 0.0543s/iter; left time: 397.8055s
	iters: 300, epoch: 4 | loss: 0.2152324
	speed: 0.0609s/iter; left time: 440.2088s
	iters: 400, epoch: 4 | loss: 0.1846025
	speed: 0.0623s/iter; left time: 444.2563s
	iters: 500, epoch: 4 | loss: 0.1316896
	speed: 0.0593s/iter; left time: 416.7511s
	iters: 600, epoch: 4 | loss: 0.2915281
	speed: 0.0604s/iter; left time: 418.1735s
	iters: 700, epoch: 4 | loss: 0.3358380
	speed: 0.0578s/iter; left time: 394.4334s
	iters: 800, epoch: 4 | loss: 0.1058278
	speed: 0.0544s/iter; left time: 365.9465s
	iters: 900, epoch: 4 | loss: 0.2040305
	speed: 0.0472s/iter; left time: 312.9347s
	iters: 1000, epoch: 4 | loss: 0.1288373
	speed: 0.0604s/iter; left time: 394.2221s
Epoch: 4 cost time: 62.7289617061615
Epoch: 4, Steps: 1075 | Train Loss: 0.2160673 Vali Loss: 0.1285822 Test Loss: 0.1780741
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1702369
	speed: 0.3781s/iter; left time: 2401.0599s
	iters: 200, epoch: 5 | loss: 0.1432155
	speed: 0.0518s/iter; left time: 323.5994s
	iters: 300, epoch: 5 | loss: 0.1471262
	speed: 0.0589s/iter; left time: 362.5189s
	iters: 400, epoch: 5 | loss: 0.2607697
	speed: 0.0582s/iter; left time: 351.9272s
	iters: 500, epoch: 5 | loss: 0.1614239
	speed: 0.0657s/iter; left time: 391.0585s
	iters: 600, epoch: 5 | loss: 0.2317502
	speed: 0.0557s/iter; left time: 326.0085s
	iters: 700, epoch: 5 | loss: 0.1568583
	speed: 0.0588s/iter; left time: 338.0030s
	iters: 800, epoch: 5 | loss: 0.2949825
	speed: 0.0613s/iter; left time: 346.2707s
	iters: 900, epoch: 5 | loss: 0.1218515
	speed: 0.0660s/iter; left time: 366.6377s
	iters: 1000, epoch: 5 | loss: 0.2985696
	speed: 0.0573s/iter; left time: 312.5481s
Epoch: 5 cost time: 63.74160981178284
Epoch: 5, Steps: 1075 | Train Loss: 0.2113575 Vali Loss: 0.1305563 Test Loss: 0.1813578
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_96_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (11425, 96, 7) (11425, 96, 7)
test shape: (11425, 96, 7) (11425, 96, 7)
mse:0.1763177067041397, mae:0.2590201199054718
Running ETTm2 with pred_len=192, e_layers=3, n_heads=2, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_192        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            2                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2683956
	speed: 0.1706s/iter; left time: 440.2521s
	iters: 200, epoch: 1 | loss: 0.3362712
	speed: 0.1667s/iter; left time: 413.6125s
Epoch: 1 cost time: 44.21363639831543
Epoch: 1, Steps: 268 | Train Loss: 0.3431215 Vali Loss: 0.1778451 Test Loss: 0.2442916
Validation loss decreased (inf --> 0.177845).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4848431
	speed: 0.5339s/iter; left time: 1234.9802s
	iters: 200, epoch: 2 | loss: 0.3586670
	speed: 0.1268s/iter; left time: 280.5259s
Epoch: 2 cost time: 36.40476202964783
Epoch: 2, Steps: 268 | Train Loss: 0.3305158 Vali Loss: 0.1729337 Test Loss: 0.2417692
Validation loss decreased (0.177845 --> 0.172934).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3219270
	speed: 0.4865s/iter; left time: 994.9174s
	iters: 200, epoch: 3 | loss: 0.3946100
	speed: 0.1312s/iter; left time: 255.1534s
Epoch: 3 cost time: 36.65086030960083
Epoch: 3, Steps: 268 | Train Loss: 0.3220370 Vali Loss: 0.1753244 Test Loss: 0.2434667
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4123579
	speed: 0.5514s/iter; left time: 979.7847s
	iters: 200, epoch: 4 | loss: 0.3128305
	speed: 0.1414s/iter; left time: 237.0798s
Epoch: 4 cost time: 39.4152455329895
Epoch: 4, Steps: 268 | Train Loss: 0.3164962 Vali Loss: 0.1732850 Test Loss: 0.2424793
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4480640
	speed: 0.4523s/iter; left time: 682.5240s
	iters: 200, epoch: 5 | loss: 0.3734781
	speed: 0.1550s/iter; left time: 218.3725s
Epoch: 5 cost time: 43.34347987174988
Epoch: 5, Steps: 268 | Train Loss: 0.3127808 Vali Loss: 0.1755440 Test Loss: 0.2444440
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_192_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 192, 7) (11329, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.2425329089164734, mae:0.30277174711227417
Running ETTm2 with pred_len=336, e_layers=1, n_heads=4, batch_size=32
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_336        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3162335
	speed: 0.0649s/iter; left time: 686.0383s
	iters: 200, epoch: 1 | loss: 0.2662390
	speed: 0.0622s/iter; left time: 651.4625s
	iters: 300, epoch: 1 | loss: 0.6700891
	speed: 0.0544s/iter; left time: 564.3027s
	iters: 400, epoch: 1 | loss: 0.9626034
	speed: 0.0619s/iter; left time: 635.4056s
	iters: 500, epoch: 1 | loss: 0.5090491
	speed: 0.0619s/iter; left time: 629.1804s
	iters: 600, epoch: 1 | loss: 0.2726261
	speed: 0.0622s/iter; left time: 626.0195s
	iters: 700, epoch: 1 | loss: 0.3446003
	speed: 0.0576s/iter; left time: 574.0615s
	iters: 800, epoch: 1 | loss: 0.2483850
	speed: 0.0559s/iter; left time: 551.7173s
	iters: 900, epoch: 1 | loss: 0.5027685
	speed: 0.0578s/iter; left time: 565.2472s
	iters: 1000, epoch: 1 | loss: 0.4247297
	speed: 0.0606s/iter; left time: 586.1213s
Epoch: 1 cost time: 64.1691198348999
Epoch: 1, Steps: 1067 | Train Loss: 0.4510340 Vali Loss: 0.2268056 Test Loss: 0.3114098
Validation loss decreased (inf --> 0.226806).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2145407
	speed: 0.4819s/iter; left time: 4580.2587s
	iters: 200, epoch: 2 | loss: 0.3324335
	speed: 0.0560s/iter; left time: 526.6565s
	iters: 300, epoch: 2 | loss: 0.2769611
	speed: 0.0565s/iter; left time: 525.5425s
	iters: 400, epoch: 2 | loss: 0.4680433
	speed: 0.0553s/iter; left time: 508.8571s
	iters: 500, epoch: 2 | loss: 0.6337728
	speed: 0.0513s/iter; left time: 467.2194s
	iters: 600, epoch: 2 | loss: 0.3302185
	speed: 0.0541s/iter; left time: 486.9757s
	iters: 700, epoch: 2 | loss: 0.2919529
	speed: 0.0574s/iter; left time: 511.5183s
	iters: 800, epoch: 2 | loss: 0.2099085
	speed: 0.0592s/iter; left time: 521.2071s
	iters: 900, epoch: 2 | loss: 0.5752898
	speed: 0.0595s/iter; left time: 517.6210s
	iters: 1000, epoch: 2 | loss: 0.3760704
	speed: 0.0648s/iter; left time: 557.4018s
Epoch: 2 cost time: 61.32427263259888
Epoch: 2, Steps: 1067 | Train Loss: 0.4358857 Vali Loss: 0.2277533 Test Loss: 0.3071764
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3270597
	speed: 0.5624s/iter; left time: 4744.7786s
	iters: 200, epoch: 3 | loss: 0.2037500
	speed: 0.0641s/iter; left time: 534.7530s
	iters: 300, epoch: 3 | loss: 0.2801573
	speed: 0.0656s/iter; left time: 540.2816s
	iters: 400, epoch: 3 | loss: 0.2327752
	speed: 0.0609s/iter; left time: 495.1597s
	iters: 500, epoch: 3 | loss: 0.4631135
	speed: 0.0610s/iter; left time: 490.2033s
	iters: 600, epoch: 3 | loss: 0.5017137
	speed: 0.0597s/iter; left time: 474.0102s
	iters: 700, epoch: 3 | loss: 0.4674698
	speed: 0.0649s/iter; left time: 508.2644s
	iters: 800, epoch: 3 | loss: 0.3503422
	speed: 0.0651s/iter; left time: 503.9837s
	iters: 900, epoch: 3 | loss: 0.4933549
	speed: 0.0627s/iter; left time: 478.7713s
	iters: 1000, epoch: 3 | loss: 0.4663556
	speed: 0.0656s/iter; left time: 494.2647s
Epoch: 3 cost time: 67.59152817726135
Epoch: 3, Steps: 1067 | Train Loss: 0.4260228 Vali Loss: 0.2191913 Test Loss: 0.3014007
Validation loss decreased (0.226806 --> 0.219191).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5721951
	speed: 0.5730s/iter; left time: 4223.3093s
	iters: 200, epoch: 4 | loss: 0.2743123
	speed: 0.0545s/iter; left time: 396.5253s
	iters: 300, epoch: 4 | loss: 0.2210261
	speed: 0.0546s/iter; left time: 391.3886s
	iters: 400, epoch: 4 | loss: 0.2229168
	speed: 0.0558s/iter; left time: 394.3503s
	iters: 500, epoch: 4 | loss: 0.3648192
	speed: 0.0575s/iter; left time: 400.7032s
	iters: 600, epoch: 4 | loss: 0.5081627
	speed: 0.0595s/iter; left time: 408.6699s
	iters: 700, epoch: 4 | loss: 0.6623183
	speed: 0.0580s/iter; left time: 392.6326s
	iters: 800, epoch: 4 | loss: 0.4648753
	speed: 0.0548s/iter; left time: 365.7182s
	iters: 900, epoch: 4 | loss: 0.3240497
	speed: 0.0552s/iter; left time: 362.4430s
	iters: 1000, epoch: 4 | loss: 0.3795254
	speed: 0.0564s/iter; left time: 364.9568s
Epoch: 4 cost time: 60.960349559783936
Epoch: 4, Steps: 1067 | Train Loss: 0.4183807 Vali Loss: 0.2212262 Test Loss: 0.3037570
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5323228
	speed: 1.1632s/iter; left time: 7331.7310s
	iters: 200, epoch: 5 | loss: 0.3219174
	speed: 0.0541s/iter; left time: 335.2953s
	iters: 300, epoch: 5 | loss: 0.2209551
	speed: 0.0551s/iter; left time: 336.1559s
	iters: 400, epoch: 5 | loss: 0.9227943
	speed: 0.0533s/iter; left time: 320.0105s
	iters: 500, epoch: 5 | loss: 0.1956650
	speed: 0.0443s/iter; left time: 261.3076s
	iters: 600, epoch: 5 | loss: 0.3826073
	speed: 0.0478s/iter; left time: 277.1455s
	iters: 700, epoch: 5 | loss: 0.2161024
	speed: 0.0506s/iter; left time: 288.4889s
	iters: 800, epoch: 5 | loss: 0.3347746
	speed: 0.0520s/iter; left time: 291.5919s
	iters: 900, epoch: 5 | loss: 0.4283868
	speed: 0.0498s/iter; left time: 273.9579s
	iters: 1000, epoch: 5 | loss: 0.3457807
	speed: 0.0538s/iter; left time: 290.7123s
Epoch: 5 cost time: 54.951416969299316
Epoch: 5, Steps: 1067 | Train Loss: 0.4135740 Vali Loss: 0.2205428 Test Loss: 0.3033214
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2274620
	speed: 0.6529s/iter; left time: 3418.3295s
	iters: 200, epoch: 6 | loss: 0.2616158
	speed: 0.0627s/iter; left time: 322.1417s
	iters: 300, epoch: 6 | loss: 0.7240016
	speed: 0.0596s/iter; left time: 300.0838s
	iters: 400, epoch: 6 | loss: 1.0267491
	speed: 0.0611s/iter; left time: 301.7896s
	iters: 500, epoch: 6 | loss: 0.4022176
	speed: 0.0628s/iter; left time: 303.4721s
	iters: 600, epoch: 6 | loss: 0.3690952
	speed: 0.0616s/iter; left time: 291.8734s
	iters: 700, epoch: 6 | loss: 0.7664151
	speed: 0.0675s/iter; left time: 312.9902s
	iters: 800, epoch: 6 | loss: 0.2582485
	speed: 0.0649s/iter; left time: 294.2033s
	iters: 900, epoch: 6 | loss: 0.3979405
	speed: 0.0656s/iter; left time: 290.9004s
	iters: 1000, epoch: 6 | loss: 0.3314523
	speed: 0.0656s/iter; left time: 284.4538s
Epoch: 6 cost time: 67.43646502494812
Epoch: 6, Steps: 1067 | Train Loss: 0.4105536 Vali Loss: 0.2217260 Test Loss: 0.3048656
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_336_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (11185, 336, 7) (11185, 336, 7)
test shape: (11185, 336, 7) (11185, 336, 7)
mse:0.3016412556171417, mae:0.3419671654701233
Running ETTm2 with pred_len=720, e_layers=3, n_heads=4, batch_size=128
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          AGPT_loss           Is Training:        1                   
  Model ID:           ETTm2_96_720        Model:              AGPT_loss_G         

[1mData Loader[0m
  Data:               ETTm2               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTm2.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            4                   e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : AGPT_loss_ETTm2_96_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5871162
	speed: 0.1743s/iter; left time: 442.9869s
	iters: 200, epoch: 1 | loss: 0.5122428
	speed: 0.1694s/iter; left time: 413.4557s
Epoch: 1 cost time: 45.35385060310364
Epoch: 1, Steps: 264 | Train Loss: 0.5909425 Vali Loss: 0.2889628 Test Loss: 0.4073965
Validation loss decreased (inf --> 0.288963).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7090607
	speed: 0.4851s/iter; left time: 1104.6647s
	iters: 200, epoch: 2 | loss: 0.5370839
	speed: 0.1849s/iter; left time: 402.5773s
Epoch: 2 cost time: 48.37988615036011
Epoch: 2, Steps: 264 | Train Loss: 0.5781986 Vali Loss: 0.2929929 Test Loss: 0.4013797
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7055976
	speed: 0.5515s/iter; left time: 1110.1255s
	iters: 200, epoch: 3 | loss: 0.7570540
	speed: 0.1809s/iter; left time: 345.9983s
Epoch: 3 cost time: 48.781989336013794
Epoch: 3, Steps: 264 | Train Loss: 0.5669836 Vali Loss: 0.2898543 Test Loss: 0.4030312
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4782483
	speed: 0.5861s/iter; left time: 1025.0448s
	iters: 200, epoch: 4 | loss: 0.6419213
	speed: 0.1850s/iter; left time: 304.9879s
Epoch: 4 cost time: 47.81292223930359
Epoch: 4, Steps: 264 | Train Loss: 0.5593182 Vali Loss: 0.2912957 Test Loss: 0.4026508
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : AGPT_loss_ETTm2_96_720_AGPT_loss_G_2048_fixedFalse_0.0001_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.4051836133003235, mae:0.39990976452827454
